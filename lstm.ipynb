{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# network\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "from torchmetrics import F1\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import gc\n",
    "\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # shuffle 是否将官方给的的测试集和训练集重新打乱，再分成新的的训练集和测试集\n",
    " # ss标准化\n",
    "def process_data(tr_data, te_data, ss=None, shuffle=False):\n",
    "    split_num = len(tr_data)\n",
    "    data_temp = pd.concat([tr_data, te_data], axis=0)\n",
    "    data = pd.get_dummies(data_temp.iloc[:, 1:-2])\n",
    "    data['cat_code'] = LabelEncoder().fit_transform(data_temp.loc[:, 'attack_cat'])\n",
    "    # data['label'] = data_temp['label']\n",
    "    # data['attack_cat'] = data_temp['attack_cat']\n",
    "    if ss is None:\n",
    "        data.iloc[:,:-3] = ss.fit_transform(data.iloc[:,:-3])\n",
    "    if shuffle:\n",
    "        pass\n",
    "    else:\n",
    "        return data.iloc[:split_num,:], data.iloc[split_num:, :]\n",
    "\n",
    "ss = StandardScaler()\n",
    "tr_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_testing-set.csv')\n",
    "te_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_training-set.csv')\n",
    "tr_data, te_data = process_data(tr_raw_data, te_raw_data, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None:\n",
    "            y = y.astype(np.int)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        tr_data,\n",
    "        te_data,\n",
    "        val_num: float = 0.1,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        num_workers: int = NUM_WORKERS,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    # def prepare_data(self):\n",
    "        self.tr_data = MyDataset(tr_data[:,:-1], tr_data[:,-1])\n",
    "        self.test_set = MyDataset(te_data[:,:-1], te_data[:,-1])\n",
    "    def setup(self, stage = None):\n",
    "        # 划分训练集、验证集、测试集\n",
    "        if stage in (None, \"fit\"):\n",
    "            total_num = len(self.tr_data)\n",
    "            val_num = int (total_num * 0.1)\n",
    "            self.train_set, self.val_set = random_split(self.tr_data, [total_num-val_num, val_num])\n",
    "            del self.tr_data\n",
    "            gc.collect()\n",
    "        # if stage in (None, \"test\"):\n",
    "        #     self.te_data\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_set,\n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_set,\n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_class,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        num_layers,\n",
    "        dropout: float = 0.5,\n",
    "        lr: float = 0.001,\n",
    "        b1: float = 0.9,\n",
    "        b2: float = 0.999,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # networks\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_class),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        num_layers = self.hparams.num_layers\n",
    "        batch_size = self.hparams.batch_size\n",
    "        hidden_dim = self.hparams.hidden_dim\n",
    "        # h0 = torch.randn(num_layers, batch_size, hidden_dim)\n",
    "        # c0 = torch.randn(num_layers, batch_size, hidden_dim)\n",
    "        # x, _ = self.lstm(inputs, (h0, c0))\n",
    "        inputs = torch.unsqueeze(inputs, 1)\n",
    "        x, _ = self.lstm(inputs, None)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def evaluation(self, y_pred, y_true):\n",
    "        # if statue == 'test':\n",
    "        # 待写 判断调用时模型的过程（），\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        f1score = f1_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        metrics = {\n",
    "            # 'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1score,\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = torch.argmax(y_hat, dim=1).cpu().numpy()\n",
    "        metrics = self.evaluation(y_true, y_pred)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        metrics['loss'] = loss\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_true = y.cpu().detach().numpy()\n",
    "        y_pred = torch.argmax(y_hat, dim=1).cpu().numpy()\n",
    "        metrics = self.evaluation(y_true, y_pred)\n",
    "        # self.print('metrics:', metrics)\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "        return torch.optim.Adam(self.parameters(), lr = lr, betas = (b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | lstm       | LSTM       | 299 K \n",
      "1 | classifier | Sequential | 1.3 K \n",
      "------------------------------------------\n",
      "300 K     Trainable params\n",
      "0         Non-trainable params\n",
      "300 K     Total params\n",
      "1.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c1b7d7db254a0e8c7cbbc0ef6c828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsm/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jsm/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jsm/miniconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/properties.py:306: UserWarning: The progress bar already tracks a metric with the name(s) 'loss' and `self.log('loss', ..., prog_bar=True)` will overwrite this value.  If this is undesired, change the name or override `get_progress_bar_dict()` in `LightingModule`.\n",
      "  UserWarning,\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e17ddfea7bd4a3aa7f2507e94829301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da8359272f34223a42612a207376156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d612c580394b038885ef8d045d44e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc4260960d64a6da89e617e59ab2699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60682c62d794530a62f5b042078182e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886c488b3d4d4cde8177dc95f8e81d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsm/miniconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef659029ec8a456fa92b7e504a763e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'accuracy': 0.6178885698318481,\n",
      " 'f1_score': 0.3727115988731384,\n",
      " 'precision': 0.3698578178882599,\n",
      " 'recall': 0.39625516533851624}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.6178885698318481,\n",
       "  'precision': 0.3698578178882599,\n",
       "  'recall': 0.39625516533851624,\n",
       "  'f1_score': 0.3727115988731384}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "dm = MyDataModule(tr_data.values, te_data.values)\n",
    "model = MyLSTM(10, 196, 128, 2)\n",
    "trainer = Trainer(gpus = AVAIL_GPUS, max_epochs=5, progress_bar_refresh_rate=20)\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b82254768225213474ab4669cea3d52fe6b864ad6c9d79489ae1089fd4498"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
