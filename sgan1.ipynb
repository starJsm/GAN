{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch import nn\n",
    "# import pytorch_lightning as pl\n",
    "from pytorch_lightning import  LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "#sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import random\n",
    "\n",
    "# data process\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 为了结果可复现\n",
    "Seed = 42\n",
    "same_seeds(Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # shuffle 是否将官方给的的测试集和训练集重新打乱，再分成新的的训练集和测试集\n",
    " # ss标准化\n",
    "def process_data(tr_data, te_data=None, ss=None, shuffle=False):\n",
    "    split_num = len(tr_data)\n",
    "    data_temp = pd.concat([tr_data, te_data], axis=0)\n",
    "    data = pd.get_dummies(data_temp.iloc[:, 1:-2])\n",
    "    data['cat_code'] = LabelEncoder().fit_transform(data_temp.loc[:, 'attack_cat'])\n",
    "    # data['label'] = data_temp['label']\n",
    "    # data['attack_cat'] = data_temp['attack_cat']\n",
    "    if ss != None:\n",
    "        data.iloc[:,:-3] = ss.fit_transform(data.iloc[:,:-3])\n",
    "    if shuffle:\n",
    "        pass\n",
    "    else:\n",
    "        return data.iloc[:split_num,:], data.iloc[split_num:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>state_ACC</th>\n",
       "      <th>state_CLO</th>\n",
       "      <th>state_CON</th>\n",
       "      <th>state_ECO</th>\n",
       "      <th>state_FIN</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>state_PAR</th>\n",
       "      <th>state_REQ</th>\n",
       "      <th>state_RST</th>\n",
       "      <th>cat_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.188346</td>\n",
       "      <td>-0.101342</td>\n",
       "      <td>-0.129612</td>\n",
       "      <td>-0.047849</td>\n",
       "      <td>-0.097232</td>\n",
       "      <td>-0.568650</td>\n",
       "      <td>0.702512</td>\n",
       "      <td>1.500906</td>\n",
       "      <td>-0.380090</td>\n",
       "      <td>-0.269328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.099897</td>\n",
       "      <td>-0.042496</td>\n",
       "      <td>0.173998</td>\n",
       "      <td>-0.045110</td>\n",
       "      <td>0.188966</td>\n",
       "      <td>-0.568623</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380121</td>\n",
       "      <td>-0.064104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063006</td>\n",
       "      <td>-0.086630</td>\n",
       "      <td>-0.022456</td>\n",
       "      <td>-0.047239</td>\n",
       "      <td>-0.008217</td>\n",
       "      <td>-0.569024</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380158</td>\n",
       "      <td>-0.247593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072800</td>\n",
       "      <td>-0.057207</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>-0.045720</td>\n",
       "      <td>-0.093142</td>\n",
       "      <td>-0.569027</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380152</td>\n",
       "      <td>-0.271458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.133449</td>\n",
       "      <td>-0.071919</td>\n",
       "      <td>-0.111753</td>\n",
       "      <td>-0.046261</td>\n",
       "      <td>-0.096576</td>\n",
       "      <td>-0.568904</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380121</td>\n",
       "      <td>-0.271197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
       "0 -0.188346 -0.101342 -0.129612 -0.047849 -0.097232 -0.568650  0.702512   \n",
       "1 -0.099897 -0.042496  0.173998 -0.045110  0.188966 -0.568623 -1.151363   \n",
       "2  0.063006 -0.086630 -0.022456 -0.047239 -0.008217 -0.569024 -1.151363   \n",
       "3  0.072800 -0.057207 -0.058174 -0.045720 -0.093142 -0.569027 -1.151363   \n",
       "4 -0.133449 -0.071919 -0.111753 -0.046261 -0.096576 -0.568904  0.722026   \n",
       "\n",
       "       dttl     sload     dload  ...  state_ACC  state_CLO  state_CON  \\\n",
       "0  1.500906 -0.380090 -0.269328  ...   -0.00394   -0.00197  -0.291137   \n",
       "1  1.483170 -0.380121 -0.064104  ...   -0.00394   -0.00197  -0.291137   \n",
       "2  1.483170 -0.380158 -0.247593  ...   -0.00394   -0.00197  -0.291137   \n",
       "3  1.483170 -0.380152 -0.271458  ...   -0.00394   -0.00197  -0.291137   \n",
       "4  1.483170 -0.380121 -0.271197  ...   -0.00394   -0.00197  -0.291137   \n",
       "\n",
       "   state_ECO  state_FIN  state_INT  state_PAR  state_REQ  state_RST  cat_code  \n",
       "0  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "1  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "2  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "3  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "4  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据未处理的数据\n",
    "tr_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_testing-set.csv')\n",
    "te_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_training-set.csv')\n",
    "ss = StandardScaler()\n",
    "# 调用数据处理函数\n",
    "tr_data, te_data = process_data(tr_raw_data, te_raw_data, ss)\n",
    "# 挑选'Normal'的列，'cat_code'=6\n",
    "# tr_data = tr_data.loc[tr_data['cat_code'] == 6]\n",
    "# tr_data.drop(['cat_code'], axis=1, inplace=True)\n",
    "# 去掉无用的列\n",
    "tr_data.drop(['state_URN', 'state_no'], axis=1, inplace=True)\n",
    "te_data.drop(['state_URN', 'state_no'], axis=1, inplace=True)\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None:\n",
    "            y = y.astype(np.int64)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = MyDataset(tr_data.values[:,:-1], tr_data.values[:,-1])\n",
    "te_dataset = MyDataset(te_data.values[:,:-1], te_data.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # 初始化网络层\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, in_dim)\n",
    "    Output shape: (N, 1, out_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        def dconv_bn_relu(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose1d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(in_dim, dim*4*4*4, bias=False),\n",
    "            # tf 默认为0.3， torch 默认为0.01\n",
    "            nn.BatchNorm1d(dim*4*4*4),\n",
    "            nn.ReLU()\n",
    "            # nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.midlayer = nn.Sequential(\n",
    "           dconv_bn_relu(dim*4, dim*2),\n",
    "        #    dconv_bn_relu(dim*2, dim*2),\n",
    "           dconv_bn_relu(dim*2, dim),\n",
    "           dconv_bn_relu(dim, 1)\n",
    "        )\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Linear(128, out_dim, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = y.view(y.size(0), -1, 16)\n",
    "        y = self.midlayer(y)\n",
    "        y = y.squeeze(1)\n",
    "        y = self.outlayer(y)\n",
    "        y = y.unsqueeze(1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, )\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, dlatent_dim=128, in_channel=1, channel=8, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_bn_lrelu(in_channel, out_channel):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channel, out_channel, 5, 2, 2),\n",
    "                nn.BatchNorm1d(out_channel),\n",
    "                nn.LeakyReLU(0.2),\n",
    "            )\n",
    "\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(in_dim, dlatent_dim, bias=False),\n",
    "            nn.BatchNorm1d(dlatent_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.ls = nn.Sequential(\n",
    "            conv_bn_lrelu(in_channel, channel),\n",
    "            conv_bn_lrelu(channel, channel * 2),\n",
    "            conv_bn_lrelu(channel * 2, channel * 4),\n",
    "            conv_bn_lrelu(channel * 4, channel * 8),\n",
    "            conv_bn_lrelu(channel * 8, channel * 16),\n",
    "            nn.Conv1d(channel * 16, dlatent_dim, 4),\n",
    "        )\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(dlatent_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(dlatent_dim, num_classes + 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        # self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x.squeeze(1)\n",
    "        y = self.inlayer(y)\n",
    "        y = y.unsqueeze(1)\n",
    "        y = self.ls(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        validity = self.adv_layer(y)\n",
    "        label = self.aux_layer(y)\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "batch_size = 256\n",
    "z_dim = 100\n",
    "gout_dim = tr_data.shape[-1] - 1\n",
    "# 将tensor(张量)转化成variable(变量)。之所以需要将tensor转化成variable是因为pytorch中tensor(张量)只能放在CPU上运算，而(variable)变量是可以只用GPU进行加速计算的。\n",
    "z_sample = Variable(torch.randn(100, z_dim)).cuda()\n",
    "lr = 1e-4\n",
    "\n",
    "\"\"\" Medium: WGAN, 50 epoch, n_critic=5, clip_value=0.01 \"\"\"\n",
    "n_epoch = 5 # 50\n",
    "n_critic = 5 # 5\n",
    "clip_value = 0.01\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "workspace_dir = '.'\n",
    "log_dir = os.path.join(workspace_dir, 'lightning_logs')\n",
    "ckpt_dir = os.path.join(workspace_dir, 'checkpoints')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# Model\n",
    "G = Generator(in_dim=z_dim, out_dim=gout_dim)\n",
    "D = Discriminator(in_dim=gout_dim)\n",
    "G.train()\n",
    "D.train()\n",
    "\n",
    "# Loss\n",
    "# 一个二分类损失函数。可以是单标签的损失函数也可是多标签的损失函数。\n",
    "# https://blog.csdn.net/weixin_37724529/article/details/107084970\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\"\"\" Medium: Use RMSprop for WGAN. \"\"\"\n",
    "# Optimizer\n",
    "opt_D = torch.optim.RMSprop(D.parameters(), lr=lr)\n",
    "opt_G = torch.optim.RMSprop(G.parameters(), lr=lr)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# DataLoader\n",
    "tr_dataloader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "te_dataloader = DataLoader(te_dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5] [Batch 0/684] [D loss: 2.391188, acc: 0.119141, f1: 0.041220] [G loss: -0.332678]\n",
      "[Epoch 0/5] [Batch 1/684] [D loss: 2.256932, acc: 0.398438, f1: 0.063886] [G loss: -0.425813]\n",
      "[Epoch 0/5] [Batch 2/684] [D loss: 2.175638, acc: 0.496094, f1: 0.066405] [G loss: -0.571487]\n",
      "[Epoch 0/5] [Batch 3/684] [D loss: 2.129001, acc: 0.500000, f1: 0.066667] [G loss: -0.723965]\n",
      "[Epoch 0/5] [Batch 4/684] [D loss: 2.101161, acc: 0.500000, f1: 0.074074] [G loss: -0.837575]\n",
      "[Epoch 0/5] [Batch 5/684] [D loss: 2.067074, acc: 0.500000, f1: 0.074074] [G loss: -0.901612]\n",
      "[Epoch 0/5] [Batch 6/684] [D loss: 2.030314, acc: 0.500000, f1: 0.066667] [G loss: -0.936064]\n",
      "[Epoch 0/5] [Batch 7/684] [D loss: 2.015955, acc: 0.500000, f1: 0.066667] [G loss: -0.959663]\n",
      "[Epoch 0/5] [Batch 8/684] [D loss: 2.008918, acc: 0.500000, f1: 0.066667] [G loss: -0.971341]\n",
      "[Epoch 0/5] [Batch 9/684] [D loss: 2.004596, acc: 0.500000, f1: 0.066667] [G loss: -0.980995]\n",
      "[Epoch 0/5] [Batch 10/684] [D loss: 2.000489, acc: 0.500000, f1: 0.074074] [G loss: -0.986742]\n",
      "[Epoch 0/5] [Batch 11/684] [D loss: 1.992046, acc: 0.500000, f1: 0.066667] [G loss: -0.990378]\n",
      "[Epoch 0/5] [Batch 12/684] [D loss: 1.975762, acc: 0.500000, f1: 0.066667] [G loss: -0.993770]\n",
      "[Epoch 0/5] [Batch 13/684] [D loss: 1.965247, acc: 0.585938, f1: 0.181500] [G loss: -0.995660]\n",
      "[Epoch 0/5] [Batch 14/684] [D loss: 1.934119, acc: 0.628906, f1: 0.154634] [G loss: -0.996564]\n",
      "[Epoch 0/5] [Batch 15/684] [D loss: 1.919189, acc: 0.611328, f1: 0.185907] [G loss: -0.997443]\n",
      "[Epoch 0/5] [Batch 16/684] [D loss: 1.907110, acc: 0.609375, f1: 0.188451] [G loss: -0.997947]\n",
      "[Epoch 0/5] [Batch 17/684] [D loss: 1.902296, acc: 0.609375, f1: 0.149947] [G loss: -0.998044]\n",
      "[Epoch 0/5] [Batch 18/684] [D loss: 1.877512, acc: 0.705078, f1: 0.222458] [G loss: -0.998703]\n",
      "[Epoch 0/5] [Batch 19/684] [D loss: 1.844742, acc: 0.750000, f1: 0.235951] [G loss: -0.998927]\n",
      "[Epoch 0/5] [Batch 20/684] [D loss: 1.849847, acc: 0.740234, f1: 0.232399] [G loss: -0.999140]\n",
      "[Epoch 0/5] [Batch 21/684] [D loss: 1.856720, acc: 0.732422, f1: 0.231500] [G loss: -0.999306]\n",
      "[Epoch 0/5] [Batch 22/684] [D loss: 1.822295, acc: 0.763672, f1: 0.241460] [G loss: -0.999353]\n",
      "[Epoch 0/5] [Batch 23/684] [D loss: 1.843565, acc: 0.726562, f1: 0.232450] [G loss: -0.999430]\n",
      "[Epoch 0/5] [Batch 24/684] [D loss: 1.837892, acc: 0.728516, f1: 0.211275] [G loss: -0.999544]\n",
      "[Epoch 0/5] [Batch 25/684] [D loss: 1.815483, acc: 0.748047, f1: 0.243411] [G loss: -0.999624]\n",
      "[Epoch 0/5] [Batch 26/684] [D loss: 1.826247, acc: 0.734375, f1: 0.239933] [G loss: -0.999580]\n",
      "[Epoch 0/5] [Batch 27/684] [D loss: 1.798311, acc: 0.769531, f1: 0.229513] [G loss: -0.999682]\n",
      "[Epoch 0/5] [Batch 28/684] [D loss: 1.802748, acc: 0.753906, f1: 0.250327] [G loss: -0.999728]\n",
      "[Epoch 0/5] [Batch 29/684] [D loss: 1.798745, acc: 0.750000, f1: 0.273057] [G loss: -0.999766]\n",
      "[Epoch 0/5] [Batch 30/684] [D loss: 1.815582, acc: 0.736328, f1: 0.217423] [G loss: -0.999780]\n",
      "[Epoch 0/5] [Batch 31/684] [D loss: 1.822279, acc: 0.726562, f1: 0.217809] [G loss: -0.999810]\n",
      "[Epoch 0/5] [Batch 32/684] [D loss: 1.808875, acc: 0.740234, f1: 0.246519] [G loss: -0.999783]\n",
      "[Epoch 0/5] [Batch 33/684] [D loss: 1.809905, acc: 0.738281, f1: 0.272467] [G loss: -0.999833]\n",
      "[Epoch 0/5] [Batch 34/684] [D loss: 1.797930, acc: 0.750000, f1: 0.278458] [G loss: -0.999865]\n",
      "[Epoch 0/5] [Batch 35/684] [D loss: 1.790723, acc: 0.751953, f1: 0.250698] [G loss: -0.999870]\n",
      "[Epoch 0/5] [Batch 36/684] [D loss: 1.760424, acc: 0.785156, f1: 0.258856] [G loss: -0.999878]\n",
      "[Epoch 0/5] [Batch 37/684] [D loss: 1.774436, acc: 0.771484, f1: 0.232990] [G loss: -0.999897]\n",
      "[Epoch 0/5] [Batch 38/684] [D loss: 1.805038, acc: 0.738281, f1: 0.245498] [G loss: -0.999902]\n",
      "[Epoch 0/5] [Batch 39/684] [D loss: 1.783829, acc: 0.759766, f1: 0.254516] [G loss: -0.999913]\n",
      "[Epoch 0/5] [Batch 40/684] [D loss: 1.759479, acc: 0.783203, f1: 0.258521] [G loss: -0.999928]\n",
      "[Epoch 0/5] [Batch 41/684] [D loss: 1.783856, acc: 0.757812, f1: 0.251305] [G loss: -0.999940]\n",
      "[Epoch 0/5] [Batch 42/684] [D loss: 1.765869, acc: 0.777344, f1: 0.287192] [G loss: -0.999934]\n",
      "[Epoch 0/5] [Batch 43/684] [D loss: 1.791164, acc: 0.750000, f1: 0.276816] [G loss: -0.999946]\n",
      "[Epoch 0/5] [Batch 44/684] [D loss: 1.771495, acc: 0.771484, f1: 0.255205] [G loss: -0.999939]\n",
      "[Epoch 0/5] [Batch 45/684] [D loss: 1.809804, acc: 0.730469, f1: 0.242134] [G loss: -0.999963]\n",
      "[Epoch 0/5] [Batch 46/684] [D loss: 1.794167, acc: 0.750000, f1: 0.251519] [G loss: -0.999959]\n",
      "[Epoch 0/5] [Batch 47/684] [D loss: 1.784177, acc: 0.757812, f1: 0.250260] [G loss: -0.999956]\n",
      "[Epoch 0/5] [Batch 48/684] [D loss: 1.797389, acc: 0.746094, f1: 0.228744] [G loss: -0.999962]\n",
      "[Epoch 0/5] [Batch 49/684] [D loss: 1.780191, acc: 0.761719, f1: 0.230324] [G loss: -0.999963]\n",
      "[Epoch 0/5] [Batch 50/684] [D loss: 1.774265, acc: 0.769531, f1: 0.258141] [G loss: -0.999975]\n",
      "[Epoch 0/5] [Batch 51/684] [D loss: 1.801200, acc: 0.742188, f1: 0.248948] [G loss: -0.999972]\n",
      "[Epoch 0/5] [Batch 52/684] [D loss: 1.774852, acc: 0.767578, f1: 0.256274] [G loss: -0.999979]\n",
      "[Epoch 0/5] [Batch 53/684] [D loss: 1.786584, acc: 0.757812, f1: 0.251353] [G loss: -0.999980]\n",
      "[Epoch 0/5] [Batch 54/684] [D loss: 1.792275, acc: 0.751953, f1: 0.258020] [G loss: -0.999980]\n",
      "[Epoch 0/5] [Batch 55/684] [D loss: 1.781154, acc: 0.759766, f1: 0.280958] [G loss: -0.999984]\n",
      "[Epoch 0/5] [Batch 56/684] [D loss: 1.752200, acc: 0.791016, f1: 0.292946] [G loss: -0.999984]\n",
      "[Epoch 0/5] [Batch 57/684] [D loss: 1.769989, acc: 0.771484, f1: 0.254667] [G loss: -0.999982]\n",
      "[Epoch 0/5] [Batch 58/684] [D loss: 1.792894, acc: 0.750000, f1: 0.248428] [G loss: -0.999989]\n",
      "[Epoch 0/5] [Batch 59/684] [D loss: 1.795947, acc: 0.746094, f1: 0.280849] [G loss: -0.999988]\n",
      "[Epoch 0/5] [Batch 60/684] [D loss: 1.777746, acc: 0.765625, f1: 0.254801] [G loss: -0.999991]\n",
      "[Epoch 0/5] [Batch 61/684] [D loss: 1.770208, acc: 0.773438, f1: 0.260462] [G loss: -0.999985]\n",
      "[Epoch 0/5] [Batch 62/684] [D loss: 1.776981, acc: 0.765625, f1: 0.285497] [G loss: -0.999992]\n",
      "[Epoch 0/5] [Batch 63/684] [D loss: 1.789924, acc: 0.753906, f1: 0.254970] [G loss: -0.999992]\n",
      "[Epoch 0/5] [Batch 64/684] [D loss: 1.773823, acc: 0.769531, f1: 0.257100] [G loss: -0.999991]\n",
      "[Epoch 0/5] [Batch 65/684] [D loss: 1.744580, acc: 0.796875, f1: 0.291152] [G loss: -0.999994]\n",
      "[Epoch 0/5] [Batch 66/684] [D loss: 1.771425, acc: 0.771484, f1: 0.234954] [G loss: -0.999990]\n",
      "[Epoch 0/5] [Batch 67/684] [D loss: 1.785927, acc: 0.755859, f1: 0.251920] [G loss: -0.999990]\n",
      "[Epoch 0/5] [Batch 68/684] [D loss: 1.798335, acc: 0.744141, f1: 0.281687] [G loss: -0.999994]\n",
      "[Epoch 0/5] [Batch 69/684] [D loss: 1.778599, acc: 0.763672, f1: 0.234018] [G loss: -0.999992]\n",
      "[Epoch 0/5] [Batch 70/684] [D loss: 1.783296, acc: 0.759766, f1: 0.247580] [G loss: -0.999996]\n",
      "[Epoch 0/5] [Batch 71/684] [D loss: 1.762218, acc: 0.781250, f1: 0.256480] [G loss: -0.999996]\n",
      "[Epoch 0/5] [Batch 72/684] [D loss: 1.781227, acc: 0.761719, f1: 0.258244] [G loss: -0.999995]\n",
      "[Epoch 0/5] [Batch 73/684] [D loss: 1.772900, acc: 0.769531, f1: 0.256656] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 74/684] [D loss: 1.783003, acc: 0.759766, f1: 0.253651] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 75/684] [D loss: 1.755584, acc: 0.787109, f1: 0.260549] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 76/684] [D loss: 1.772523, acc: 0.769531, f1: 0.259019] [G loss: -0.999996]\n",
      "[Epoch 0/5] [Batch 77/684] [D loss: 1.783069, acc: 0.757812, f1: 0.253511] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 78/684] [D loss: 1.819814, acc: 0.722656, f1: 0.219460] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 79/684] [D loss: 1.781314, acc: 0.761719, f1: 0.250706] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 80/684] [D loss: 1.762974, acc: 0.779297, f1: 0.287660] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 81/684] [D loss: 1.735252, acc: 0.806641, f1: 0.264213] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 82/684] [D loss: 1.746850, acc: 0.794922, f1: 0.325838] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 83/684] [D loss: 1.761648, acc: 0.781250, f1: 0.261791] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 84/684] [D loss: 1.742447, acc: 0.800781, f1: 0.265433] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 85/684] [D loss: 1.751754, acc: 0.791016, f1: 0.265027] [G loss: -0.999996]\n",
      "[Epoch 0/5] [Batch 86/684] [D loss: 1.740376, acc: 0.800781, f1: 0.263859] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 87/684] [D loss: 1.745781, acc: 0.796875, f1: 0.239392] [G loss: -0.999997]\n",
      "[Epoch 0/5] [Batch 88/684] [D loss: 1.765265, acc: 0.777344, f1: 0.257610] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 89/684] [D loss: 1.791617, acc: 0.750000, f1: 0.254725] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 90/684] [D loss: 1.771359, acc: 0.771484, f1: 0.258549] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 91/684] [D loss: 1.770647, acc: 0.771484, f1: 0.259263] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 92/684] [D loss: 1.776428, acc: 0.765625, f1: 0.258628] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 93/684] [D loss: 1.764681, acc: 0.777344, f1: 0.285450] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 94/684] [D loss: 1.759859, acc: 0.783203, f1: 0.259516] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 95/684] [D loss: 1.803483, acc: 0.738281, f1: 0.278381] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 96/684] [D loss: 1.776078, acc: 0.765625, f1: 0.282968] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 97/684] [D loss: 1.778733, acc: 0.763672, f1: 0.253386] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 98/684] [D loss: 1.774106, acc: 0.767578, f1: 0.287848] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 99/684] [D loss: 1.763067, acc: 0.779297, f1: 0.258829] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 100/684] [D loss: 1.762968, acc: 0.779297, f1: 0.263230] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 101/684] [D loss: 1.773085, acc: 0.769531, f1: 0.257274] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 102/684] [D loss: 1.772900, acc: 0.769531, f1: 0.258309] [G loss: -0.999998]\n",
      "[Epoch 0/5] [Batch 103/684] [D loss: 1.747272, acc: 0.794922, f1: 0.263558] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 104/684] [D loss: 1.773310, acc: 0.769531, f1: 0.253399] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 105/684] [D loss: 1.791143, acc: 0.750000, f1: 0.279834] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 106/684] [D loss: 1.785690, acc: 0.755859, f1: 0.254005] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 107/684] [D loss: 1.766628, acc: 0.775391, f1: 0.259812] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 108/684] [D loss: 1.779944, acc: 0.761719, f1: 0.258843] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 109/684] [D loss: 1.784216, acc: 0.757812, f1: 0.254603] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 110/684] [D loss: 1.793580, acc: 0.748047, f1: 0.252673] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 111/684] [D loss: 1.791608, acc: 0.750000, f1: 0.230743] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 112/684] [D loss: 1.778375, acc: 0.763672, f1: 0.254051] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 113/684] [D loss: 1.733163, acc: 0.808594, f1: 0.293365] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 114/684] [D loss: 1.756827, acc: 0.785156, f1: 0.261752] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 115/684] [D loss: 1.764746, acc: 0.777344, f1: 0.257501] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 116/684] [D loss: 1.786802, acc: 0.755859, f1: 0.283745] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 117/684] [D loss: 1.772522, acc: 0.769531, f1: 0.232951] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 118/684] [D loss: 1.803770, acc: 0.738281, f1: 0.247967] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 119/684] [D loss: 1.742399, acc: 0.800781, f1: 0.293182] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 120/684] [D loss: 1.770446, acc: 0.771484, f1: 0.283244] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 121/684] [D loss: 1.786142, acc: 0.755859, f1: 0.254829] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 122/684] [D loss: 1.789411, acc: 0.751953, f1: 0.228515] [G loss: -0.999999]\n",
      "[Epoch 0/5] [Batch 123/684] [D loss: 1.756489, acc: 0.785156, f1: 0.289888] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 124/684] [D loss: 1.776415, acc: 0.765625, f1: 0.322095] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 125/684] [D loss: 1.786668, acc: 0.753906, f1: 0.254832] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 126/684] [D loss: 1.776340, acc: 0.765625, f1: 0.257984] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 127/684] [D loss: 1.783928, acc: 0.757812, f1: 0.253044] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 128/684] [D loss: 1.791626, acc: 0.750000, f1: 0.254749] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 129/684] [D loss: 1.772744, acc: 0.769531, f1: 0.236796] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 130/684] [D loss: 1.763131, acc: 0.779297, f1: 0.259000] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 131/684] [D loss: 1.787712, acc: 0.753906, f1: 0.253574] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 132/684] [D loss: 1.770180, acc: 0.771484, f1: 0.258471] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 133/684] [D loss: 1.777650, acc: 0.763672, f1: 0.232354] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 134/684] [D loss: 1.746798, acc: 0.794922, f1: 0.264248] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 135/684] [D loss: 1.759325, acc: 0.783203, f1: 0.260624] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 136/684] [D loss: 1.764745, acc: 0.777344, f1: 0.235749] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 137/684] [D loss: 1.774936, acc: 0.767578, f1: 0.282627] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 138/684] [D loss: 1.717962, acc: 0.824219, f1: 0.296523] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 139/684] [D loss: 1.780290, acc: 0.761719, f1: 0.284329] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 140/684] [D loss: 1.799101, acc: 0.742188, f1: 0.252764] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 141/684] [D loss: 1.766250, acc: 0.775391, f1: 0.259980] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 142/684] [D loss: 1.772612, acc: 0.769531, f1: 0.257395] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 143/684] [D loss: 1.742844, acc: 0.798828, f1: 0.238299] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 144/684] [D loss: 1.758754, acc: 0.783203, f1: 0.257658] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 145/684] [D loss: 1.764624, acc: 0.777344, f1: 0.288105] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 146/684] [D loss: 1.765924, acc: 0.775391, f1: 0.261403] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 147/684] [D loss: 1.797056, acc: 0.744141, f1: 0.253946] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 148/684] [D loss: 1.757027, acc: 0.785156, f1: 0.263006] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 149/684] [D loss: 1.785864, acc: 0.755859, f1: 0.254817] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 150/684] [D loss: 1.778669, acc: 0.763672, f1: 0.234493] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 151/684] [D loss: 1.764618, acc: 0.777344, f1: 0.259503] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 152/684] [D loss: 1.754198, acc: 0.789062, f1: 0.262751] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 153/684] [D loss: 1.764714, acc: 0.777344, f1: 0.259506] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 154/684] [D loss: 1.770372, acc: 0.771484, f1: 0.291156] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 155/684] [D loss: 1.750226, acc: 0.791016, f1: 0.262715] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 156/684] [D loss: 1.780621, acc: 0.761719, f1: 0.258760] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 157/684] [D loss: 1.787802, acc: 0.753906, f1: 0.257786] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 158/684] [D loss: 1.770462, acc: 0.771484, f1: 0.261039] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 159/684] [D loss: 1.762735, acc: 0.779297, f1: 0.289879] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 160/684] [D loss: 1.793703, acc: 0.748047, f1: 0.231532] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 161/684] [D loss: 1.759577, acc: 0.783203, f1: 0.261054] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 162/684] [D loss: 1.778399, acc: 0.763672, f1: 0.259355] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 163/684] [D loss: 1.788448, acc: 0.753906, f1: 0.251300] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 164/684] [D loss: 1.768569, acc: 0.773438, f1: 0.261478] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 165/684] [D loss: 1.755967, acc: 0.787109, f1: 0.264717] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 166/684] [D loss: 1.786123, acc: 0.755859, f1: 0.233110] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 167/684] [D loss: 1.772717, acc: 0.769531, f1: 0.235552] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 168/684] [D loss: 1.789742, acc: 0.751953, f1: 0.255559] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 169/684] [D loss: 1.770367, acc: 0.771484, f1: 0.260727] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 170/684] [D loss: 1.772467, acc: 0.769531, f1: 0.233505] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 171/684] [D loss: 1.783577, acc: 0.757812, f1: 0.231096] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 172/684] [D loss: 1.750944, acc: 0.791016, f1: 0.262305] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 173/684] [D loss: 1.804099, acc: 0.736328, f1: 0.251538] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 174/684] [D loss: 1.765042, acc: 0.777344, f1: 0.286080] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 175/684] [D loss: 1.765652, acc: 0.775391, f1: 0.284895] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 176/684] [D loss: 1.768189, acc: 0.773438, f1: 0.256967] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 177/684] [D loss: 1.775796, acc: 0.765625, f1: 0.235310] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 178/684] [D loss: 1.789299, acc: 0.751953, f1: 0.254332] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 179/684] [D loss: 1.792948, acc: 0.748047, f1: 0.252724] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 180/684] [D loss: 1.751210, acc: 0.791016, f1: 0.260196] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 181/684] [D loss: 1.770323, acc: 0.771484, f1: 0.234996] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 182/684] [D loss: 1.777840, acc: 0.763672, f1: 0.255874] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 183/684] [D loss: 1.776656, acc: 0.765625, f1: 0.259083] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 184/684] [D loss: 1.776224, acc: 0.765625, f1: 0.258708] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 185/684] [D loss: 1.772050, acc: 0.769531, f1: 0.259828] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 186/684] [D loss: 1.781971, acc: 0.759766, f1: 0.255632] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 187/684] [D loss: 1.787422, acc: 0.753906, f1: 0.259197] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 188/684] [D loss: 1.791467, acc: 0.750000, f1: 0.251550] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 189/684] [D loss: 1.754273, acc: 0.787109, f1: 0.289370] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 190/684] [D loss: 1.799918, acc: 0.740234, f1: 0.229552] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 191/684] [D loss: 1.760840, acc: 0.781250, f1: 0.239320] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 192/684] [D loss: 1.758774, acc: 0.783203, f1: 0.262722] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 193/684] [D loss: 1.760909, acc: 0.781250, f1: 0.259741] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 194/684] [D loss: 1.800404, acc: 0.742188, f1: 0.252808] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 195/684] [D loss: 1.797845, acc: 0.744141, f1: 0.280336] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 196/684] [D loss: 1.775304, acc: 0.765625, f1: 0.257046] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 197/684] [D loss: 1.763071, acc: 0.779297, f1: 0.262875] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 198/684] [D loss: 1.791972, acc: 0.750000, f1: 0.252746] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 199/684] [D loss: 1.770256, acc: 0.771484, f1: 0.258651] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 200/684] [D loss: 1.752670, acc: 0.789062, f1: 0.239103] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 201/684] [D loss: 1.770467, acc: 0.771484, f1: 0.261252] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 202/684] [D loss: 1.764002, acc: 0.777344, f1: 0.236983] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 203/684] [D loss: 1.767662, acc: 0.773438, f1: 0.289639] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 204/684] [D loss: 1.762456, acc: 0.779297, f1: 0.289805] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 205/684] [D loss: 1.768549, acc: 0.773438, f1: 0.259502] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 206/684] [D loss: 1.777847, acc: 0.763672, f1: 0.255877] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 207/684] [D loss: 1.766208, acc: 0.775391, f1: 0.261681] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 208/684] [D loss: 1.756761, acc: 0.785156, f1: 0.256144] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 209/684] [D loss: 1.784385, acc: 0.757812, f1: 0.250589] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 210/684] [D loss: 1.750942, acc: 0.791016, f1: 0.261691] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 211/684] [D loss: 1.784228, acc: 0.757812, f1: 0.256305] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 212/684] [D loss: 1.774351, acc: 0.767578, f1: 0.283476] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 213/684] [D loss: 1.770005, acc: 0.771484, f1: 0.257492] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 214/684] [D loss: 1.789603, acc: 0.751953, f1: 0.253821] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 215/684] [D loss: 1.765296, acc: 0.775391, f1: 0.260388] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 216/684] [D loss: 1.773725, acc: 0.767578, f1: 0.287167] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 217/684] [D loss: 1.766776, acc: 0.775391, f1: 0.257767] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 218/684] [D loss: 1.799299, acc: 0.742188, f1: 0.248214] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 219/684] [D loss: 1.791889, acc: 0.750000, f1: 0.253365] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 220/684] [D loss: 1.751023, acc: 0.791016, f1: 0.289143] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 221/684] [D loss: 1.772341, acc: 0.769531, f1: 0.282499] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 222/684] [D loss: 1.801530, acc: 0.740234, f1: 0.228743] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 223/684] [D loss: 1.784285, acc: 0.757812, f1: 0.286528] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 224/684] [D loss: 1.772324, acc: 0.769531, f1: 0.230598] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 225/684] [D loss: 1.754738, acc: 0.787109, f1: 0.263023] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 226/684] [D loss: 1.773776, acc: 0.767578, f1: 0.258166] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 227/684] [D loss: 1.745255, acc: 0.796875, f1: 0.263296] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 228/684] [D loss: 1.721930, acc: 0.820312, f1: 0.272480] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 229/684] [D loss: 1.754698, acc: 0.787109, f1: 0.261226] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 230/684] [D loss: 1.799514, acc: 0.742188, f1: 0.253176] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 231/684] [D loss: 1.793486, acc: 0.748047, f1: 0.280399] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 232/684] [D loss: 1.769785, acc: 0.771484, f1: 0.258128] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 233/684] [D loss: 1.758433, acc: 0.783203, f1: 0.288437] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 234/684] [D loss: 1.771867, acc: 0.769531, f1: 0.287776] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 235/684] [D loss: 1.775848, acc: 0.765625, f1: 0.256195] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 236/684] [D loss: 1.795591, acc: 0.746094, f1: 0.250399] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 237/684] [D loss: 1.748387, acc: 0.792969, f1: 0.291984] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 238/684] [D loss: 1.754696, acc: 0.787109, f1: 0.292247] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 239/684] [D loss: 1.755027, acc: 0.787109, f1: 0.240315] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 240/684] [D loss: 1.777758, acc: 0.763672, f1: 0.257787] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 241/684] [D loss: 1.764424, acc: 0.777344, f1: 0.288281] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 242/684] [D loss: 1.744562, acc: 0.796875, f1: 0.294280] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 243/684] [D loss: 1.801436, acc: 0.740234, f1: 0.278100] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 244/684] [D loss: 1.777502, acc: 0.763672, f1: 0.258362] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 245/684] [D loss: 1.781707, acc: 0.759766, f1: 0.256989] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 246/684] [D loss: 1.779957, acc: 0.761719, f1: 0.253012] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 247/684] [D loss: 1.793108, acc: 0.748047, f1: 0.250040] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 248/684] [D loss: 1.810859, acc: 0.730469, f1: 0.243223] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 249/684] [D loss: 1.775104, acc: 0.765625, f1: 0.256173] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 250/684] [D loss: 1.745749, acc: 0.796875, f1: 0.291926] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 251/684] [D loss: 1.747142, acc: 0.794922, f1: 0.259675] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 252/684] [D loss: 1.779625, acc: 0.761719, f1: 0.232565] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 253/684] [D loss: 1.768968, acc: 0.771484, f1: 0.232763] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 254/684] [D loss: 1.779891, acc: 0.761719, f1: 0.251559] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 255/684] [D loss: 1.787017, acc: 0.753906, f1: 0.248026] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 256/684] [D loss: 1.789142, acc: 0.751953, f1: 0.226872] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 257/684] [D loss: 1.804540, acc: 0.736328, f1: 0.237818] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 258/684] [D loss: 1.765180, acc: 0.775391, f1: 0.257951] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 259/684] [D loss: 1.744162, acc: 0.798828, f1: 0.282250] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 260/684] [D loss: 1.750379, acc: 0.791016, f1: 0.260545] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 261/684] [D loss: 1.758986, acc: 0.783203, f1: 0.281231] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 262/684] [D loss: 1.768476, acc: 0.773438, f1: 0.283177] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 263/684] [D loss: 1.758297, acc: 0.783203, f1: 0.254766] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 264/684] [D loss: 1.773753, acc: 0.767578, f1: 0.280716] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 265/684] [D loss: 1.748908, acc: 0.792969, f1: 0.289488] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 266/684] [D loss: 1.789519, acc: 0.751953, f1: 0.224426] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 267/684] [D loss: 1.784154, acc: 0.757812, f1: 0.243793] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 268/684] [D loss: 1.754251, acc: 0.787109, f1: 0.232279] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 269/684] [D loss: 1.786284, acc: 0.755859, f1: 0.273304] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 270/684] [D loss: 1.751076, acc: 0.791016, f1: 0.254341] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 271/684] [D loss: 1.767154, acc: 0.775391, f1: 0.250260] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 272/684] [D loss: 1.782869, acc: 0.759766, f1: 0.273363] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 273/684] [D loss: 1.765410, acc: 0.777344, f1: 0.254097] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 274/684] [D loss: 1.780537, acc: 0.761719, f1: 0.245499] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 275/684] [D loss: 1.783107, acc: 0.759766, f1: 0.247743] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 276/684] [D loss: 1.786233, acc: 0.755859, f1: 0.271937] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 277/684] [D loss: 1.797837, acc: 0.744141, f1: 0.240657] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 278/684] [D loss: 1.745525, acc: 0.796875, f1: 0.258479] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 279/684] [D loss: 1.779528, acc: 0.761719, f1: 0.278761] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 280/684] [D loss: 1.780266, acc: 0.761719, f1: 0.247085] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 281/684] [D loss: 1.770760, acc: 0.771484, f1: 0.226420] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 282/684] [D loss: 1.730918, acc: 0.812500, f1: 0.293294] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 283/684] [D loss: 1.778895, acc: 0.763672, f1: 0.227350] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 284/684] [D loss: 1.789634, acc: 0.751953, f1: 0.243557] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 285/684] [D loss: 1.758176, acc: 0.783203, f1: 0.259238] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 286/684] [D loss: 1.769954, acc: 0.771484, f1: 0.281192] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 287/684] [D loss: 1.793911, acc: 0.748047, f1: 0.244787] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 288/684] [D loss: 1.794332, acc: 0.748047, f1: 0.243310] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 289/684] [D loss: 1.760651, acc: 0.781250, f1: 0.253348] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 290/684] [D loss: 1.756801, acc: 0.785156, f1: 0.263493] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 291/684] [D loss: 1.770873, acc: 0.771484, f1: 0.256154] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 292/684] [D loss: 1.770257, acc: 0.771484, f1: 0.252226] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 293/684] [D loss: 1.758441, acc: 0.783203, f1: 0.259481] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 294/684] [D loss: 1.793318, acc: 0.748047, f1: 0.271212] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 295/684] [D loss: 1.764342, acc: 0.777344, f1: 0.317625] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 296/684] [D loss: 1.789361, acc: 0.751953, f1: 0.251949] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 297/684] [D loss: 1.787846, acc: 0.753906, f1: 0.245992] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 298/684] [D loss: 1.763969, acc: 0.777344, f1: 0.260436] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 299/684] [D loss: 1.768897, acc: 0.773438, f1: 0.258504] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 300/684] [D loss: 1.792748, acc: 0.748047, f1: 0.253091] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 301/684] [D loss: 1.777877, acc: 0.763672, f1: 0.286007] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 302/684] [D loss: 1.754770, acc: 0.787109, f1: 0.239339] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 303/684] [D loss: 1.766828, acc: 0.775391, f1: 0.258367] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 304/684] [D loss: 1.762938, acc: 0.779297, f1: 0.287403] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 305/684] [D loss: 1.792228, acc: 0.750000, f1: 0.249846] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 306/684] [D loss: 1.771010, acc: 0.771484, f1: 0.256714] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 307/684] [D loss: 1.779974, acc: 0.761719, f1: 0.259568] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 308/684] [D loss: 1.809784, acc: 0.732422, f1: 0.251720] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 309/684] [D loss: 1.737831, acc: 0.804688, f1: 0.379318] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 310/684] [D loss: 1.791471, acc: 0.750000, f1: 0.256236] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 311/684] [D loss: 1.747812, acc: 0.794922, f1: 0.266698] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 312/684] [D loss: 1.769443, acc: 0.773438, f1: 0.262425] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 313/684] [D loss: 1.797801, acc: 0.744141, f1: 0.255759] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 314/684] [D loss: 1.782279, acc: 0.759766, f1: 0.285239] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 315/684] [D loss: 1.776885, acc: 0.765625, f1: 0.257704] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 316/684] [D loss: 1.758254, acc: 0.783203, f1: 0.261506] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 317/684] [D loss: 1.757021, acc: 0.785156, f1: 0.259875] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 318/684] [D loss: 1.754862, acc: 0.787109, f1: 0.261986] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 319/684] [D loss: 1.756543, acc: 0.785156, f1: 0.288441] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 320/684] [D loss: 1.799542, acc: 0.742188, f1: 0.253424] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 321/684] [D loss: 1.776219, acc: 0.765625, f1: 0.278501] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 322/684] [D loss: 1.770443, acc: 0.771484, f1: 0.286770] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 323/684] [D loss: 1.751361, acc: 0.791016, f1: 0.237406] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 324/684] [D loss: 1.777634, acc: 0.763672, f1: 0.259200] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 325/684] [D loss: 1.780310, acc: 0.761719, f1: 0.255318] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 326/684] [D loss: 1.770348, acc: 0.771484, f1: 0.234007] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 327/684] [D loss: 1.756886, acc: 0.785156, f1: 0.288620] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 328/684] [D loss: 1.737373, acc: 0.804688, f1: 0.266598] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 329/684] [D loss: 1.739516, acc: 0.802734, f1: 0.265412] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 330/684] [D loss: 1.775958, acc: 0.765625, f1: 0.255494] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 331/684] [D loss: 1.760457, acc: 0.781250, f1: 0.259805] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 332/684] [D loss: 1.745096, acc: 0.796875, f1: 0.263413] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 333/684] [D loss: 1.774009, acc: 0.767578, f1: 0.232963] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 334/684] [D loss: 1.754556, acc: 0.787109, f1: 0.262718] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 335/684] [D loss: 1.790415, acc: 0.751953, f1: 0.252295] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 336/684] [D loss: 1.772112, acc: 0.769531, f1: 0.258352] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 337/684] [D loss: 1.782645, acc: 0.759766, f1: 0.253782] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 338/684] [D loss: 1.794171, acc: 0.748047, f1: 0.228124] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 339/684] [D loss: 1.759380, acc: 0.783203, f1: 0.264080] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 340/684] [D loss: 1.753012, acc: 0.789062, f1: 0.261157] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 341/684] [D loss: 1.770191, acc: 0.771484, f1: 0.288705] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 342/684] [D loss: 1.757244, acc: 0.785156, f1: 0.233970] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 343/684] [D loss: 1.779594, acc: 0.761719, f1: 0.259105] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 344/684] [D loss: 1.771863, acc: 0.769531, f1: 0.259531] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 345/684] [D loss: 1.797897, acc: 0.744141, f1: 0.227913] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 346/684] [D loss: 1.772888, acc: 0.769531, f1: 0.288612] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 347/684] [D loss: 1.776392, acc: 0.765625, f1: 0.258231] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 348/684] [D loss: 1.759094, acc: 0.783203, f1: 0.259829] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 349/684] [D loss: 1.747386, acc: 0.794922, f1: 0.263101] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 350/684] [D loss: 1.766776, acc: 0.775391, f1: 0.237280] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 351/684] [D loss: 1.751499, acc: 0.791016, f1: 0.292009] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 352/684] [D loss: 1.793585, acc: 0.748047, f1: 0.231091] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 353/684] [D loss: 1.782668, acc: 0.759766, f1: 0.255692] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 354/684] [D loss: 1.776623, acc: 0.765625, f1: 0.284963] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 355/684] [D loss: 1.762422, acc: 0.779297, f1: 0.236853] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 356/684] [D loss: 1.762164, acc: 0.779297, f1: 0.258685] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 357/684] [D loss: 1.753117, acc: 0.789062, f1: 0.263223] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 358/684] [D loss: 1.754506, acc: 0.787109, f1: 0.259597] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 359/684] [D loss: 1.748860, acc: 0.792969, f1: 0.266789] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 360/684] [D loss: 1.766346, acc: 0.775391, f1: 0.260295] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 361/684] [D loss: 1.797983, acc: 0.744141, f1: 0.253596] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 362/684] [D loss: 1.774871, acc: 0.767578, f1: 0.235618] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 363/684] [D loss: 1.762671, acc: 0.779297, f1: 0.258739] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 364/684] [D loss: 1.778335, acc: 0.763672, f1: 0.257032] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 365/684] [D loss: 1.761624, acc: 0.781250, f1: 0.258334] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 366/684] [D loss: 1.774590, acc: 0.767578, f1: 0.257310] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 367/684] [D loss: 1.794571, acc: 0.748047, f1: 0.250952] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 368/684] [D loss: 1.800304, acc: 0.742188, f1: 0.251388] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 369/684] [D loss: 1.787403, acc: 0.753906, f1: 0.257268] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 370/684] [D loss: 1.759979, acc: 0.781250, f1: 0.259785] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 371/684] [D loss: 1.780426, acc: 0.761719, f1: 0.257110] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 372/684] [D loss: 1.788703, acc: 0.753906, f1: 0.250211] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 373/684] [D loss: 1.770884, acc: 0.771484, f1: 0.258309] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 374/684] [D loss: 1.776196, acc: 0.765625, f1: 0.289822] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 375/684] [D loss: 1.780297, acc: 0.761719, f1: 0.256392] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 376/684] [D loss: 1.792402, acc: 0.748047, f1: 0.232514] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 377/684] [D loss: 1.752804, acc: 0.789062, f1: 0.261592] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 378/684] [D loss: 1.766560, acc: 0.775391, f1: 0.289194] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 379/684] [D loss: 1.758649, acc: 0.783203, f1: 0.260876] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 380/684] [D loss: 1.799392, acc: 0.742188, f1: 0.279522] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 381/684] [D loss: 1.798391, acc: 0.744141, f1: 0.277666] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 382/684] [D loss: 1.768022, acc: 0.773438, f1: 0.231068] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 383/684] [D loss: 1.754591, acc: 0.787109, f1: 0.264754] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 384/684] [D loss: 1.770815, acc: 0.771484, f1: 0.233891] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 385/684] [D loss: 1.798253, acc: 0.744141, f1: 0.256607] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 386/684] [D loss: 1.792474, acc: 0.750000, f1: 0.253012] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 387/684] [D loss: 1.756026, acc: 0.785156, f1: 0.293360] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 388/684] [D loss: 1.743274, acc: 0.798828, f1: 0.296146] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 389/684] [D loss: 1.760925, acc: 0.781250, f1: 0.263622] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 390/684] [D loss: 1.749591, acc: 0.792969, f1: 0.263424] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 391/684] [D loss: 1.753126, acc: 0.789062, f1: 0.261756] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 392/684] [D loss: 1.764493, acc: 0.777344, f1: 0.292228] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 393/684] [D loss: 1.765010, acc: 0.777344, f1: 0.240529] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 394/684] [D loss: 1.788689, acc: 0.753906, f1: 0.284934] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 395/684] [D loss: 1.796752, acc: 0.746094, f1: 0.256573] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 396/684] [D loss: 1.764317, acc: 0.777344, f1: 0.260767] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 397/684] [D loss: 1.780799, acc: 0.761719, f1: 0.237085] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 398/684] [D loss: 1.766529, acc: 0.775391, f1: 0.291323] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 399/684] [D loss: 1.747124, acc: 0.794922, f1: 0.265618] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 400/684] [D loss: 1.770731, acc: 0.771484, f1: 0.236633] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 401/684] [D loss: 1.766300, acc: 0.775391, f1: 0.258560] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 402/684] [D loss: 1.776069, acc: 0.765625, f1: 0.259326] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 403/684] [D loss: 1.766692, acc: 0.775391, f1: 0.259071] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 404/684] [D loss: 1.756266, acc: 0.785156, f1: 0.293152] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 405/684] [D loss: 1.799011, acc: 0.742188, f1: 0.251938] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 406/684] [D loss: 1.747039, acc: 0.794922, f1: 0.262111] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 407/684] [D loss: 1.762796, acc: 0.779297, f1: 0.261132] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 408/684] [D loss: 1.782099, acc: 0.759766, f1: 0.255387] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 409/684] [D loss: 1.765140, acc: 0.777344, f1: 0.235666] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 410/684] [D loss: 1.772893, acc: 0.769531, f1: 0.287988] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 411/684] [D loss: 1.789950, acc: 0.751953, f1: 0.252989] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 412/684] [D loss: 1.776361, acc: 0.765625, f1: 0.258090] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 413/684] [D loss: 1.770197, acc: 0.771484, f1: 0.285664] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 414/684] [D loss: 1.778942, acc: 0.763672, f1: 0.230361] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 415/684] [D loss: 1.778922, acc: 0.763672, f1: 0.252862] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 416/684] [D loss: 1.769454, acc: 0.771484, f1: 0.257612] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 417/684] [D loss: 1.792112, acc: 0.750000, f1: 0.253584] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 418/684] [D loss: 1.758259, acc: 0.785156, f1: 0.257613] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 419/684] [D loss: 1.788144, acc: 0.753906, f1: 0.281219] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 420/684] [D loss: 1.783944, acc: 0.757812, f1: 0.258649] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 421/684] [D loss: 1.760711, acc: 0.781250, f1: 0.260949] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 422/684] [D loss: 1.754965, acc: 0.787109, f1: 0.261191] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 423/684] [D loss: 1.792686, acc: 0.750000, f1: 0.256012] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 424/684] [D loss: 1.782396, acc: 0.759766, f1: 0.257828] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 425/684] [D loss: 1.796035, acc: 0.746094, f1: 0.256570] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 426/684] [D loss: 1.749164, acc: 0.792969, f1: 0.264741] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 427/684] [D loss: 1.778700, acc: 0.763672, f1: 0.287432] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 428/684] [D loss: 1.763353, acc: 0.779297, f1: 0.260703] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 429/684] [D loss: 1.773468, acc: 0.769531, f1: 0.233101] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 430/684] [D loss: 1.790307, acc: 0.751953, f1: 0.253399] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 431/684] [D loss: 1.764949, acc: 0.777344, f1: 0.261327] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 432/684] [D loss: 1.774965, acc: 0.767578, f1: 0.259928] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 433/684] [D loss: 1.775140, acc: 0.767578, f1: 0.254582] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 434/684] [D loss: 1.782572, acc: 0.759766, f1: 0.285107] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 435/684] [D loss: 1.763073, acc: 0.779297, f1: 0.292599] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 436/684] [D loss: 1.778400, acc: 0.763672, f1: 0.257145] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 437/684] [D loss: 1.797661, acc: 0.744141, f1: 0.255844] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 438/684] [D loss: 1.780153, acc: 0.761719, f1: 0.255701] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 439/684] [D loss: 1.770380, acc: 0.771484, f1: 0.260564] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 440/684] [D loss: 1.770264, acc: 0.771484, f1: 0.261712] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 441/684] [D loss: 1.781996, acc: 0.759766, f1: 0.255365] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 442/684] [D loss: 1.758689, acc: 0.783203, f1: 0.261494] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 443/684] [D loss: 1.746886, acc: 0.794922, f1: 0.262252] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 444/684] [D loss: 1.770458, acc: 0.771484, f1: 0.284333] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 445/684] [D loss: 1.776179, acc: 0.765625, f1: 0.256911] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 446/684] [D loss: 1.761183, acc: 0.781250, f1: 0.237251] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 447/684] [D loss: 1.766663, acc: 0.775391, f1: 0.257285] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 448/684] [D loss: 1.773244, acc: 0.769531, f1: 0.255015] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 449/684] [D loss: 1.782124, acc: 0.759766, f1: 0.253063] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 450/684] [D loss: 1.786323, acc: 0.755859, f1: 0.257161] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 451/684] [D loss: 1.771269, acc: 0.771484, f1: 0.284384] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 452/684] [D loss: 1.798069, acc: 0.744141, f1: 0.229591] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 453/684] [D loss: 1.772886, acc: 0.769531, f1: 0.257583] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 454/684] [D loss: 1.767244, acc: 0.775391, f1: 0.287017] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 455/684] [D loss: 1.772996, acc: 0.769531, f1: 0.257260] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 456/684] [D loss: 1.747626, acc: 0.794922, f1: 0.261213] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 457/684] [D loss: 1.786020, acc: 0.755859, f1: 0.254803] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 458/684] [D loss: 1.755550, acc: 0.787109, f1: 0.289505] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 459/684] [D loss: 1.786224, acc: 0.757812, f1: 0.259460] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 460/684] [D loss: 1.768539, acc: 0.773438, f1: 0.261472] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 461/684] [D loss: 1.749990, acc: 0.792969, f1: 0.264108] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 462/684] [D loss: 1.764843, acc: 0.777344, f1: 0.292670] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 463/684] [D loss: 1.785760, acc: 0.755859, f1: 0.281884] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 464/684] [D loss: 1.768589, acc: 0.773438, f1: 0.261724] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 465/684] [D loss: 1.785842, acc: 0.755859, f1: 0.256931] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 466/684] [D loss: 1.805079, acc: 0.736328, f1: 0.232177] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 467/684] [D loss: 1.773701, acc: 0.767578, f1: 0.257603] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 468/684] [D loss: 1.772330, acc: 0.769531, f1: 0.259988] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 469/684] [D loss: 1.779407, acc: 0.761719, f1: 0.258639] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 470/684] [D loss: 1.804997, acc: 0.736328, f1: 0.251735] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 471/684] [D loss: 1.791764, acc: 0.750000, f1: 0.256723] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 472/684] [D loss: 1.789916, acc: 0.751953, f1: 0.258751] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 473/684] [D loss: 1.777871, acc: 0.763672, f1: 0.257145] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 474/684] [D loss: 1.785466, acc: 0.755859, f1: 0.286887] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 475/684] [D loss: 1.759097, acc: 0.783203, f1: 0.263955] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 476/684] [D loss: 1.776127, acc: 0.765625, f1: 0.288297] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 477/684] [D loss: 1.795861, acc: 0.746094, f1: 0.253973] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 478/684] [D loss: 1.790506, acc: 0.751953, f1: 0.285943] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 479/684] [D loss: 1.786140, acc: 0.755859, f1: 0.254792] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 480/684] [D loss: 1.797203, acc: 0.744141, f1: 0.253703] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 481/684] [D loss: 1.772344, acc: 0.769531, f1: 0.289593] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 482/684] [D loss: 1.770270, acc: 0.771484, f1: 0.261570] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 483/684] [D loss: 1.821468, acc: 0.720703, f1: 0.274877] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 484/684] [D loss: 1.802165, acc: 0.740234, f1: 0.253315] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 485/684] [D loss: 1.775988, acc: 0.765625, f1: 0.262045] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 486/684] [D loss: 1.791675, acc: 0.750000, f1: 0.257514] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 487/684] [D loss: 1.770504, acc: 0.771484, f1: 0.232623] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 488/684] [D loss: 1.744919, acc: 0.796875, f1: 0.261842] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 489/684] [D loss: 1.748227, acc: 0.792969, f1: 0.238945] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 490/684] [D loss: 1.749393, acc: 0.792969, f1: 0.261482] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 491/684] [D loss: 1.786102, acc: 0.755859, f1: 0.280992] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 492/684] [D loss: 1.756728, acc: 0.785156, f1: 0.290627] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 493/684] [D loss: 1.790044, acc: 0.751953, f1: 0.253448] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 494/684] [D loss: 1.766474, acc: 0.775391, f1: 0.286150] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 495/684] [D loss: 1.760964, acc: 0.781250, f1: 0.289698] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 496/684] [D loss: 1.761443, acc: 0.781250, f1: 0.260925] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 497/684] [D loss: 1.781838, acc: 0.759766, f1: 0.233255] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 498/684] [D loss: 1.789768, acc: 0.751953, f1: 0.231250] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 499/684] [D loss: 1.796773, acc: 0.744141, f1: 0.253529] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 500/684] [D loss: 1.783942, acc: 0.757812, f1: 0.234387] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 501/684] [D loss: 1.759089, acc: 0.783203, f1: 0.237717] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 502/684] [D loss: 1.781824, acc: 0.759766, f1: 0.258584] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 503/684] [D loss: 1.762708, acc: 0.779297, f1: 0.260892] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 504/684] [D loss: 1.783823, acc: 0.757812, f1: 0.255294] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 505/684] [D loss: 1.766669, acc: 0.775391, f1: 0.258254] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 506/684] [D loss: 1.770207, acc: 0.771484, f1: 0.258035] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 507/684] [D loss: 1.762928, acc: 0.779297, f1: 0.262356] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 508/684] [D loss: 1.760389, acc: 0.781250, f1: 0.261467] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 509/684] [D loss: 1.760825, acc: 0.781250, f1: 0.240074] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 510/684] [D loss: 1.804065, acc: 0.738281, f1: 0.227062] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 511/684] [D loss: 1.741858, acc: 0.800781, f1: 0.260030] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 512/684] [D loss: 1.766804, acc: 0.775391, f1: 0.261293] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 513/684] [D loss: 1.757000, acc: 0.785156, f1: 0.262291] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 514/684] [D loss: 1.741576, acc: 0.800781, f1: 0.262587] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 515/684] [D loss: 1.770282, acc: 0.771484, f1: 0.258537] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 516/684] [D loss: 1.789792, acc: 0.751953, f1: 0.254243] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 517/684] [D loss: 1.778377, acc: 0.763672, f1: 0.253227] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 518/684] [D loss: 1.774328, acc: 0.767578, f1: 0.258566] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 519/684] [D loss: 1.786680, acc: 0.755859, f1: 0.255008] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 520/684] [D loss: 1.786768, acc: 0.755859, f1: 0.257282] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 521/684] [D loss: 1.778095, acc: 0.763672, f1: 0.258557] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 522/684] [D loss: 1.786930, acc: 0.755859, f1: 0.230122] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 523/684] [D loss: 1.760828, acc: 0.781250, f1: 0.263167] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 524/684] [D loss: 1.768400, acc: 0.773438, f1: 0.260211] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 525/684] [D loss: 1.739538, acc: 0.802734, f1: 0.263858] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 526/684] [D loss: 1.733571, acc: 0.808594, f1: 0.296352] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 527/684] [D loss: 1.774387, acc: 0.767578, f1: 0.256125] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 528/684] [D loss: 1.784122, acc: 0.757812, f1: 0.256452] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 529/684] [D loss: 1.760618, acc: 0.781250, f1: 0.261518] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 530/684] [D loss: 1.766545, acc: 0.775391, f1: 0.262167] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 531/684] [D loss: 1.776737, acc: 0.765625, f1: 0.258121] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 532/684] [D loss: 1.786021, acc: 0.755859, f1: 0.284264] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 533/684] [D loss: 1.788579, acc: 0.753906, f1: 0.281319] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 534/684] [D loss: 1.754863, acc: 0.787109, f1: 0.262303] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 535/684] [D loss: 1.774366, acc: 0.767578, f1: 0.234553] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 536/684] [D loss: 1.782203, acc: 0.759766, f1: 0.282821] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 537/684] [D loss: 1.801339, acc: 0.740234, f1: 0.279853] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 538/684] [D loss: 1.762948, acc: 0.779297, f1: 0.261405] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 539/684] [D loss: 1.760950, acc: 0.781250, f1: 0.256920] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 540/684] [D loss: 1.764421, acc: 0.777344, f1: 0.287538] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 541/684] [D loss: 1.754877, acc: 0.787109, f1: 0.290216] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 542/684] [D loss: 1.766176, acc: 0.775391, f1: 0.259512] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 543/684] [D loss: 1.758175, acc: 0.783203, f1: 0.239769] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 544/684] [D loss: 1.733285, acc: 0.808594, f1: 0.266377] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 545/684] [D loss: 1.795862, acc: 0.746094, f1: 0.252092] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 546/684] [D loss: 1.756923, acc: 0.785156, f1: 0.235887] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 547/684] [D loss: 1.780187, acc: 0.761719, f1: 0.256127] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 548/684] [D loss: 1.762623, acc: 0.779297, f1: 0.258466] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 549/684] [D loss: 1.770467, acc: 0.771484, f1: 0.285471] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 550/684] [D loss: 1.762897, acc: 0.779297, f1: 0.259550] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 551/684] [D loss: 1.752891, acc: 0.789062, f1: 0.263207] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 552/684] [D loss: 1.780036, acc: 0.761719, f1: 0.283183] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 553/684] [D loss: 1.758564, acc: 0.783203, f1: 0.262241] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 554/684] [D loss: 1.768443, acc: 0.773438, f1: 0.255850] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 555/684] [D loss: 1.778513, acc: 0.763672, f1: 0.233751] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 556/684] [D loss: 1.763181, acc: 0.779297, f1: 0.257933] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 557/684] [D loss: 1.793645, acc: 0.748047, f1: 0.251104] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 558/684] [D loss: 1.784179, acc: 0.757812, f1: 0.360420] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 559/684] [D loss: 1.762833, acc: 0.779297, f1: 0.233830] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 560/684] [D loss: 1.770444, acc: 0.771484, f1: 0.284297] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 561/684] [D loss: 1.766300, acc: 0.775391, f1: 0.287025] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 562/684] [D loss: 1.766405, acc: 0.775391, f1: 0.260922] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 563/684] [D loss: 1.747336, acc: 0.794922, f1: 0.294208] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 564/684] [D loss: 1.768577, acc: 0.773438, f1: 0.258087] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 565/684] [D loss: 1.774650, acc: 0.767578, f1: 0.258174] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 566/684] [D loss: 1.758678, acc: 0.783203, f1: 0.292843] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 567/684] [D loss: 1.766256, acc: 0.775391, f1: 0.290574] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 568/684] [D loss: 1.775571, acc: 0.765625, f1: 0.260801] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 569/684] [D loss: 1.789457, acc: 0.751953, f1: 0.284742] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 570/684] [D loss: 1.768707, acc: 0.773438, f1: 0.259521] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 571/684] [D loss: 1.774686, acc: 0.767578, f1: 0.256656] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 572/684] [D loss: 1.778483, acc: 0.763672, f1: 0.260102] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 573/684] [D loss: 1.794291, acc: 0.748047, f1: 0.252640] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 574/684] [D loss: 1.739059, acc: 0.802734, f1: 0.264005] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 575/684] [D loss: 1.806290, acc: 0.736328, f1: 0.252914] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 576/684] [D loss: 1.778243, acc: 0.763672, f1: 0.257911] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 577/684] [D loss: 1.752965, acc: 0.789062, f1: 0.258198] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 578/684] [D loss: 1.756575, acc: 0.785156, f1: 0.289094] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 579/684] [D loss: 1.766377, acc: 0.775391, f1: 0.256311] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 580/684] [D loss: 1.788073, acc: 0.753906, f1: 0.254039] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 581/684] [D loss: 1.781781, acc: 0.759766, f1: 0.255673] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 582/684] [D loss: 1.764685, acc: 0.777344, f1: 0.261615] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 583/684] [D loss: 1.768630, acc: 0.773438, f1: 0.263155] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 584/684] [D loss: 1.753248, acc: 0.789062, f1: 0.262848] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 585/684] [D loss: 1.746995, acc: 0.794922, f1: 0.266146] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 586/684] [D loss: 1.764767, acc: 0.777344, f1: 0.262322] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 587/684] [D loss: 1.786803, acc: 0.755859, f1: 0.282784] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 588/684] [D loss: 1.745539, acc: 0.796875, f1: 0.262878] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 589/684] [D loss: 1.775133, acc: 0.767578, f1: 0.258405] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 590/684] [D loss: 1.744926, acc: 0.796875, f1: 0.264605] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 591/684] [D loss: 1.776639, acc: 0.765625, f1: 0.283265] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 592/684] [D loss: 1.752851, acc: 0.789062, f1: 0.290304] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 593/684] [D loss: 1.774871, acc: 0.767578, f1: 0.256135] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 594/684] [D loss: 1.741218, acc: 0.800781, f1: 0.292641] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 595/684] [D loss: 1.766694, acc: 0.775391, f1: 0.258658] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 596/684] [D loss: 1.770968, acc: 0.771484, f1: 0.254146] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 597/684] [D loss: 1.780548, acc: 0.761719, f1: 0.253309] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 598/684] [D loss: 1.776766, acc: 0.765625, f1: 0.259426] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 599/684] [D loss: 1.780677, acc: 0.761719, f1: 0.233246] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 600/684] [D loss: 1.776548, acc: 0.765625, f1: 0.252415] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 601/684] [D loss: 1.748724, acc: 0.792969, f1: 0.263158] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 602/684] [D loss: 1.770907, acc: 0.771484, f1: 0.256896] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 603/684] [D loss: 1.755155, acc: 0.787109, f1: 0.261538] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 604/684] [D loss: 1.758763, acc: 0.783203, f1: 0.263400] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 605/684] [D loss: 1.766735, acc: 0.775391, f1: 0.235817] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 606/684] [D loss: 1.739570, acc: 0.802734, f1: 0.296623] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 607/684] [D loss: 1.780428, acc: 0.761719, f1: 0.257047] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 608/684] [D loss: 1.758575, acc: 0.783203, f1: 0.262288] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 609/684] [D loss: 1.789644, acc: 0.751953, f1: 0.255377] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 610/684] [D loss: 1.763093, acc: 0.779297, f1: 0.290189] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 611/684] [D loss: 1.768761, acc: 0.773438, f1: 0.287181] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 612/684] [D loss: 1.759240, acc: 0.783203, f1: 0.262238] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 613/684] [D loss: 1.780295, acc: 0.761719, f1: 0.319523] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 614/684] [D loss: 1.755090, acc: 0.787109, f1: 0.265489] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 615/684] [D loss: 1.759557, acc: 0.783203, f1: 0.260558] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 616/684] [D loss: 1.784083, acc: 0.757812, f1: 0.253911] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 617/684] [D loss: 1.771066, acc: 0.771484, f1: 0.255552] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 618/684] [D loss: 1.773388, acc: 0.769531, f1: 0.286845] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 619/684] [D loss: 1.790461, acc: 0.751953, f1: 0.256946] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 620/684] [D loss: 1.759426, acc: 0.783203, f1: 0.265750] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 621/684] [D loss: 1.754670, acc: 0.787109, f1: 0.293340] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 622/684] [D loss: 1.735763, acc: 0.806641, f1: 0.262416] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 623/684] [D loss: 1.757389, acc: 0.785156, f1: 0.260484] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 624/684] [D loss: 1.766663, acc: 0.775391, f1: 0.291611] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 625/684] [D loss: 1.783959, acc: 0.757812, f1: 0.256941] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 626/684] [D loss: 1.780278, acc: 0.761719, f1: 0.257492] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 627/684] [D loss: 1.741977, acc: 0.800781, f1: 0.264467] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 628/684] [D loss: 1.780329, acc: 0.761719, f1: 0.256054] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 629/684] [D loss: 1.784288, acc: 0.757812, f1: 0.250945] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 630/684] [D loss: 1.754583, acc: 0.787109, f1: 0.288403] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 631/684] [D loss: 1.793830, acc: 0.748047, f1: 0.253918] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 632/684] [D loss: 1.765562, acc: 0.777344, f1: 0.259008] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 633/684] [D loss: 1.796427, acc: 0.746094, f1: 0.276414] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 634/684] [D loss: 1.757105, acc: 0.785156, f1: 0.288971] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 635/684] [D loss: 1.757534, acc: 0.785156, f1: 0.259990] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 636/684] [D loss: 1.755599, acc: 0.787109, f1: 0.259896] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 637/684] [D loss: 1.800492, acc: 0.742188, f1: 0.250650] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 638/684] [D loss: 1.775885, acc: 0.765625, f1: 0.255759] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 639/684] [D loss: 1.802073, acc: 0.740234, f1: 0.251847] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 640/684] [D loss: 1.792000, acc: 0.750000, f1: 0.280298] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 641/684] [D loss: 1.764935, acc: 0.777344, f1: 0.289403] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 642/684] [D loss: 1.758667, acc: 0.783203, f1: 0.259948] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 643/684] [D loss: 1.762521, acc: 0.779297, f1: 0.287396] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 644/684] [D loss: 1.748803, acc: 0.792969, f1: 0.262629] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 645/684] [D loss: 1.772468, acc: 0.769531, f1: 0.257114] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 646/684] [D loss: 1.776547, acc: 0.765625, f1: 0.256101] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 647/684] [D loss: 1.756843, acc: 0.785156, f1: 0.261803] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 648/684] [D loss: 1.772554, acc: 0.769531, f1: 0.257103] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 649/684] [D loss: 1.776706, acc: 0.765625, f1: 0.257094] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 650/684] [D loss: 1.784732, acc: 0.757812, f1: 0.254485] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 651/684] [D loss: 1.753189, acc: 0.789062, f1: 0.265392] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 652/684] [D loss: 1.757251, acc: 0.785156, f1: 0.260892] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 653/684] [D loss: 1.766841, acc: 0.775391, f1: 0.259678] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 654/684] [D loss: 1.756682, acc: 0.785156, f1: 0.259723] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 655/684] [D loss: 1.770984, acc: 0.771484, f1: 0.237756] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 656/684] [D loss: 1.751311, acc: 0.791016, f1: 0.263123] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 657/684] [D loss: 1.774861, acc: 0.767578, f1: 0.232420] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 658/684] [D loss: 1.778120, acc: 0.763672, f1: 0.284328] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 659/684] [D loss: 1.766422, acc: 0.775391, f1: 0.259975] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 660/684] [D loss: 1.786226, acc: 0.755859, f1: 0.282392] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 661/684] [D loss: 1.774513, acc: 0.767578, f1: 0.257331] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 662/684] [D loss: 1.755395, acc: 0.787109, f1: 0.260807] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 663/684] [D loss: 1.752465, acc: 0.789062, f1: 0.263521] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 664/684] [D loss: 1.767005, acc: 0.775391, f1: 0.290005] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 665/684] [D loss: 1.764384, acc: 0.777344, f1: 0.286745] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 666/684] [D loss: 1.790662, acc: 0.751953, f1: 0.256740] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 667/684] [D loss: 1.774031, acc: 0.767578, f1: 0.286083] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 668/684] [D loss: 1.779657, acc: 0.761719, f1: 0.251810] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 669/684] [D loss: 1.778647, acc: 0.763672, f1: 0.257587] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 670/684] [D loss: 1.793319, acc: 0.748047, f1: 0.251884] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 671/684] [D loss: 1.768443, acc: 0.773438, f1: 0.259871] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 672/684] [D loss: 1.780325, acc: 0.761719, f1: 0.255149] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 673/684] [D loss: 1.755175, acc: 0.787109, f1: 0.288606] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 674/684] [D loss: 1.784127, acc: 0.757812, f1: 0.282032] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 675/684] [D loss: 1.752837, acc: 0.789062, f1: 0.325768] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 676/684] [D loss: 1.766619, acc: 0.775391, f1: 0.285463] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 677/684] [D loss: 1.799899, acc: 0.742188, f1: 0.253036] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 678/684] [D loss: 1.780925, acc: 0.761719, f1: 0.256059] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 679/684] [D loss: 1.785905, acc: 0.755859, f1: 0.257419] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 680/684] [D loss: 1.745755, acc: 0.796875, f1: 0.238230] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 681/684] [D loss: 1.764996, acc: 0.777344, f1: 0.290437] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 682/684] [D loss: 1.747247, acc: 0.794922, f1: 0.376255] [G loss: -1.000000]\n",
      "[Epoch 0/5] [Batch 683/684] [D loss: 1.741182, acc: 0.800781, f1: 0.239895] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 0/684] [D loss: 1.745486, acc: 0.796875, f1: 0.292964] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 1/684] [D loss: 1.776636, acc: 0.765625, f1: 0.260093] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 2/684] [D loss: 1.778256, acc: 0.763672, f1: 0.256887] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 3/684] [D loss: 1.758964, acc: 0.783203, f1: 0.324114] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 4/684] [D loss: 1.774752, acc: 0.767578, f1: 0.259063] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 5/684] [D loss: 1.763230, acc: 0.779297, f1: 0.260120] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 6/684] [D loss: 1.780224, acc: 0.761719, f1: 0.285739] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 7/684] [D loss: 1.768709, acc: 0.773438, f1: 0.258125] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 8/684] [D loss: 1.763596, acc: 0.779297, f1: 0.261768] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 9/684] [D loss: 1.790073, acc: 0.751953, f1: 0.250797] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 10/684] [D loss: 1.776361, acc: 0.765625, f1: 0.233654] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 11/684] [D loss: 1.752876, acc: 0.789062, f1: 0.263434] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 12/684] [D loss: 1.772661, acc: 0.769531, f1: 0.260938] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 13/684] [D loss: 1.744287, acc: 0.796875, f1: 0.290936] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 14/684] [D loss: 1.804522, acc: 0.736328, f1: 0.252557] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 15/684] [D loss: 1.738006, acc: 0.804688, f1: 0.243342] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 16/684] [D loss: 1.764445, acc: 0.777344, f1: 0.262691] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 17/684] [D loss: 1.778689, acc: 0.763672, f1: 0.289822] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 18/684] [D loss: 1.773189, acc: 0.769531, f1: 0.285490] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 19/684] [D loss: 1.755144, acc: 0.787109, f1: 0.261468] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 20/684] [D loss: 1.782248, acc: 0.759766, f1: 0.233095] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 21/684] [D loss: 1.776355, acc: 0.765625, f1: 0.320802] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 22/684] [D loss: 1.770532, acc: 0.771484, f1: 0.287474] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 23/684] [D loss: 1.743895, acc: 0.798828, f1: 0.268228] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 24/684] [D loss: 1.761155, acc: 0.781250, f1: 0.263248] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 25/684] [D loss: 1.763938, acc: 0.777344, f1: 0.234891] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 26/684] [D loss: 1.758919, acc: 0.783203, f1: 0.258971] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 27/684] [D loss: 1.766679, acc: 0.775391, f1: 0.237874] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 28/684] [D loss: 1.782246, acc: 0.759766, f1: 0.255402] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 29/684] [D loss: 1.791595, acc: 0.750000, f1: 0.233068] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 30/684] [D loss: 1.763136, acc: 0.779297, f1: 0.291057] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 31/684] [D loss: 1.757488, acc: 0.785156, f1: 0.290812] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 32/684] [D loss: 1.790658, acc: 0.751953, f1: 0.250514] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 33/684] [D loss: 1.755642, acc: 0.787109, f1: 0.264048] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 34/684] [D loss: 1.772889, acc: 0.769531, f1: 0.257852] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 35/684] [D loss: 1.759102, acc: 0.783203, f1: 0.261654] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 36/684] [D loss: 1.764789, acc: 0.777344, f1: 0.233751] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 37/684] [D loss: 1.745513, acc: 0.796875, f1: 0.264134] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 38/684] [D loss: 1.764782, acc: 0.777344, f1: 0.258106] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 39/684] [D loss: 1.794426, acc: 0.748047, f1: 0.251106] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 40/684] [D loss: 1.754712, acc: 0.787109, f1: 0.293397] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 41/684] [D loss: 1.756906, acc: 0.785156, f1: 0.289426] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 42/684] [D loss: 1.772985, acc: 0.769531, f1: 0.329684] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 43/684] [D loss: 1.735444, acc: 0.806641, f1: 0.265340] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 44/684] [D loss: 1.774848, acc: 0.767578, f1: 0.323748] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 45/684] [D loss: 1.760886, acc: 0.781250, f1: 0.259713] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 46/684] [D loss: 1.755438, acc: 0.787109, f1: 0.290049] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 47/684] [D loss: 1.760877, acc: 0.781250, f1: 0.258937] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 48/684] [D loss: 1.792815, acc: 0.750000, f1: 0.258103] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 49/684] [D loss: 1.800365, acc: 0.742188, f1: 0.252538] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 50/684] [D loss: 1.764499, acc: 0.777344, f1: 0.288511] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 51/684] [D loss: 1.755461, acc: 0.787109, f1: 0.265990] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 52/684] [D loss: 1.745054, acc: 0.796875, f1: 0.262009] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 53/684] [D loss: 1.755517, acc: 0.787109, f1: 0.261797] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 54/684] [D loss: 1.774744, acc: 0.767578, f1: 0.288319] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 55/684] [D loss: 1.758984, acc: 0.783203, f1: 0.262310] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 56/684] [D loss: 1.747576, acc: 0.794922, f1: 0.261682] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 57/684] [D loss: 1.769043, acc: 0.773438, f1: 0.235007] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 58/684] [D loss: 1.791937, acc: 0.750000, f1: 0.251604] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 59/684] [D loss: 1.738995, acc: 0.802734, f1: 0.265611] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 60/684] [D loss: 1.751194, acc: 0.791016, f1: 0.295568] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 61/684] [D loss: 1.772654, acc: 0.769531, f1: 0.286807] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 62/684] [D loss: 1.781947, acc: 0.759766, f1: 0.255059] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 63/684] [D loss: 1.755049, acc: 0.787109, f1: 0.261212] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 64/684] [D loss: 1.749384, acc: 0.792969, f1: 0.261014] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 65/684] [D loss: 1.784552, acc: 0.757812, f1: 0.255484] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 66/684] [D loss: 1.764976, acc: 0.777344, f1: 0.259111] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 67/684] [D loss: 1.763368, acc: 0.779297, f1: 0.255580] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 68/684] [D loss: 1.792095, acc: 0.750000, f1: 0.252901] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 69/684] [D loss: 1.761471, acc: 0.781250, f1: 0.288709] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 70/684] [D loss: 1.774563, acc: 0.767578, f1: 0.236072] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 71/684] [D loss: 1.770326, acc: 0.771484, f1: 0.256387] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 72/684] [D loss: 1.766881, acc: 0.775391, f1: 0.257742] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 73/684] [D loss: 1.755281, acc: 0.787109, f1: 0.291841] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 74/684] [D loss: 1.733446, acc: 0.808594, f1: 0.296575] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 75/684] [D loss: 1.758963, acc: 0.783203, f1: 0.264556] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 76/684] [D loss: 1.756715, acc: 0.785156, f1: 0.261958] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 77/684] [D loss: 1.752697, acc: 0.789062, f1: 0.261678] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 78/684] [D loss: 1.752954, acc: 0.789062, f1: 0.264229] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 79/684] [D loss: 1.787970, acc: 0.753906, f1: 0.255736] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 80/684] [D loss: 1.774778, acc: 0.767578, f1: 0.258339] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 81/684] [D loss: 1.785777, acc: 0.755859, f1: 0.278309] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 82/684] [D loss: 1.783448, acc: 0.757812, f1: 0.254461] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 83/684] [D loss: 1.766407, acc: 0.775391, f1: 0.259246] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 84/684] [D loss: 1.743323, acc: 0.798828, f1: 0.295195] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 85/684] [D loss: 1.788565, acc: 0.753906, f1: 0.257313] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 86/684] [D loss: 1.774136, acc: 0.767578, f1: 0.254973] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 87/684] [D loss: 1.751124, acc: 0.791016, f1: 0.262082] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 88/684] [D loss: 1.797485, acc: 0.744141, f1: 0.253253] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 89/684] [D loss: 1.793738, acc: 0.748047, f1: 0.284198] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 90/684] [D loss: 1.792498, acc: 0.750000, f1: 0.285934] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 91/684] [D loss: 1.794162, acc: 0.748047, f1: 0.254110] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 92/684] [D loss: 1.774182, acc: 0.767578, f1: 0.258122] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 93/684] [D loss: 1.778230, acc: 0.763672, f1: 0.232213] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 94/684] [D loss: 1.761314, acc: 0.781250, f1: 0.261620] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 95/684] [D loss: 1.790378, acc: 0.751953, f1: 0.255267] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 96/684] [D loss: 1.780461, acc: 0.761719, f1: 0.255148] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 97/684] [D loss: 1.745619, acc: 0.796875, f1: 0.293092] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 98/684] [D loss: 1.772375, acc: 0.769531, f1: 0.259730] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 99/684] [D loss: 1.754883, acc: 0.787109, f1: 0.258593] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 100/684] [D loss: 1.764721, acc: 0.777344, f1: 0.289559] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 101/684] [D loss: 1.791663, acc: 0.750000, f1: 0.257772] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 102/684] [D loss: 1.768753, acc: 0.773438, f1: 0.257883] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 103/684] [D loss: 1.746865, acc: 0.794922, f1: 0.265465] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 104/684] [D loss: 1.741489, acc: 0.800781, f1: 0.265207] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 105/684] [D loss: 1.780320, acc: 0.761719, f1: 0.255992] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 106/684] [D loss: 1.766634, acc: 0.775391, f1: 0.290449] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 107/684] [D loss: 1.735243, acc: 0.806641, f1: 0.265926] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 108/684] [D loss: 1.768897, acc: 0.773438, f1: 0.289628] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 109/684] [D loss: 1.778937, acc: 0.763672, f1: 0.255484] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 110/684] [D loss: 1.753197, acc: 0.789062, f1: 0.262341] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 111/684] [D loss: 1.778361, acc: 0.763672, f1: 0.252878] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 112/684] [D loss: 1.764703, acc: 0.777344, f1: 0.260172] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 113/684] [D loss: 1.765302, acc: 0.777344, f1: 0.259055] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 114/684] [D loss: 1.761210, acc: 0.781250, f1: 0.236635] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 115/684] [D loss: 1.762742, acc: 0.779297, f1: 0.257503] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 116/684] [D loss: 1.772611, acc: 0.769531, f1: 0.287270] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 117/684] [D loss: 1.772873, acc: 0.769531, f1: 0.253169] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 118/684] [D loss: 1.758586, acc: 0.783203, f1: 0.288791] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 119/684] [D loss: 1.776090, acc: 0.765625, f1: 0.252753] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 120/684] [D loss: 1.758353, acc: 0.783203, f1: 0.259979] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 121/684] [D loss: 1.774288, acc: 0.767578, f1: 0.237622] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 122/684] [D loss: 1.803798, acc: 0.738281, f1: 0.246880] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 123/684] [D loss: 1.754642, acc: 0.787109, f1: 0.260202] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 124/684] [D loss: 1.786188, acc: 0.755859, f1: 0.254650] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 125/684] [D loss: 1.775607, acc: 0.765625, f1: 0.254329] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 126/684] [D loss: 1.739634, acc: 0.802734, f1: 0.240288] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 127/684] [D loss: 1.774856, acc: 0.767578, f1: 0.258475] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 128/684] [D loss: 1.763327, acc: 0.779297, f1: 0.286833] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 129/684] [D loss: 1.783460, acc: 0.757812, f1: 0.254661] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 130/684] [D loss: 1.753504, acc: 0.789062, f1: 0.265052] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 131/684] [D loss: 1.772547, acc: 0.769531, f1: 0.233012] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 132/684] [D loss: 1.770917, acc: 0.771484, f1: 0.262589] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 133/684] [D loss: 1.782157, acc: 0.759766, f1: 0.255574] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 134/684] [D loss: 1.756783, acc: 0.785156, f1: 0.292751] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 135/684] [D loss: 1.786114, acc: 0.755859, f1: 0.255287] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 136/684] [D loss: 1.786479, acc: 0.755859, f1: 0.227457] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 137/684] [D loss: 1.775826, acc: 0.765625, f1: 0.284936] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 138/684] [D loss: 1.772908, acc: 0.769531, f1: 0.286275] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 139/684] [D loss: 1.806858, acc: 0.734375, f1: 0.247858] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 140/684] [D loss: 1.754594, acc: 0.787109, f1: 0.259086] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 141/684] [D loss: 1.787971, acc: 0.753906, f1: 0.254512] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 142/684] [D loss: 1.766643, acc: 0.775391, f1: 0.258231] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 143/684] [D loss: 1.780066, acc: 0.761719, f1: 0.284880] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 144/684] [D loss: 1.760637, acc: 0.781250, f1: 0.290126] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 145/684] [D loss: 1.756641, acc: 0.785156, f1: 0.235727] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 146/684] [D loss: 1.764858, acc: 0.777344, f1: 0.291906] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 147/684] [D loss: 1.760637, acc: 0.781250, f1: 0.290341] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 148/684] [D loss: 1.752906, acc: 0.789062, f1: 0.294796] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 149/684] [D loss: 1.783910, acc: 0.757812, f1: 0.229025] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 150/684] [D loss: 1.760870, acc: 0.781250, f1: 0.283704] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 151/684] [D loss: 1.772586, acc: 0.769531, f1: 0.259168] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 152/684] [D loss: 1.778898, acc: 0.763672, f1: 0.256394] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 153/684] [D loss: 1.789565, acc: 0.751953, f1: 0.254689] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 154/684] [D loss: 1.796968, acc: 0.746094, f1: 0.250852] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 155/684] [D loss: 1.768679, acc: 0.773438, f1: 0.255830] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 156/684] [D loss: 1.779763, acc: 0.761719, f1: 0.285071] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 157/684] [D loss: 1.757089, acc: 0.785156, f1: 0.285619] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 158/684] [D loss: 1.770615, acc: 0.771484, f1: 0.260369] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 159/684] [D loss: 1.784699, acc: 0.757812, f1: 0.285856] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 160/684] [D loss: 1.783965, acc: 0.757812, f1: 0.251852] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 161/684] [D loss: 1.801881, acc: 0.740234, f1: 0.252700] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 162/684] [D loss: 1.783997, acc: 0.757812, f1: 0.255984] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 163/684] [D loss: 1.749131, acc: 0.792969, f1: 0.263901] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 164/684] [D loss: 1.795871, acc: 0.746094, f1: 0.252477] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 165/684] [D loss: 1.791879, acc: 0.750000, f1: 0.256418] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 166/684] [D loss: 1.782350, acc: 0.759766, f1: 0.257080] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 167/684] [D loss: 1.776040, acc: 0.765625, f1: 0.231952] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 168/684] [D loss: 1.766532, acc: 0.775391, f1: 0.260474] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 169/684] [D loss: 1.774836, acc: 0.767578, f1: 0.285116] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 170/684] [D loss: 1.776156, acc: 0.765625, f1: 0.285921] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 171/684] [D loss: 1.763134, acc: 0.779297, f1: 0.258411] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 172/684] [D loss: 1.785784, acc: 0.755859, f1: 0.252500] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 173/684] [D loss: 1.758981, acc: 0.783203, f1: 0.261182] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 174/684] [D loss: 1.764810, acc: 0.777344, f1: 0.236310] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 175/684] [D loss: 1.785743, acc: 0.755859, f1: 0.282465] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 176/684] [D loss: 1.749362, acc: 0.792969, f1: 0.329565] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 177/684] [D loss: 1.768766, acc: 0.773438, f1: 0.257396] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 178/684] [D loss: 1.764952, acc: 0.777344, f1: 0.260199] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 179/684] [D loss: 1.720114, acc: 0.822266, f1: 0.298709] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 180/684] [D loss: 1.772429, acc: 0.769531, f1: 0.234640] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 181/684] [D loss: 1.749377, acc: 0.792969, f1: 0.292662] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 182/684] [D loss: 1.780152, acc: 0.761719, f1: 0.256772] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 183/684] [D loss: 1.759310, acc: 0.783203, f1: 0.290601] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 184/684] [D loss: 1.788336, acc: 0.753906, f1: 0.280144] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 185/684] [D loss: 1.799888, acc: 0.742188, f1: 0.256437] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 186/684] [D loss: 1.739152, acc: 0.802734, f1: 0.263919] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 187/684] [D loss: 1.763013, acc: 0.779297, f1: 0.289149] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 188/684] [D loss: 1.790852, acc: 0.751953, f1: 0.254778] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 189/684] [D loss: 1.778394, acc: 0.763672, f1: 0.257751] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 190/684] [D loss: 1.747154, acc: 0.794922, f1: 0.263350] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 191/684] [D loss: 1.772700, acc: 0.769531, f1: 0.262693] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 192/684] [D loss: 1.768735, acc: 0.773438, f1: 0.258334] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 193/684] [D loss: 1.755440, acc: 0.787109, f1: 0.327332] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 194/684] [D loss: 1.747261, acc: 0.794922, f1: 0.264228] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 195/684] [D loss: 1.768966, acc: 0.773438, f1: 0.257088] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 196/684] [D loss: 1.776581, acc: 0.765625, f1: 0.233999] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 197/684] [D loss: 1.770591, acc: 0.771484, f1: 0.289503] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 198/684] [D loss: 1.754983, acc: 0.787109, f1: 0.240569] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 199/684] [D loss: 1.788120, acc: 0.753906, f1: 0.279101] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 200/684] [D loss: 1.768724, acc: 0.773438, f1: 0.232718] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 201/684] [D loss: 1.783170, acc: 0.759766, f1: 0.254178] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 202/684] [D loss: 1.776449, acc: 0.765625, f1: 0.258779] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 203/684] [D loss: 1.763366, acc: 0.779297, f1: 0.288737] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 204/684] [D loss: 1.779087, acc: 0.763672, f1: 0.253047] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 205/684] [D loss: 1.758923, acc: 0.783203, f1: 0.293862] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 206/684] [D loss: 1.755302, acc: 0.787109, f1: 0.260352] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 207/684] [D loss: 1.782337, acc: 0.759766, f1: 0.251487] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 208/684] [D loss: 1.773046, acc: 0.769531, f1: 0.253492] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 209/684] [D loss: 1.807816, acc: 0.734375, f1: 0.250627] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 210/684] [D loss: 1.757489, acc: 0.785156, f1: 0.238212] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 211/684] [D loss: 1.779838, acc: 0.765625, f1: 0.258166] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 212/684] [D loss: 1.784089, acc: 0.757812, f1: 0.256354] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 213/684] [D loss: 1.759416, acc: 0.783203, f1: 0.259142] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 214/684] [D loss: 1.788387, acc: 0.753906, f1: 0.254248] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 215/684] [D loss: 1.801896, acc: 0.740234, f1: 0.281964] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 216/684] [D loss: 1.753093, acc: 0.789062, f1: 0.263102] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 217/684] [D loss: 1.787868, acc: 0.753906, f1: 0.251815] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 218/684] [D loss: 1.774696, acc: 0.767578, f1: 0.258665] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 219/684] [D loss: 1.766824, acc: 0.775391, f1: 0.283034] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 220/684] [D loss: 1.779860, acc: 0.761719, f1: 0.255185] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 221/684] [D loss: 1.802210, acc: 0.740234, f1: 0.248047] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 222/684] [D loss: 1.789730, acc: 0.751953, f1: 0.255460] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 223/684] [D loss: 1.757060, acc: 0.785156, f1: 0.261475] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 224/684] [D loss: 1.751131, acc: 0.791016, f1: 0.263971] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 225/684] [D loss: 1.803858, acc: 0.738281, f1: 0.251784] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 226/684] [D loss: 1.792053, acc: 0.750000, f1: 0.230062] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 227/684] [D loss: 1.815517, acc: 0.726562, f1: 0.247789] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 228/684] [D loss: 1.792642, acc: 0.750000, f1: 0.254699] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 229/684] [D loss: 1.764985, acc: 0.777344, f1: 0.262086] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 230/684] [D loss: 1.774404, acc: 0.767578, f1: 0.257008] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 231/684] [D loss: 1.774424, acc: 0.767578, f1: 0.325264] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 232/684] [D loss: 1.768521, acc: 0.773438, f1: 0.259692] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 233/684] [D loss: 1.798123, acc: 0.744141, f1: 0.253178] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 234/684] [D loss: 1.790315, acc: 0.751953, f1: 0.250934] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 235/684] [D loss: 1.764604, acc: 0.777344, f1: 0.258773] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 236/684] [D loss: 1.731988, acc: 0.810547, f1: 0.268800] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 237/684] [D loss: 1.765156, acc: 0.777344, f1: 0.259534] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 238/684] [D loss: 1.760566, acc: 0.781250, f1: 0.239164] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 239/684] [D loss: 1.762800, acc: 0.779297, f1: 0.262753] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 240/684] [D loss: 1.799868, acc: 0.742188, f1: 0.247948] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 241/684] [D loss: 1.807340, acc: 0.734375, f1: 0.250931] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 242/684] [D loss: 1.776933, acc: 0.765625, f1: 0.230664] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 243/684] [D loss: 1.774646, acc: 0.767578, f1: 0.259253] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 244/684] [D loss: 1.774047, acc: 0.767578, f1: 0.257665] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 245/684] [D loss: 1.782001, acc: 0.759766, f1: 0.284061] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 246/684] [D loss: 1.755080, acc: 0.787109, f1: 0.330705] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 247/684] [D loss: 1.784812, acc: 0.757812, f1: 0.230247] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 248/684] [D loss: 1.757319, acc: 0.785156, f1: 0.289282] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 249/684] [D loss: 1.765620, acc: 0.777344, f1: 0.262246] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 250/684] [D loss: 1.771226, acc: 0.771484, f1: 0.258740] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 251/684] [D loss: 1.759603, acc: 0.783203, f1: 0.260585] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 252/684] [D loss: 1.749706, acc: 0.792969, f1: 0.262640] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 253/684] [D loss: 1.765200, acc: 0.777344, f1: 0.237024] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 254/684] [D loss: 1.802515, acc: 0.740234, f1: 0.251994] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 255/684] [D loss: 1.772871, acc: 0.769531, f1: 0.257380] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 256/684] [D loss: 1.763493, acc: 0.779297, f1: 0.288247] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 257/684] [D loss: 1.776979, acc: 0.765625, f1: 0.256109] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 258/684] [D loss: 1.763209, acc: 0.779297, f1: 0.325070] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 259/684] [D loss: 1.761670, acc: 0.781250, f1: 0.238453] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 260/684] [D loss: 1.774626, acc: 0.767578, f1: 0.288091] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 261/684] [D loss: 1.776172, acc: 0.765625, f1: 0.256182] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 262/684] [D loss: 1.731794, acc: 0.810547, f1: 0.294569] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 263/684] [D loss: 1.737702, acc: 0.804688, f1: 0.296465] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 264/684] [D loss: 1.760959, acc: 0.781250, f1: 0.237493] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 265/684] [D loss: 1.770768, acc: 0.771484, f1: 0.233296] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 266/684] [D loss: 1.747633, acc: 0.794922, f1: 0.289819] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 267/684] [D loss: 1.782598, acc: 0.759766, f1: 0.256623] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 268/684] [D loss: 1.797581, acc: 0.744141, f1: 0.280265] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 269/684] [D loss: 1.769125, acc: 0.773438, f1: 0.257637] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 270/684] [D loss: 1.782696, acc: 0.759766, f1: 0.258132] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 271/684] [D loss: 1.769171, acc: 0.773438, f1: 0.258984] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 272/684] [D loss: 1.755518, acc: 0.787109, f1: 0.291124] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 273/684] [D loss: 1.774576, acc: 0.767578, f1: 0.322272] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 274/684] [D loss: 1.759763, acc: 0.783203, f1: 0.264410] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 275/684] [D loss: 1.776412, acc: 0.765625, f1: 0.236534] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 276/684] [D loss: 1.759087, acc: 0.783203, f1: 0.261364] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 277/684] [D loss: 1.745918, acc: 0.796875, f1: 0.263537] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 278/684] [D loss: 1.796126, acc: 0.746094, f1: 0.278579] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 279/684] [D loss: 1.771119, acc: 0.771484, f1: 0.290133] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 280/684] [D loss: 1.751264, acc: 0.791016, f1: 0.288834] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 281/684] [D loss: 1.751259, acc: 0.791016, f1: 0.291836] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 282/684] [D loss: 1.779774, acc: 0.761719, f1: 0.285316] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 283/684] [D loss: 1.772896, acc: 0.769531, f1: 0.233919] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 284/684] [D loss: 1.770623, acc: 0.771484, f1: 0.288665] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 285/684] [D loss: 1.787423, acc: 0.755859, f1: 0.252865] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 286/684] [D loss: 1.786219, acc: 0.755859, f1: 0.251520] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 287/684] [D loss: 1.739915, acc: 0.802734, f1: 0.293311] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 288/684] [D loss: 1.767113, acc: 0.775391, f1: 0.258088] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 289/684] [D loss: 1.765150, acc: 0.777344, f1: 0.261670] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 290/684] [D loss: 1.768866, acc: 0.773438, f1: 0.288747] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 291/684] [D loss: 1.786030, acc: 0.755859, f1: 0.257720] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 292/684] [D loss: 1.788628, acc: 0.753906, f1: 0.229158] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 293/684] [D loss: 1.741603, acc: 0.800781, f1: 0.262064] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 294/684] [D loss: 1.755644, acc: 0.787109, f1: 0.263296] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 295/684] [D loss: 1.797721, acc: 0.744141, f1: 0.252373] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 296/684] [D loss: 1.739945, acc: 0.802734, f1: 0.372377] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 297/684] [D loss: 1.784554, acc: 0.757812, f1: 0.256362] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 298/684] [D loss: 1.769036, acc: 0.773438, f1: 0.260592] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 299/684] [D loss: 1.772680, acc: 0.769531, f1: 0.288369] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 300/684] [D loss: 1.788013, acc: 0.753906, f1: 0.249085] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 301/684] [D loss: 1.741382, acc: 0.800781, f1: 0.264374] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 302/684] [D loss: 1.782273, acc: 0.759766, f1: 0.257383] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 303/684] [D loss: 1.784424, acc: 0.757812, f1: 0.232384] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 304/684] [D loss: 1.758863, acc: 0.783203, f1: 0.264736] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 305/684] [D loss: 1.763155, acc: 0.779297, f1: 0.262095] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 306/684] [D loss: 1.771120, acc: 0.771484, f1: 0.252541] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 307/684] [D loss: 1.761079, acc: 0.781250, f1: 0.257927] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 308/684] [D loss: 1.799696, acc: 0.742188, f1: 0.252839] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 309/684] [D loss: 1.759179, acc: 0.783203, f1: 0.327159] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 310/684] [D loss: 1.761140, acc: 0.781250, f1: 0.257254] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 311/684] [D loss: 1.780370, acc: 0.761719, f1: 0.254988] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 312/684] [D loss: 1.784392, acc: 0.757812, f1: 0.233581] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 313/684] [D loss: 1.741550, acc: 0.800781, f1: 0.260556] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 314/684] [D loss: 1.762909, acc: 0.779297, f1: 0.259224] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 315/684] [D loss: 1.769035, acc: 0.773438, f1: 0.258499] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 316/684] [D loss: 1.780273, acc: 0.761719, f1: 0.255691] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 317/684] [D loss: 1.801902, acc: 0.740234, f1: 0.275388] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 318/684] [D loss: 1.771188, acc: 0.771484, f1: 0.237329] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 319/684] [D loss: 1.747391, acc: 0.794922, f1: 0.262458] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 320/684] [D loss: 1.780481, acc: 0.761719, f1: 0.255169] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 321/684] [D loss: 1.789641, acc: 0.751953, f1: 0.253458] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 322/684] [D loss: 1.760780, acc: 0.781250, f1: 0.237753] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 323/684] [D loss: 1.754970, acc: 0.787109, f1: 0.263462] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 324/684] [D loss: 1.766971, acc: 0.775391, f1: 0.288938] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 325/684] [D loss: 1.771012, acc: 0.771484, f1: 0.260058] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 326/684] [D loss: 1.786291, acc: 0.755859, f1: 0.256220] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 327/684] [D loss: 1.758749, acc: 0.783203, f1: 0.258950] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 328/684] [D loss: 1.782159, acc: 0.759766, f1: 0.256771] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 329/684] [D loss: 1.770806, acc: 0.771484, f1: 0.258511] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 330/684] [D loss: 1.811519, acc: 0.730469, f1: 0.273504] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 331/684] [D loss: 1.769191, acc: 0.773438, f1: 0.254231] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 332/684] [D loss: 1.755635, acc: 0.787109, f1: 0.257909] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 333/684] [D loss: 1.776877, acc: 0.765625, f1: 0.258206] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 334/684] [D loss: 1.767866, acc: 0.775391, f1: 0.233030] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 335/684] [D loss: 1.765467, acc: 0.777344, f1: 0.255377] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 336/684] [D loss: 1.769487, acc: 0.773438, f1: 0.285284] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 337/684] [D loss: 1.777064, acc: 0.765625, f1: 0.257373] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 338/684] [D loss: 1.813924, acc: 0.728516, f1: 0.248558] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 339/684] [D loss: 1.794614, acc: 0.748047, f1: 0.280118] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 340/684] [D loss: 1.780496, acc: 0.761719, f1: 0.256293] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 341/684] [D loss: 1.780444, acc: 0.761719, f1: 0.283460] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 342/684] [D loss: 1.739712, acc: 0.802734, f1: 0.262892] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 343/684] [D loss: 1.806195, acc: 0.736328, f1: 0.226134] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 344/684] [D loss: 1.735799, acc: 0.806641, f1: 0.266251] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 345/684] [D loss: 1.756989, acc: 0.785156, f1: 0.289892] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 346/684] [D loss: 1.795357, acc: 0.746094, f1: 0.233785] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 347/684] [D loss: 1.780755, acc: 0.761719, f1: 0.232053] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 348/684] [D loss: 1.784320, acc: 0.757812, f1: 0.255196] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 349/684] [D loss: 1.759315, acc: 0.783203, f1: 0.262226] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 350/684] [D loss: 1.763376, acc: 0.779297, f1: 0.261532] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 351/684] [D loss: 1.767193, acc: 0.775391, f1: 0.289109] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 352/684] [D loss: 1.794113, acc: 0.748047, f1: 0.254213] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 353/684] [D loss: 1.741233, acc: 0.800781, f1: 0.292937] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 354/684] [D loss: 1.796106, acc: 0.746094, f1: 0.253696] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 355/684] [D loss: 1.781055, acc: 0.761719, f1: 0.286984] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 356/684] [D loss: 1.778542, acc: 0.763672, f1: 0.253932] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 357/684] [D loss: 1.764856, acc: 0.777344, f1: 0.258597] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 358/684] [D loss: 1.756948, acc: 0.785156, f1: 0.263750] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 359/684] [D loss: 1.773446, acc: 0.769531, f1: 0.279114] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 360/684] [D loss: 1.742598, acc: 0.798828, f1: 0.264095] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 361/684] [D loss: 1.769231, acc: 0.773438, f1: 0.233082] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 362/684] [D loss: 1.776911, acc: 0.765625, f1: 0.255116] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 363/684] [D loss: 1.768567, acc: 0.773438, f1: 0.259038] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 364/684] [D loss: 1.763327, acc: 0.779297, f1: 0.236957] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 365/684] [D loss: 1.778608, acc: 0.763672, f1: 0.259524] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 366/684] [D loss: 1.789092, acc: 0.753906, f1: 0.256032] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 367/684] [D loss: 1.776572, acc: 0.765625, f1: 0.235530] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 368/684] [D loss: 1.794070, acc: 0.748047, f1: 0.231549] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 369/684] [D loss: 1.789841, acc: 0.751953, f1: 0.254399] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 370/684] [D loss: 1.766444, acc: 0.775391, f1: 0.258577] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 371/684] [D loss: 1.776283, acc: 0.765625, f1: 0.254019] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 372/684] [D loss: 1.787553, acc: 0.753906, f1: 0.255270] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 373/684] [D loss: 1.764859, acc: 0.777344, f1: 0.256302] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 374/684] [D loss: 1.791714, acc: 0.750000, f1: 0.251162] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 375/684] [D loss: 1.782720, acc: 0.759766, f1: 0.284299] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 376/684] [D loss: 1.739833, acc: 0.802734, f1: 0.266479] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 377/684] [D loss: 1.763088, acc: 0.779297, f1: 0.259699] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 378/684] [D loss: 1.786232, acc: 0.755859, f1: 0.255371] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 379/684] [D loss: 1.753859, acc: 0.789062, f1: 0.293302] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 380/684] [D loss: 1.741470, acc: 0.800781, f1: 0.294978] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 381/684] [D loss: 1.769074, acc: 0.773438, f1: 0.258499] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 382/684] [D loss: 1.772584, acc: 0.769531, f1: 0.250609] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 383/684] [D loss: 1.781239, acc: 0.761719, f1: 0.286044] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 384/684] [D loss: 1.775057, acc: 0.767578, f1: 0.258387] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 385/684] [D loss: 1.775338, acc: 0.767578, f1: 0.235520] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 386/684] [D loss: 1.755921, acc: 0.787109, f1: 0.293398] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 387/684] [D loss: 1.769405, acc: 0.773438, f1: 0.261356] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 388/684] [D loss: 1.759371, acc: 0.783203, f1: 0.261364] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 389/684] [D loss: 1.765597, acc: 0.777344, f1: 0.258542] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 390/684] [D loss: 1.769373, acc: 0.773438, f1: 0.260721] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 391/684] [D loss: 1.759716, acc: 0.783203, f1: 0.261329] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 392/684] [D loss: 1.726506, acc: 0.816406, f1: 0.265707] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 393/684] [D loss: 1.759720, acc: 0.783203, f1: 0.262162] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 394/684] [D loss: 1.789763, acc: 0.751953, f1: 0.280512] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 395/684] [D loss: 1.788534, acc: 0.753906, f1: 0.255117] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 396/684] [D loss: 1.765193, acc: 0.777344, f1: 0.322580] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 397/684] [D loss: 1.784316, acc: 0.757812, f1: 0.256704] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 398/684] [D loss: 1.781118, acc: 0.761719, f1: 0.320201] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 399/684] [D loss: 1.750914, acc: 0.791016, f1: 0.259867] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 400/684] [D loss: 1.774423, acc: 0.767578, f1: 0.283698] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 401/684] [D loss: 1.743143, acc: 0.798828, f1: 0.265386] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 402/684] [D loss: 1.780289, acc: 0.761719, f1: 0.232748] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 403/684] [D loss: 1.770954, acc: 0.771484, f1: 0.233339] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 404/684] [D loss: 1.749322, acc: 0.792969, f1: 0.290989] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 405/684] [D loss: 1.778276, acc: 0.763672, f1: 0.256081] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 406/684] [D loss: 1.778839, acc: 0.763672, f1: 0.257487] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 407/684] [D loss: 1.771240, acc: 0.771484, f1: 0.254898] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 408/684] [D loss: 1.765623, acc: 0.777344, f1: 0.257048] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 409/684] [D loss: 1.769266, acc: 0.773438, f1: 0.235710] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 410/684] [D loss: 1.798762, acc: 0.744141, f1: 0.247869] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 411/684] [D loss: 1.794797, acc: 0.748047, f1: 0.281575] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 412/684] [D loss: 1.759393, acc: 0.783203, f1: 0.259503] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 413/684] [D loss: 1.767316, acc: 0.775391, f1: 0.287567] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 414/684] [D loss: 1.765304, acc: 0.777344, f1: 0.261006] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 415/684] [D loss: 1.769421, acc: 0.773438, f1: 0.256060] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 416/684] [D loss: 1.763505, acc: 0.779297, f1: 0.261146] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 417/684] [D loss: 1.767323, acc: 0.775391, f1: 0.257625] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 418/684] [D loss: 1.755599, acc: 0.787109, f1: 0.262535] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 419/684] [D loss: 1.777205, acc: 0.765625, f1: 0.253822] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 420/684] [D loss: 1.782773, acc: 0.759766, f1: 0.253782] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 421/684] [D loss: 1.776341, acc: 0.765625, f1: 0.256955] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 422/684] [D loss: 1.762582, acc: 0.779297, f1: 0.261287] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 423/684] [D loss: 1.769008, acc: 0.773438, f1: 0.324138] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 424/684] [D loss: 1.778356, acc: 0.763672, f1: 0.285099] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 425/684] [D loss: 1.766767, acc: 0.775391, f1: 0.262133] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 426/684] [D loss: 1.789927, acc: 0.751953, f1: 0.252166] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 427/684] [D loss: 1.815541, acc: 0.726562, f1: 0.250675] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 428/684] [D loss: 1.763082, acc: 0.779297, f1: 0.286150] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 429/684] [D loss: 1.790500, acc: 0.751953, f1: 0.256496] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 430/684] [D loss: 1.777814, acc: 0.763672, f1: 0.255076] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 431/684] [D loss: 1.765239, acc: 0.777344, f1: 0.262419] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 432/684] [D loss: 1.780720, acc: 0.761719, f1: 0.255455] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 433/684] [D loss: 1.765089, acc: 0.777344, f1: 0.258977] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 434/684] [D loss: 1.777092, acc: 0.765625, f1: 0.287327] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 435/684] [D loss: 1.755749, acc: 0.787109, f1: 0.263083] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 436/684] [D loss: 1.763722, acc: 0.779297, f1: 0.235283] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 437/684] [D loss: 1.773976, acc: 0.767578, f1: 0.260086] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 438/684] [D loss: 1.780652, acc: 0.761719, f1: 0.255410] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 439/684] [D loss: 1.767283, acc: 0.775391, f1: 0.258749] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 440/684] [D loss: 1.777123, acc: 0.765625, f1: 0.232307] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 441/684] [D loss: 1.797585, acc: 0.744141, f1: 0.229800] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 442/684] [D loss: 1.784153, acc: 0.757812, f1: 0.285343] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 443/684] [D loss: 1.769038, acc: 0.773438, f1: 0.259324] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 444/684] [D loss: 1.782276, acc: 0.759766, f1: 0.258031] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 445/684] [D loss: 1.787766, acc: 0.753906, f1: 0.254653] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 446/684] [D loss: 1.776420, acc: 0.765625, f1: 0.258387] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 447/684] [D loss: 1.758667, acc: 0.783203, f1: 0.290738] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 448/684] [D loss: 1.747295, acc: 0.794922, f1: 0.261941] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 449/684] [D loss: 1.767484, acc: 0.775391, f1: 0.321031] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 450/684] [D loss: 1.729582, acc: 0.812500, f1: 0.299787] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 451/684] [D loss: 1.778446, acc: 0.763672, f1: 0.257170] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 452/684] [D loss: 1.758280, acc: 0.783203, f1: 0.262300] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 453/684] [D loss: 1.778912, acc: 0.763672, f1: 0.257092] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 454/684] [D loss: 1.767227, acc: 0.775391, f1: 0.255906] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 455/684] [D loss: 1.762855, acc: 0.779297, f1: 0.262119] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 456/684] [D loss: 1.751116, acc: 0.791016, f1: 0.290155] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 457/684] [D loss: 1.789771, acc: 0.751953, f1: 0.282882] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 458/684] [D loss: 1.772165, acc: 0.769531, f1: 0.259815] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 459/684] [D loss: 1.809717, acc: 0.732422, f1: 0.252072] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 460/684] [D loss: 1.776161, acc: 0.765625, f1: 0.257488] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 461/684] [D loss: 1.792322, acc: 0.750000, f1: 0.249983] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 462/684] [D loss: 1.788183, acc: 0.753906, f1: 0.316200] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 463/684] [D loss: 1.784470, acc: 0.757812, f1: 0.278686] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 464/684] [D loss: 1.796594, acc: 0.746094, f1: 0.283902] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 465/684] [D loss: 1.779084, acc: 0.763672, f1: 0.258656] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 466/684] [D loss: 1.775007, acc: 0.767578, f1: 0.254651] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 467/684] [D loss: 1.758982, acc: 0.783203, f1: 0.233213] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 468/684] [D loss: 1.777220, acc: 0.765625, f1: 0.259721] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 469/684] [D loss: 1.771490, acc: 0.771484, f1: 0.260812] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 470/684] [D loss: 1.764898, acc: 0.777344, f1: 0.258032] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 471/684] [D loss: 1.765064, acc: 0.777344, f1: 0.258650] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 472/684] [D loss: 1.768598, acc: 0.773438, f1: 0.258926] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 473/684] [D loss: 1.765424, acc: 0.777344, f1: 0.286609] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 474/684] [D loss: 1.820090, acc: 0.722656, f1: 0.277550] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 475/684] [D loss: 1.773423, acc: 0.769531, f1: 0.287382] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 476/684] [D loss: 1.788877, acc: 0.753906, f1: 0.254816] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 477/684] [D loss: 1.753894, acc: 0.789062, f1: 0.239409] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 478/684] [D loss: 1.755483, acc: 0.787109, f1: 0.289697] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 479/684] [D loss: 1.744113, acc: 0.798828, f1: 0.266943] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 480/684] [D loss: 1.783189, acc: 0.759766, f1: 0.232253] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 481/684] [D loss: 1.738216, acc: 0.804688, f1: 0.266439] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 482/684] [D loss: 1.765413, acc: 0.777344, f1: 0.257844] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 483/684] [D loss: 1.781180, acc: 0.761719, f1: 0.259954] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 484/684] [D loss: 1.755108, acc: 0.787109, f1: 0.290827] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 485/684] [D loss: 1.772296, acc: 0.769531, f1: 0.288967] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 486/684] [D loss: 1.800456, acc: 0.742188, f1: 0.252204] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 487/684] [D loss: 1.759178, acc: 0.783203, f1: 0.291617] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 488/684] [D loss: 1.777370, acc: 0.765625, f1: 0.258740] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 489/684] [D loss: 1.735484, acc: 0.806641, f1: 0.265116] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 490/684] [D loss: 1.784411, acc: 0.757812, f1: 0.259679] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 491/684] [D loss: 1.785641, acc: 0.755859, f1: 0.283804] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 492/684] [D loss: 1.769350, acc: 0.773438, f1: 0.289961] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 493/684] [D loss: 1.772878, acc: 0.769531, f1: 0.257684] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 494/684] [D loss: 1.802046, acc: 0.740234, f1: 0.252931] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 495/684] [D loss: 1.765105, acc: 0.777344, f1: 0.258631] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 496/684] [D loss: 1.745944, acc: 0.796875, f1: 0.295953] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 497/684] [D loss: 1.784638, acc: 0.757812, f1: 0.254426] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 498/684] [D loss: 1.774967, acc: 0.767578, f1: 0.254014] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 499/684] [D loss: 1.779190, acc: 0.763672, f1: 0.255716] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 500/684] [D loss: 1.745588, acc: 0.796875, f1: 0.264124] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 501/684] [D loss: 1.755793, acc: 0.787109, f1: 0.261758] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 502/684] [D loss: 1.800523, acc: 0.742188, f1: 0.251138] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 503/684] [D loss: 1.771503, acc: 0.771484, f1: 0.257996] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 504/684] [D loss: 1.789035, acc: 0.753906, f1: 0.279822] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 505/684] [D loss: 1.777355, acc: 0.765625, f1: 0.255506] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 506/684] [D loss: 1.759472, acc: 0.783203, f1: 0.259410] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 507/684] [D loss: 1.788840, acc: 0.753906, f1: 0.255155] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 508/684] [D loss: 1.781055, acc: 0.761719, f1: 0.259825] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 509/684] [D loss: 1.753488, acc: 0.789062, f1: 0.289459] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 510/684] [D loss: 1.807544, acc: 0.734375, f1: 0.224302] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 511/684] [D loss: 1.778683, acc: 0.763672, f1: 0.256805] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 512/684] [D loss: 1.757182, acc: 0.785156, f1: 0.259385] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 513/684] [D loss: 1.774506, acc: 0.767578, f1: 0.235312] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 514/684] [D loss: 1.767052, acc: 0.775391, f1: 0.288834] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 515/684] [D loss: 1.786264, acc: 0.755859, f1: 0.250942] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 516/684] [D loss: 1.765381, acc: 0.777344, f1: 0.259820] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 517/684] [D loss: 1.828991, acc: 0.712891, f1: 0.247974] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 518/684] [D loss: 1.774999, acc: 0.767578, f1: 0.253915] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 519/684] [D loss: 1.764496, acc: 0.777344, f1: 0.261155] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 520/684] [D loss: 1.773332, acc: 0.769531, f1: 0.286938] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 521/684] [D loss: 1.768546, acc: 0.773438, f1: 0.259324] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 522/684] [D loss: 1.749326, acc: 0.792969, f1: 0.262005] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 523/684] [D loss: 1.739649, acc: 0.802734, f1: 0.266715] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 524/684] [D loss: 1.772821, acc: 0.769531, f1: 0.258608] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 525/684] [D loss: 1.777250, acc: 0.765625, f1: 0.261686] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 526/684] [D loss: 1.779195, acc: 0.763672, f1: 0.255464] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 527/684] [D loss: 1.807247, acc: 0.734375, f1: 0.225671] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 528/684] [D loss: 1.805671, acc: 0.734375, f1: 0.241638] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 529/684] [D loss: 1.766603, acc: 0.775391, f1: 0.287773] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 530/684] [D loss: 1.773351, acc: 0.769531, f1: 0.257981] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 531/684] [D loss: 1.774417, acc: 0.767578, f1: 0.233905] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 532/684] [D loss: 1.759428, acc: 0.783203, f1: 0.262653] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 533/684] [D loss: 1.817496, acc: 0.724609, f1: 0.246099] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 534/684] [D loss: 1.782522, acc: 0.759766, f1: 0.253610] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 535/684] [D loss: 1.777176, acc: 0.765625, f1: 0.251199] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 536/684] [D loss: 1.794684, acc: 0.748047, f1: 0.248418] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 537/684] [D loss: 1.771499, acc: 0.771484, f1: 0.256034] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 538/684] [D loss: 1.788269, acc: 0.753906, f1: 0.281800] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 539/684] [D loss: 1.757783, acc: 0.785156, f1: 0.259751] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 540/684] [D loss: 1.751111, acc: 0.791016, f1: 0.290722] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 541/684] [D loss: 1.765617, acc: 0.777344, f1: 0.259043] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 542/684] [D loss: 1.775335, acc: 0.767578, f1: 0.258372] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 543/684] [D loss: 1.749918, acc: 0.792969, f1: 0.263742] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 544/684] [D loss: 1.761687, acc: 0.781250, f1: 0.260036] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 545/684] [D loss: 1.769473, acc: 0.773438, f1: 0.255205] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 546/684] [D loss: 1.779304, acc: 0.763672, f1: 0.283353] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 547/684] [D loss: 1.755832, acc: 0.787109, f1: 0.293764] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 548/684] [D loss: 1.748105, acc: 0.794922, f1: 0.292506] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 549/684] [D loss: 1.794627, acc: 0.748047, f1: 0.253802] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 550/684] [D loss: 1.769598, acc: 0.773438, f1: 0.229190] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 551/684] [D loss: 1.753975, acc: 0.789062, f1: 0.262251] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 552/684] [D loss: 1.751946, acc: 0.791016, f1: 0.262139] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 553/684] [D loss: 1.782976, acc: 0.759766, f1: 0.282829] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 554/684] [D loss: 1.786835, acc: 0.755859, f1: 0.255347] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 555/684] [D loss: 1.771442, acc: 0.771484, f1: 0.233399] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 556/684] [D loss: 1.777365, acc: 0.765625, f1: 0.257178] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 557/684] [D loss: 1.787124, acc: 0.755859, f1: 0.253649] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 558/684] [D loss: 1.765666, acc: 0.777344, f1: 0.257232] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 559/684] [D loss: 1.767588, acc: 0.775391, f1: 0.255737] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 560/684] [D loss: 1.777383, acc: 0.765625, f1: 0.254319] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 561/684] [D loss: 1.765623, acc: 0.777344, f1: 0.262633] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 562/684] [D loss: 1.763714, acc: 0.779297, f1: 0.259840] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 563/684] [D loss: 1.808603, acc: 0.734375, f1: 0.228534] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 564/684] [D loss: 1.796822, acc: 0.746094, f1: 0.253840] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 565/684] [D loss: 1.790862, acc: 0.751953, f1: 0.230547] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 566/684] [D loss: 1.777380, acc: 0.765625, f1: 0.255242] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 567/684] [D loss: 1.800839, acc: 0.742188, f1: 0.250035] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 568/684] [D loss: 1.759828, acc: 0.783203, f1: 0.261453] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 569/684] [D loss: 1.755663, acc: 0.787109, f1: 0.262267] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 570/684] [D loss: 1.771764, acc: 0.771484, f1: 0.259431] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 571/684] [D loss: 1.767274, acc: 0.775391, f1: 0.261696] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 572/684] [D loss: 1.745777, acc: 0.796875, f1: 0.263933] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 573/684] [D loss: 1.788470, acc: 0.753906, f1: 0.231441] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 574/684] [D loss: 1.776591, acc: 0.765625, f1: 0.259850] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 575/684] [D loss: 1.776892, acc: 0.765625, f1: 0.252193] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 576/684] [D loss: 1.773397, acc: 0.769531, f1: 0.257461] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 577/684] [D loss: 1.758986, acc: 0.783203, f1: 0.262406] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 578/684] [D loss: 1.763325, acc: 0.779297, f1: 0.283632] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 579/684] [D loss: 1.768765, acc: 0.773438, f1: 0.254600] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 580/684] [D loss: 1.745553, acc: 0.796875, f1: 0.261656] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 581/684] [D loss: 1.796160, acc: 0.746094, f1: 0.282061] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 582/684] [D loss: 1.784611, acc: 0.757812, f1: 0.285359] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 583/684] [D loss: 1.794545, acc: 0.748047, f1: 0.282654] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 584/684] [D loss: 1.784781, acc: 0.757812, f1: 0.258038] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 585/684] [D loss: 1.776965, acc: 0.765625, f1: 0.287147] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 586/684] [D loss: 1.792448, acc: 0.750000, f1: 0.254606] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 587/684] [D loss: 1.759767, acc: 0.783203, f1: 0.261218] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 588/684] [D loss: 1.767308, acc: 0.775391, f1: 0.258060] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 589/684] [D loss: 1.766908, acc: 0.775391, f1: 0.261321] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 590/684] [D loss: 1.732377, acc: 0.810547, f1: 0.297366] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 591/684] [D loss: 1.765670, acc: 0.777344, f1: 0.289261] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 592/684] [D loss: 1.763550, acc: 0.779297, f1: 0.239111] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 593/684] [D loss: 1.772832, acc: 0.769531, f1: 0.370505] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 594/684] [D loss: 1.769577, acc: 0.773438, f1: 0.285650] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 595/684] [D loss: 1.783122, acc: 0.759766, f1: 0.256724] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 596/684] [D loss: 1.777274, acc: 0.765625, f1: 0.233815] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 597/684] [D loss: 1.732432, acc: 0.810547, f1: 0.298270] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 598/684] [D loss: 1.773444, acc: 0.769531, f1: 0.259163] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 599/684] [D loss: 1.773323, acc: 0.769531, f1: 0.286737] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 600/684] [D loss: 1.790949, acc: 0.751953, f1: 0.255713] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 601/684] [D loss: 1.763721, acc: 0.779297, f1: 0.261491] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 602/684] [D loss: 1.791049, acc: 0.751953, f1: 0.281880] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 603/684] [D loss: 1.783111, acc: 0.759766, f1: 0.256766] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 604/684] [D loss: 1.759812, acc: 0.783203, f1: 0.262275] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 605/684] [D loss: 1.796861, acc: 0.746094, f1: 0.252837] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 606/684] [D loss: 1.757864, acc: 0.785156, f1: 0.262588] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 607/684] [D loss: 1.781221, acc: 0.761719, f1: 0.256048] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 608/684] [D loss: 1.759763, acc: 0.783203, f1: 0.259559] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 609/684] [D loss: 1.773341, acc: 0.769531, f1: 0.285489] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 610/684] [D loss: 1.763676, acc: 0.779297, f1: 0.235235] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 611/684] [D loss: 1.786924, acc: 0.755859, f1: 0.254438] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 612/684] [D loss: 1.771546, acc: 0.771484, f1: 0.237531] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 613/684] [D loss: 1.779336, acc: 0.763672, f1: 0.255724] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 614/684] [D loss: 1.753966, acc: 0.789062, f1: 0.289072] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 615/684] [D loss: 1.761687, acc: 0.781250, f1: 0.261310] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 616/684] [D loss: 1.769598, acc: 0.773438, f1: 0.257855] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 617/684] [D loss: 1.806550, acc: 0.736328, f1: 0.227984] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 618/684] [D loss: 1.787177, acc: 0.755859, f1: 0.254445] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 619/684] [D loss: 1.783040, acc: 0.759766, f1: 0.286343] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 620/684] [D loss: 1.783167, acc: 0.759766, f1: 0.255103] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 621/684] [D loss: 1.776444, acc: 0.765625, f1: 0.258540] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 622/684] [D loss: 1.740304, acc: 0.802734, f1: 0.264879] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 623/684] [D loss: 1.755927, acc: 0.787109, f1: 0.259618] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 624/684] [D loss: 1.777351, acc: 0.765625, f1: 0.285533] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 625/684] [D loss: 1.804724, acc: 0.738281, f1: 0.281222] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 626/684] [D loss: 1.787166, acc: 0.755859, f1: 0.252434] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 627/684] [D loss: 1.793040, acc: 0.750000, f1: 0.283201] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 628/684] [D loss: 1.777215, acc: 0.765625, f1: 0.237234] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 629/684] [D loss: 1.763744, acc: 0.779297, f1: 0.288650] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 630/684] [D loss: 1.753920, acc: 0.789062, f1: 0.264328] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 631/684] [D loss: 1.759837, acc: 0.783203, f1: 0.264906] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 632/684] [D loss: 1.769430, acc: 0.773438, f1: 0.291203] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 633/684] [D loss: 1.769547, acc: 0.773438, f1: 0.236127] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 634/684] [D loss: 1.773419, acc: 0.769531, f1: 0.235767] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 635/684] [D loss: 1.757885, acc: 0.785156, f1: 0.288410] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 636/684] [D loss: 1.777390, acc: 0.765625, f1: 0.233612] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 637/684] [D loss: 1.759593, acc: 0.783203, f1: 0.238665] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 638/684] [D loss: 1.787141, acc: 0.755859, f1: 0.256921] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 639/684] [D loss: 1.775462, acc: 0.767578, f1: 0.257831] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 640/684] [D loss: 1.773453, acc: 0.769531, f1: 0.256095] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 641/684] [D loss: 1.794954, acc: 0.748047, f1: 0.257101] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 642/684] [D loss: 1.771494, acc: 0.771484, f1: 0.235021] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 643/684] [D loss: 1.800842, acc: 0.742188, f1: 0.253247] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 644/684] [D loss: 1.781305, acc: 0.761719, f1: 0.257799] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 645/684] [D loss: 1.779322, acc: 0.763672, f1: 0.233916] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 646/684] [D loss: 1.786561, acc: 0.755859, f1: 0.255773] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 647/684] [D loss: 1.783235, acc: 0.759766, f1: 0.281495] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 648/684] [D loss: 1.777275, acc: 0.765625, f1: 0.262873] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 649/684] [D loss: 1.790936, acc: 0.751953, f1: 0.279635] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 650/684] [D loss: 1.761791, acc: 0.781250, f1: 0.291383] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 651/684] [D loss: 1.771478, acc: 0.771484, f1: 0.263240] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 652/684] [D loss: 1.767618, acc: 0.775391, f1: 0.260080] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 653/684] [D loss: 1.789023, acc: 0.753906, f1: 0.254650] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 654/684] [D loss: 1.792929, acc: 0.750000, f1: 0.254696] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 655/684] [D loss: 1.785230, acc: 0.757812, f1: 0.256688] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 656/684] [D loss: 1.779369, acc: 0.763672, f1: 0.257566] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 657/684] [D loss: 1.789083, acc: 0.753906, f1: 0.285393] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 658/684] [D loss: 1.757812, acc: 0.785156, f1: 0.290573] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 659/684] [D loss: 1.777347, acc: 0.765625, f1: 0.258892] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 660/684] [D loss: 1.761789, acc: 0.781250, f1: 0.257955] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 661/684] [D loss: 1.757866, acc: 0.785156, f1: 0.289154] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 662/684] [D loss: 1.792073, acc: 0.750000, f1: 0.254356] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 663/684] [D loss: 1.783275, acc: 0.759766, f1: 0.255226] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 664/684] [D loss: 1.753935, acc: 0.789062, f1: 0.295704] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 665/684] [D loss: 1.773471, acc: 0.769531, f1: 0.255101] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 666/684] [D loss: 1.740251, acc: 0.802734, f1: 0.266182] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 667/684] [D loss: 1.777413, acc: 0.765625, f1: 0.257811] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 668/684] [D loss: 1.771544, acc: 0.771484, f1: 0.289034] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 669/684] [D loss: 1.771555, acc: 0.771484, f1: 0.286093] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 670/684] [D loss: 1.785075, acc: 0.757812, f1: 0.258344] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 671/684] [D loss: 1.781240, acc: 0.761719, f1: 0.258939] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 672/684] [D loss: 1.750070, acc: 0.792969, f1: 0.292949] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 673/684] [D loss: 1.777380, acc: 0.765625, f1: 0.234730] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 674/684] [D loss: 1.755931, acc: 0.787109, f1: 0.261174] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 675/684] [D loss: 1.775463, acc: 0.767578, f1: 0.256348] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 676/684] [D loss: 1.773504, acc: 0.769531, f1: 0.259476] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 677/684] [D loss: 1.775462, acc: 0.767578, f1: 0.231398] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 678/684] [D loss: 1.757877, acc: 0.785156, f1: 0.263958] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 679/684] [D loss: 1.744436, acc: 0.798828, f1: 0.265682] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 680/684] [D loss: 1.757846, acc: 0.785156, f1: 0.290175] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 681/684] [D loss: 1.744163, acc: 0.798828, f1: 0.238124] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 682/684] [D loss: 1.759794, acc: 0.783203, f1: 0.263675] [G loss: -1.000000]\n",
      "[Epoch 1/5] [Batch 683/684] [D loss: 1.763588, acc: 0.779297, f1: 0.290853] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 0/684] [D loss: 1.779365, acc: 0.763672, f1: 0.231589] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 1/684] [D loss: 1.787179, acc: 0.755859, f1: 0.256522] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 2/684] [D loss: 1.759809, acc: 0.783203, f1: 0.264608] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 3/684] [D loss: 1.775455, acc: 0.767578, f1: 0.256516] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 4/684] [D loss: 1.759735, acc: 0.783203, f1: 0.240131] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 5/684] [D loss: 1.765635, acc: 0.777344, f1: 0.259744] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 6/684] [D loss: 1.765587, acc: 0.777344, f1: 0.290627] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 7/684] [D loss: 1.781053, acc: 0.761719, f1: 0.255258] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 8/684] [D loss: 1.786253, acc: 0.755859, f1: 0.257662] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 9/684] [D loss: 1.796630, acc: 0.746094, f1: 0.252394] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 10/684] [D loss: 1.761660, acc: 0.781250, f1: 0.263167] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 11/684] [D loss: 1.753948, acc: 0.789062, f1: 0.239662] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 12/684] [D loss: 1.759809, acc: 0.783203, f1: 0.293727] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 13/684] [D loss: 1.757883, acc: 0.785156, f1: 0.238779] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 14/684] [D loss: 1.780983, acc: 0.761719, f1: 0.256622] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 15/684] [D loss: 1.796808, acc: 0.746094, f1: 0.256420] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 16/684] [D loss: 1.771404, acc: 0.771484, f1: 0.285918] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 17/684] [D loss: 1.814280, acc: 0.728516, f1: 0.276970] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 18/684] [D loss: 1.787107, acc: 0.755859, f1: 0.254234] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 19/684] [D loss: 1.765657, acc: 0.777344, f1: 0.258438] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 20/684] [D loss: 1.781143, acc: 0.761719, f1: 0.257126] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 21/684] [D loss: 1.783215, acc: 0.759766, f1: 0.254818] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 22/684] [D loss: 1.783151, acc: 0.759766, f1: 0.257341] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 23/684] [D loss: 1.777415, acc: 0.765625, f1: 0.259696] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 24/684] [D loss: 1.759834, acc: 0.783203, f1: 0.261435] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 25/684] [D loss: 1.771529, acc: 0.771484, f1: 0.236101] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 26/684] [D loss: 1.751881, acc: 0.791016, f1: 0.264513] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 27/684] [D loss: 1.808484, acc: 0.734375, f1: 0.281111] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 28/684] [D loss: 1.763576, acc: 0.779297, f1: 0.239139] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 29/684] [D loss: 1.777375, acc: 0.765625, f1: 0.257497] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 30/684] [D loss: 1.757868, acc: 0.785156, f1: 0.293356] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 31/684] [D loss: 1.787172, acc: 0.755859, f1: 0.253571] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 32/684] [D loss: 1.776240, acc: 0.765625, f1: 0.255963] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 33/684] [D loss: 1.786668, acc: 0.755859, f1: 0.284196] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 34/684] [D loss: 1.761678, acc: 0.781250, f1: 0.258519] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 35/684] [D loss: 1.783067, acc: 0.759766, f1: 0.258173] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 36/684] [D loss: 1.763592, acc: 0.779297, f1: 0.235385] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 37/684] [D loss: 1.757876, acc: 0.785156, f1: 0.291596] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 38/684] [D loss: 1.761733, acc: 0.781250, f1: 0.262795] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 39/684] [D loss: 1.742334, acc: 0.800781, f1: 0.264324] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 40/684] [D loss: 1.777157, acc: 0.765625, f1: 0.287476] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 41/684] [D loss: 1.773462, acc: 0.769531, f1: 0.287198] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 42/684] [D loss: 1.756062, acc: 0.787109, f1: 0.287781] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 43/684] [D loss: 1.775411, acc: 0.767578, f1: 0.286995] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 44/684] [D loss: 1.750044, acc: 0.792969, f1: 0.262150] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 45/684] [D loss: 1.767237, acc: 0.775391, f1: 0.262730] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 46/684] [D loss: 1.769431, acc: 0.773438, f1: 0.261258] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 47/684] [D loss: 1.755711, acc: 0.787109, f1: 0.263105] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 48/684] [D loss: 1.777289, acc: 0.765625, f1: 0.257885] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 49/684] [D loss: 1.773269, acc: 0.769531, f1: 0.260253] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 50/684] [D loss: 1.760036, acc: 0.783203, f1: 0.289354] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 51/684] [D loss: 1.744257, acc: 0.798828, f1: 0.265577] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 52/684] [D loss: 1.745926, acc: 0.796875, f1: 0.293019] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 53/684] [D loss: 1.765455, acc: 0.777344, f1: 0.286921] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 54/684] [D loss: 1.794359, acc: 0.748047, f1: 0.252279] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 55/684] [D loss: 1.759577, acc: 0.783203, f1: 0.262391] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 56/684] [D loss: 1.767485, acc: 0.775391, f1: 0.258323] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 57/684] [D loss: 1.790656, acc: 0.751953, f1: 0.254957] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 58/684] [D loss: 1.747858, acc: 0.794922, f1: 0.265053] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 59/684] [D loss: 1.747946, acc: 0.794922, f1: 0.294138] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 60/684] [D loss: 1.771195, acc: 0.771484, f1: 0.257808] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 61/684] [D loss: 1.786683, acc: 0.755859, f1: 0.284448] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 62/684] [D loss: 1.751622, acc: 0.791016, f1: 0.329505] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 63/684] [D loss: 1.769553, acc: 0.773438, f1: 0.286799] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 64/684] [D loss: 1.784872, acc: 0.757812, f1: 0.258636] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 65/684] [D loss: 1.774964, acc: 0.767578, f1: 0.258036] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 66/684] [D loss: 1.763474, acc: 0.779297, f1: 0.258469] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 67/684] [D loss: 1.791798, acc: 0.751953, f1: 0.254005] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 68/684] [D loss: 1.765541, acc: 0.777344, f1: 0.258041] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 69/684] [D loss: 1.767251, acc: 0.775391, f1: 0.261563] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 70/684] [D loss: 1.766875, acc: 0.775391, f1: 0.257535] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 71/684] [D loss: 1.749722, acc: 0.792969, f1: 0.294273] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 72/684] [D loss: 1.738076, acc: 0.804688, f1: 0.265239] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 73/684] [D loss: 1.781257, acc: 0.761719, f1: 0.255377] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 74/684] [D loss: 1.798705, acc: 0.744141, f1: 0.281961] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 75/684] [D loss: 1.753704, acc: 0.789062, f1: 0.261327] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 76/684] [D loss: 1.794559, acc: 0.748047, f1: 0.279736] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 77/684] [D loss: 1.783152, acc: 0.759766, f1: 0.255420] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 78/684] [D loss: 1.765646, acc: 0.777344, f1: 0.259595] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 79/684] [D loss: 1.761678, acc: 0.781250, f1: 0.256534] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 80/684] [D loss: 1.767329, acc: 0.775391, f1: 0.262429] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 81/684] [D loss: 1.806704, acc: 0.736328, f1: 0.223390] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 82/684] [D loss: 1.744153, acc: 0.798828, f1: 0.293137] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 83/684] [D loss: 1.781035, acc: 0.761719, f1: 0.256826] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 84/684] [D loss: 1.789133, acc: 0.753906, f1: 0.256166] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 85/684] [D loss: 1.773336, acc: 0.769531, f1: 0.254273] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 86/684] [D loss: 1.780870, acc: 0.761719, f1: 0.255323] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 87/684] [D loss: 1.785220, acc: 0.757812, f1: 0.256568] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 88/684] [D loss: 1.755912, acc: 0.787109, f1: 0.261000] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 89/684] [D loss: 1.759794, acc: 0.783203, f1: 0.262387] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 90/684] [D loss: 1.751514, acc: 0.791016, f1: 0.329341] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 91/684] [D loss: 1.771529, acc: 0.771484, f1: 0.259277] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 92/684] [D loss: 1.753434, acc: 0.789062, f1: 0.288177] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 93/684] [D loss: 1.767472, acc: 0.775391, f1: 0.261886] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 94/684] [D loss: 1.779310, acc: 0.763672, f1: 0.282062] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 95/684] [D loss: 1.802438, acc: 0.740234, f1: 0.274336] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 96/684] [D loss: 1.779143, acc: 0.763672, f1: 0.254723] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 97/684] [D loss: 1.769176, acc: 0.773438, f1: 0.284869] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 98/684] [D loss: 1.753801, acc: 0.789062, f1: 0.291192] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 99/684] [D loss: 1.787066, acc: 0.755859, f1: 0.255173] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 100/684] [D loss: 1.759679, acc: 0.783203, f1: 0.258483] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 101/684] [D loss: 1.767242, acc: 0.775391, f1: 0.254291] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 102/684] [D loss: 1.771554, acc: 0.771484, f1: 0.256545] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 103/684] [D loss: 1.802622, acc: 0.740234, f1: 0.356737] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 104/684] [D loss: 1.767372, acc: 0.775391, f1: 0.257363] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 105/684] [D loss: 1.769445, acc: 0.773438, f1: 0.258517] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 106/684] [D loss: 1.792629, acc: 0.750000, f1: 0.278423] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 107/684] [D loss: 1.765242, acc: 0.777344, f1: 0.257144] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 108/684] [D loss: 1.780681, acc: 0.761719, f1: 0.256594] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 109/684] [D loss: 1.774896, acc: 0.767578, f1: 0.260531] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 110/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259075] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 111/684] [D loss: 1.772979, acc: 0.769531, f1: 0.254932] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 112/684] [D loss: 1.774978, acc: 0.767578, f1: 0.256657] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 113/684] [D loss: 1.751656, acc: 0.791016, f1: 0.262140] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 114/684] [D loss: 1.767460, acc: 0.775391, f1: 0.258048] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 115/684] [D loss: 1.777126, acc: 0.765625, f1: 0.286465] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 116/684] [D loss: 1.796744, acc: 0.746094, f1: 0.254926] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 117/684] [D loss: 1.783020, acc: 0.759766, f1: 0.230915] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 118/684] [D loss: 1.755661, acc: 0.787109, f1: 0.293404] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 119/684] [D loss: 1.763605, acc: 0.779297, f1: 0.289499] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 120/684] [D loss: 1.780840, acc: 0.761719, f1: 0.285900] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 121/684] [D loss: 1.779339, acc: 0.763672, f1: 0.258820] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 122/684] [D loss: 1.783025, acc: 0.759766, f1: 0.286091] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 123/684] [D loss: 1.765677, acc: 0.777344, f1: 0.287877] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 124/684] [D loss: 1.763458, acc: 0.779297, f1: 0.286897] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 125/684] [D loss: 1.761420, acc: 0.781250, f1: 0.237570] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 126/684] [D loss: 1.779036, acc: 0.763672, f1: 0.249576] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 127/684] [D loss: 1.763671, acc: 0.779297, f1: 0.287831] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 128/684] [D loss: 1.781209, acc: 0.761719, f1: 0.255300] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 129/684] [D loss: 1.773067, acc: 0.769531, f1: 0.258893] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 130/684] [D loss: 1.788754, acc: 0.753906, f1: 0.252087] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 131/684] [D loss: 1.792878, acc: 0.750000, f1: 0.250932] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 132/684] [D loss: 1.779186, acc: 0.763672, f1: 0.233923] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 133/684] [D loss: 1.751776, acc: 0.791016, f1: 0.257676] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 134/684] [D loss: 1.777135, acc: 0.765625, f1: 0.280259] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 135/684] [D loss: 1.779201, acc: 0.763672, f1: 0.255098] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 136/684] [D loss: 1.765513, acc: 0.777344, f1: 0.256587] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 137/684] [D loss: 1.761592, acc: 0.781250, f1: 0.260381] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 138/684] [D loss: 1.792617, acc: 0.750000, f1: 0.251508] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 139/684] [D loss: 1.736168, acc: 0.806641, f1: 0.265601] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 140/684] [D loss: 1.771486, acc: 0.771484, f1: 0.233796] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 141/684] [D loss: 1.773403, acc: 0.769531, f1: 0.258432] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 142/684] [D loss: 1.759657, acc: 0.783203, f1: 0.258348] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 143/684] [D loss: 1.747699, acc: 0.794922, f1: 0.263846] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 144/684] [D loss: 1.742132, acc: 0.800781, f1: 0.240827] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 145/684] [D loss: 1.806577, acc: 0.736328, f1: 0.230965] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 146/684] [D loss: 1.771179, acc: 0.771484, f1: 0.234002] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 147/684] [D loss: 1.781163, acc: 0.761719, f1: 0.258635] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 148/684] [D loss: 1.779118, acc: 0.763672, f1: 0.283366] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 149/684] [D loss: 1.745807, acc: 0.796875, f1: 0.266719] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 150/684] [D loss: 1.767253, acc: 0.775391, f1: 0.286023] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 151/684] [D loss: 1.786986, acc: 0.755859, f1: 0.257344] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 152/684] [D loss: 1.757714, acc: 0.785156, f1: 0.261581] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 153/684] [D loss: 1.771507, acc: 0.771484, f1: 0.282885] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 154/684] [D loss: 1.773217, acc: 0.769531, f1: 0.258812] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 155/684] [D loss: 1.730403, acc: 0.812500, f1: 0.267816] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 156/684] [D loss: 1.785819, acc: 0.757812, f1: 0.257085] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 157/684] [D loss: 1.781182, acc: 0.761719, f1: 0.254007] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 158/684] [D loss: 1.774053, acc: 0.769531, f1: 0.261465] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 159/684] [D loss: 1.765684, acc: 0.777344, f1: 0.259548] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 160/684] [D loss: 1.781285, acc: 0.761719, f1: 0.257492] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 161/684] [D loss: 1.773387, acc: 0.769531, f1: 0.289248] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 162/684] [D loss: 1.757885, acc: 0.785156, f1: 0.260935] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 163/684] [D loss: 1.781287, acc: 0.761719, f1: 0.256146] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 164/684] [D loss: 1.753757, acc: 0.789062, f1: 0.238335] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 165/684] [D loss: 1.751933, acc: 0.791016, f1: 0.262821] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 166/684] [D loss: 1.769457, acc: 0.773438, f1: 0.236917] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 167/684] [D loss: 1.749974, acc: 0.792969, f1: 0.260795] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 168/684] [D loss: 1.785003, acc: 0.757812, f1: 0.257614] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 169/684] [D loss: 1.779269, acc: 0.763672, f1: 0.289569] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 170/684] [D loss: 1.777256, acc: 0.765625, f1: 0.253431] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 171/684] [D loss: 1.776191, acc: 0.767578, f1: 0.256759] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 172/684] [D loss: 1.752002, acc: 0.791016, f1: 0.262960] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 173/684] [D loss: 1.767456, acc: 0.775391, f1: 0.284178] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 174/684] [D loss: 1.763897, acc: 0.779297, f1: 0.260103] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 175/684] [D loss: 1.763587, acc: 0.779297, f1: 0.262388] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 176/684] [D loss: 1.769222, acc: 0.773438, f1: 0.260070] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 177/684] [D loss: 1.765346, acc: 0.777344, f1: 0.287998] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 178/684] [D loss: 1.765335, acc: 0.777344, f1: 0.259526] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 179/684] [D loss: 1.771121, acc: 0.771484, f1: 0.259652] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 180/684] [D loss: 1.761596, acc: 0.781250, f1: 0.291426] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 181/684] [D loss: 1.771270, acc: 0.771484, f1: 0.284453] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 182/684] [D loss: 1.788744, acc: 0.753906, f1: 0.255921] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 183/684] [D loss: 1.788872, acc: 0.753906, f1: 0.278255] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 184/684] [D loss: 1.738297, acc: 0.804688, f1: 0.264938] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 185/684] [D loss: 1.781172, acc: 0.761719, f1: 0.283740] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 186/684] [D loss: 1.779190, acc: 0.763672, f1: 0.255231] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 187/684] [D loss: 1.790800, acc: 0.751953, f1: 0.227831] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 188/684] [D loss: 1.777252, acc: 0.765625, f1: 0.252615] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 189/684] [D loss: 1.761351, acc: 0.781250, f1: 0.238963] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 190/684] [D loss: 1.775408, acc: 0.767578, f1: 0.261045] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 191/684] [D loss: 1.763558, acc: 0.779297, f1: 0.260919] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 192/684] [D loss: 1.775156, acc: 0.767578, f1: 0.259260] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 193/684] [D loss: 1.761316, acc: 0.781250, f1: 0.291389] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 194/684] [D loss: 1.769270, acc: 0.773438, f1: 0.257459] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 195/684] [D loss: 1.794702, acc: 0.748047, f1: 0.250518] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 196/684] [D loss: 1.777198, acc: 0.765625, f1: 0.254943] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 197/684] [D loss: 1.788717, acc: 0.753906, f1: 0.253442] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 198/684] [D loss: 1.763048, acc: 0.779297, f1: 0.259348] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 199/684] [D loss: 1.769324, acc: 0.773438, f1: 0.285461] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 200/684] [D loss: 1.782855, acc: 0.759766, f1: 0.231665] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 201/684] [D loss: 1.783236, acc: 0.759766, f1: 0.256375] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 202/684] [D loss: 1.759575, acc: 0.783203, f1: 0.285833] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 203/684] [D loss: 1.782720, acc: 0.759766, f1: 0.257413] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 204/684] [D loss: 1.789078, acc: 0.753906, f1: 0.255426] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 205/684] [D loss: 1.783141, acc: 0.759766, f1: 0.256602] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 206/684] [D loss: 1.781181, acc: 0.761719, f1: 0.257372] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 207/684] [D loss: 1.765501, acc: 0.777344, f1: 0.287207] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 208/684] [D loss: 1.792736, acc: 0.750000, f1: 0.230851] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 209/684] [D loss: 1.759629, acc: 0.783203, f1: 0.260503] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 210/684] [D loss: 1.773958, acc: 0.771484, f1: 0.255852] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 211/684] [D loss: 1.775561, acc: 0.767578, f1: 0.256260] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 212/684] [D loss: 1.753640, acc: 0.789062, f1: 0.262261] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 213/684] [D loss: 1.773509, acc: 0.769531, f1: 0.285523] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 214/684] [D loss: 1.761508, acc: 0.781250, f1: 0.293293] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 215/684] [D loss: 1.802628, acc: 0.740234, f1: 0.251054] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 216/684] [D loss: 1.775462, acc: 0.767578, f1: 0.287404] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 217/684] [D loss: 1.785106, acc: 0.757812, f1: 0.278582] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 218/684] [D loss: 1.765503, acc: 0.777344, f1: 0.290085] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 219/684] [D loss: 1.775122, acc: 0.767578, f1: 0.260531] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 220/684] [D loss: 1.804313, acc: 0.738281, f1: 0.250616] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 221/684] [D loss: 1.765545, acc: 0.777344, f1: 0.258787] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 222/684] [D loss: 1.765641, acc: 0.777344, f1: 0.259737] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 223/684] [D loss: 1.773231, acc: 0.769531, f1: 0.284503] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 224/684] [D loss: 1.759836, acc: 0.783203, f1: 0.262259] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 225/684] [D loss: 1.769594, acc: 0.773438, f1: 0.258071] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 226/684] [D loss: 1.796746, acc: 0.746094, f1: 0.249637] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 227/684] [D loss: 1.781198, acc: 0.761719, f1: 0.253313] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 228/684] [D loss: 1.746774, acc: 0.794922, f1: 0.265250] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 229/684] [D loss: 1.757558, acc: 0.785156, f1: 0.257902] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 230/684] [D loss: 1.757474, acc: 0.785156, f1: 0.288564] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 231/684] [D loss: 1.790738, acc: 0.751953, f1: 0.251648] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 232/684] [D loss: 1.794531, acc: 0.748047, f1: 0.230501] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 233/684] [D loss: 1.763662, acc: 0.779297, f1: 0.261594] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 234/684] [D loss: 1.787138, acc: 0.755859, f1: 0.253017] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 235/684] [D loss: 1.740302, acc: 0.802734, f1: 0.294122] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 236/684] [D loss: 1.785034, acc: 0.757812, f1: 0.282074] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 237/684] [D loss: 1.785101, acc: 0.757812, f1: 0.255374] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 238/684] [D loss: 1.775364, acc: 0.767578, f1: 0.256847] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 239/684] [D loss: 1.771547, acc: 0.771484, f1: 0.284446] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 240/684] [D loss: 1.769596, acc: 0.773438, f1: 0.257710] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 241/684] [D loss: 1.734321, acc: 0.808594, f1: 0.267537] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 242/684] [D loss: 1.816477, acc: 0.726562, f1: 0.275368] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 243/684] [D loss: 1.769418, acc: 0.773438, f1: 0.256651] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 244/684] [D loss: 1.759763, acc: 0.783203, f1: 0.257416] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 245/684] [D loss: 1.761787, acc: 0.781250, f1: 0.258775] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 246/684] [D loss: 1.784965, acc: 0.757812, f1: 0.256432] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 247/684] [D loss: 1.747731, acc: 0.794922, f1: 0.330174] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 248/684] [D loss: 1.767360, acc: 0.775391, f1: 0.231814] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 249/684] [D loss: 1.749815, acc: 0.792969, f1: 0.291506] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 250/684] [D loss: 1.767492, acc: 0.775391, f1: 0.258169] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 251/684] [D loss: 1.779347, acc: 0.763672, f1: 0.255055] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 252/684] [D loss: 1.783266, acc: 0.759766, f1: 0.253815] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 253/684] [D loss: 1.808662, acc: 0.734375, f1: 0.248254] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 254/684] [D loss: 1.761335, acc: 0.781250, f1: 0.235245] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 255/684] [D loss: 1.769246, acc: 0.773438, f1: 0.288059] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 256/684] [D loss: 1.759836, acc: 0.783203, f1: 0.258016] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 257/684] [D loss: 1.780704, acc: 0.761719, f1: 0.255482] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 258/684] [D loss: 1.777349, acc: 0.765625, f1: 0.259079] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 259/684] [D loss: 1.771557, acc: 0.771484, f1: 0.260585] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 260/684] [D loss: 1.759603, acc: 0.783203, f1: 0.258654] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 261/684] [D loss: 1.795564, acc: 0.748047, f1: 0.230056] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 262/684] [D loss: 1.766857, acc: 0.775391, f1: 0.258952] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 263/684] [D loss: 1.763215, acc: 0.779297, f1: 0.286998] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 264/684] [D loss: 1.745803, acc: 0.796875, f1: 0.265844] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 265/684] [D loss: 1.775054, acc: 0.767578, f1: 0.286550] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 266/684] [D loss: 1.795463, acc: 0.748047, f1: 0.280914] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 267/684] [D loss: 1.771395, acc: 0.771484, f1: 0.260384] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 268/684] [D loss: 1.767447, acc: 0.775391, f1: 0.286657] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 269/684] [D loss: 1.794991, acc: 0.748047, f1: 0.255290] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 270/684] [D loss: 1.778952, acc: 0.763672, f1: 0.256506] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 271/684] [D loss: 1.742167, acc: 0.800781, f1: 0.264235] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 272/684] [D loss: 1.781255, acc: 0.761719, f1: 0.256976] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 273/684] [D loss: 1.779254, acc: 0.763672, f1: 0.259034] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 274/684] [D loss: 1.749147, acc: 0.792969, f1: 0.289147] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 275/684] [D loss: 1.782782, acc: 0.759766, f1: 0.230040] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 276/684] [D loss: 1.774960, acc: 0.767578, f1: 0.260270] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 277/684] [D loss: 1.781005, acc: 0.761719, f1: 0.231472] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 278/684] [D loss: 1.779206, acc: 0.763672, f1: 0.282708] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 279/684] [D loss: 1.794523, acc: 0.748047, f1: 0.254038] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 280/684] [D loss: 1.745825, acc: 0.796875, f1: 0.239836] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 281/684] [D loss: 1.763548, acc: 0.779297, f1: 0.258739] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 282/684] [D loss: 1.783244, acc: 0.759766, f1: 0.232310] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 283/684] [D loss: 1.761680, acc: 0.781250, f1: 0.262826] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 284/684] [D loss: 1.759627, acc: 0.783203, f1: 0.292304] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 285/684] [D loss: 1.773042, acc: 0.769531, f1: 0.257395] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 286/684] [D loss: 1.779117, acc: 0.763672, f1: 0.258702] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 287/684] [D loss: 1.752007, acc: 0.791016, f1: 0.264178] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 288/684] [D loss: 1.774989, acc: 0.767578, f1: 0.251916] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 289/684] [D loss: 1.776087, acc: 0.765625, f1: 0.258785] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 290/684] [D loss: 1.777240, acc: 0.765625, f1: 0.254217] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 291/684] [D loss: 1.806678, acc: 0.736328, f1: 0.280567] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 292/684] [D loss: 1.779283, acc: 0.763672, f1: 0.260702] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 293/684] [D loss: 1.773508, acc: 0.769531, f1: 0.257206] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 294/684] [D loss: 1.744212, acc: 0.798828, f1: 0.263451] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 295/684] [D loss: 1.763567, acc: 0.779297, f1: 0.262674] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 296/684] [D loss: 1.783087, acc: 0.759766, f1: 0.233951] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 297/684] [D loss: 1.798682, acc: 0.744141, f1: 0.254295] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 298/684] [D loss: 1.800852, acc: 0.742188, f1: 0.251106] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 299/684] [D loss: 1.765668, acc: 0.777344, f1: 0.289421] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 300/684] [D loss: 1.789029, acc: 0.753906, f1: 0.253332] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 301/684] [D loss: 1.789061, acc: 0.753906, f1: 0.259977] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 302/684] [D loss: 1.771556, acc: 0.771484, f1: 0.256276] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 303/684] [D loss: 1.763692, acc: 0.779297, f1: 0.291061] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 304/684] [D loss: 1.753865, acc: 0.789062, f1: 0.260242] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 305/684] [D loss: 1.787179, acc: 0.755859, f1: 0.254638] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 306/684] [D loss: 1.775403, acc: 0.767578, f1: 0.286329] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 307/684] [D loss: 1.757704, acc: 0.785156, f1: 0.264329] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 308/684] [D loss: 1.777184, acc: 0.765625, f1: 0.323699] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 309/684] [D loss: 1.755889, acc: 0.787109, f1: 0.238221] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 310/684] [D loss: 1.791064, acc: 0.751953, f1: 0.281945] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 311/684] [D loss: 1.751848, acc: 0.791016, f1: 0.263866] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 312/684] [D loss: 1.753960, acc: 0.789062, f1: 0.291962] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 313/684] [D loss: 1.751977, acc: 0.791016, f1: 0.263977] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 314/684] [D loss: 1.753944, acc: 0.789062, f1: 0.236929] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 315/684] [D loss: 1.785208, acc: 0.757812, f1: 0.234205] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 316/684] [D loss: 1.783113, acc: 0.759766, f1: 0.257449] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 317/684] [D loss: 1.787162, acc: 0.755859, f1: 0.283818] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 318/684] [D loss: 1.757825, acc: 0.785156, f1: 0.291119] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 319/684] [D loss: 1.752024, acc: 0.791016, f1: 0.264339] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 320/684] [D loss: 1.755905, acc: 0.787109, f1: 0.287945] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 321/684] [D loss: 1.789070, acc: 0.753906, f1: 0.255647] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 322/684] [D loss: 1.775429, acc: 0.767578, f1: 0.288117] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 323/684] [D loss: 1.761744, acc: 0.781250, f1: 0.262881] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 324/684] [D loss: 1.755910, acc: 0.787109, f1: 0.291369] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 325/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259481] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 326/684] [D loss: 1.779369, acc: 0.763672, f1: 0.285991] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 327/684] [D loss: 1.804693, acc: 0.738281, f1: 0.253516] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 328/684] [D loss: 1.769554, acc: 0.773438, f1: 0.237148] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 329/684] [D loss: 1.785228, acc: 0.757812, f1: 0.258615] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 330/684] [D loss: 1.773342, acc: 0.769531, f1: 0.260153] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 331/684] [D loss: 1.791083, acc: 0.751953, f1: 0.254637] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 332/684] [D loss: 1.757885, acc: 0.785156, f1: 0.293054] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 333/684] [D loss: 1.773427, acc: 0.769531, f1: 0.282663] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 334/684] [D loss: 1.748119, acc: 0.794922, f1: 0.264768] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 335/684] [D loss: 1.781322, acc: 0.761719, f1: 0.285666] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 336/684] [D loss: 1.785165, acc: 0.757812, f1: 0.284130] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 337/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256191] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 338/684] [D loss: 1.761777, acc: 0.781250, f1: 0.262781] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 339/684] [D loss: 1.767640, acc: 0.775391, f1: 0.257447] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 340/684] [D loss: 1.769603, acc: 0.773438, f1: 0.289334] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 341/684] [D loss: 1.794947, acc: 0.748047, f1: 0.251542] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 342/684] [D loss: 1.759838, acc: 0.783203, f1: 0.262404] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 343/684] [D loss: 1.783139, acc: 0.759766, f1: 0.253520] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 344/684] [D loss: 1.789135, acc: 0.753906, f1: 0.285034] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 345/684] [D loss: 1.773509, acc: 0.769531, f1: 0.253736] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 346/684] [D loss: 1.753978, acc: 0.789062, f1: 0.262634] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 347/684] [D loss: 1.771536, acc: 0.771484, f1: 0.257104] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 348/684] [D loss: 1.765687, acc: 0.777344, f1: 0.261461] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 349/684] [D loss: 1.802794, acc: 0.740234, f1: 0.255303] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 350/684] [D loss: 1.794928, acc: 0.748047, f1: 0.254828] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 351/684] [D loss: 1.761790, acc: 0.781250, f1: 0.289386] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 352/684] [D loss: 1.794994, acc: 0.748047, f1: 0.254277] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 353/684] [D loss: 1.771545, acc: 0.771484, f1: 0.258375] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 354/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257563] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 355/684] [D loss: 1.783256, acc: 0.759766, f1: 0.259421] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 356/684] [D loss: 1.755932, acc: 0.787109, f1: 0.239445] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 357/684] [D loss: 1.753944, acc: 0.789062, f1: 0.265504] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 358/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253679] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 359/684] [D loss: 1.781185, acc: 0.761719, f1: 0.284032] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 360/684] [D loss: 1.746166, acc: 0.796875, f1: 0.291136] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 361/684] [D loss: 1.781318, acc: 0.761719, f1: 0.285171] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 362/684] [D loss: 1.769601, acc: 0.773438, f1: 0.258843] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 363/684] [D loss: 1.769621, acc: 0.773438, f1: 0.257451] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 364/684] [D loss: 1.789092, acc: 0.753906, f1: 0.252211] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 365/684] [D loss: 1.771502, acc: 0.771484, f1: 0.260242] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 366/684] [D loss: 1.748119, acc: 0.794922, f1: 0.266595] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 367/684] [D loss: 1.796947, acc: 0.746094, f1: 0.283800] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 368/684] [D loss: 1.787179, acc: 0.755859, f1: 0.252652] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 369/684] [D loss: 1.767608, acc: 0.775391, f1: 0.261404] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 370/684] [D loss: 1.759719, acc: 0.783203, f1: 0.260432] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 371/684] [D loss: 1.759834, acc: 0.783203, f1: 0.265092] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 372/684] [D loss: 1.771557, acc: 0.771484, f1: 0.256155] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 373/684] [D loss: 1.757885, acc: 0.785156, f1: 0.262311] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 374/684] [D loss: 1.796888, acc: 0.746094, f1: 0.254915] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 375/684] [D loss: 1.750042, acc: 0.792969, f1: 0.264925] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 376/684] [D loss: 1.791088, acc: 0.751953, f1: 0.257766] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 377/684] [D loss: 1.787177, acc: 0.755859, f1: 0.255531] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 378/684] [D loss: 1.793124, acc: 0.750000, f1: 0.254764] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 379/684] [D loss: 1.751840, acc: 0.791016, f1: 0.265197] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 380/684] [D loss: 1.767585, acc: 0.775391, f1: 0.259052] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 381/684] [D loss: 1.785142, acc: 0.757812, f1: 0.230528] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 382/684] [D loss: 1.781250, acc: 0.761719, f1: 0.283661] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 383/684] [D loss: 1.781311, acc: 0.761719, f1: 0.257568] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 384/684] [D loss: 1.755889, acc: 0.787109, f1: 0.292781] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 385/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256931] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 386/684] [D loss: 1.734447, acc: 0.808594, f1: 0.266745] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 387/684] [D loss: 1.761789, acc: 0.781250, f1: 0.262378] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 388/684] [D loss: 1.769554, acc: 0.773438, f1: 0.259557] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 389/684] [D loss: 1.761791, acc: 0.781250, f1: 0.257702] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 390/684] [D loss: 1.773507, acc: 0.769531, f1: 0.260938] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 391/684] [D loss: 1.757885, acc: 0.785156, f1: 0.292506] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 392/684] [D loss: 1.779368, acc: 0.763672, f1: 0.284160] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 393/684] [D loss: 1.783276, acc: 0.759766, f1: 0.251815] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 394/684] [D loss: 1.771498, acc: 0.771484, f1: 0.288651] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 395/684] [D loss: 1.793041, acc: 0.750000, f1: 0.284199] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 396/684] [D loss: 1.773510, acc: 0.769531, f1: 0.235284] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 397/684] [D loss: 1.783275, acc: 0.759766, f1: 0.285537] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 398/684] [D loss: 1.775451, acc: 0.767578, f1: 0.255633] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 399/684] [D loss: 1.761782, acc: 0.781250, f1: 0.292344] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 400/684] [D loss: 1.769599, acc: 0.773438, f1: 0.290146] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 401/684] [D loss: 1.759838, acc: 0.783203, f1: 0.290011] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 402/684] [D loss: 1.775463, acc: 0.767578, f1: 0.233548] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 403/684] [D loss: 1.750041, acc: 0.792969, f1: 0.293550] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 404/684] [D loss: 1.775410, acc: 0.767578, f1: 0.289187] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 405/684] [D loss: 1.787182, acc: 0.755859, f1: 0.254239] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 406/684] [D loss: 1.761725, acc: 0.781250, f1: 0.262305] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 407/684] [D loss: 1.779308, acc: 0.763672, f1: 0.288090] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 408/684] [D loss: 1.750010, acc: 0.792969, f1: 0.237785] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 409/684] [D loss: 1.791083, acc: 0.751953, f1: 0.255089] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 410/684] [D loss: 1.736400, acc: 0.806641, f1: 0.293623] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 411/684] [D loss: 1.744213, acc: 0.798828, f1: 0.265106] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 412/684] [D loss: 1.791069, acc: 0.751953, f1: 0.233255] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 413/684] [D loss: 1.775400, acc: 0.767578, f1: 0.234274] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 414/684] [D loss: 1.800786, acc: 0.742188, f1: 0.252604] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 415/684] [D loss: 1.792983, acc: 0.750000, f1: 0.255447] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 416/684] [D loss: 1.779360, acc: 0.763672, f1: 0.256652] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 417/684] [D loss: 1.765693, acc: 0.777344, f1: 0.289272] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 418/684] [D loss: 1.794994, acc: 0.748047, f1: 0.281903] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 419/684] [D loss: 1.757882, acc: 0.785156, f1: 0.262099] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 420/684] [D loss: 1.775399, acc: 0.767578, f1: 0.258439] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 421/684] [D loss: 1.767650, acc: 0.775391, f1: 0.261662] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 422/684] [D loss: 1.746159, acc: 0.796875, f1: 0.294255] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 423/684] [D loss: 1.732359, acc: 0.810547, f1: 0.268709] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 424/684] [D loss: 1.787181, acc: 0.755859, f1: 0.231644] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 425/684] [D loss: 1.726534, acc: 0.816406, f1: 0.380151] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 426/684] [D loss: 1.773377, acc: 0.769531, f1: 0.258454] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 427/684] [D loss: 1.789116, acc: 0.753906, f1: 0.279922] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 428/684] [D loss: 1.777416, acc: 0.765625, f1: 0.254197] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 429/684] [D loss: 1.779344, acc: 0.763672, f1: 0.258368] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 430/684] [D loss: 1.794993, acc: 0.748047, f1: 0.284229] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 431/684] [D loss: 1.777414, acc: 0.765625, f1: 0.285995] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 432/684] [D loss: 1.757849, acc: 0.785156, f1: 0.260854] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 433/684] [D loss: 1.767738, acc: 0.775391, f1: 0.259274] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 434/684] [D loss: 1.757870, acc: 0.785156, f1: 0.240827] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 435/684] [D loss: 1.789273, acc: 0.753906, f1: 0.253571] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 436/684] [D loss: 1.740303, acc: 0.802734, f1: 0.292940] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 437/684] [D loss: 1.726635, acc: 0.816406, f1: 0.243161] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 438/684] [D loss: 1.761752, acc: 0.781250, f1: 0.291211] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 439/684] [D loss: 1.777397, acc: 0.765625, f1: 0.236905] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 440/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260587] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 441/684] [D loss: 1.740289, acc: 0.802734, f1: 0.265305] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 442/684] [D loss: 1.789135, acc: 0.753906, f1: 0.282576] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 443/684] [D loss: 1.757885, acc: 0.785156, f1: 0.237357] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 444/684] [D loss: 1.775463, acc: 0.767578, f1: 0.260961] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 445/684] [D loss: 1.781322, acc: 0.761719, f1: 0.256742] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 446/684] [D loss: 1.787660, acc: 0.755859, f1: 0.256745] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 447/684] [D loss: 1.777388, acc: 0.765625, f1: 0.258354] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 448/684] [D loss: 1.763679, acc: 0.779297, f1: 0.258732] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 449/684] [D loss: 1.781277, acc: 0.761719, f1: 0.256165] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 450/684] [D loss: 1.750048, acc: 0.792969, f1: 0.261534] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 451/684] [D loss: 1.781264, acc: 0.761719, f1: 0.258393] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 452/684] [D loss: 1.761785, acc: 0.781250, f1: 0.262087] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 453/684] [D loss: 1.748112, acc: 0.794922, f1: 0.266278] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 454/684] [D loss: 1.779361, acc: 0.763672, f1: 0.258817] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 455/684] [D loss: 1.789082, acc: 0.753906, f1: 0.257212] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 456/684] [D loss: 1.777371, acc: 0.765625, f1: 0.324331] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 457/684] [D loss: 1.777349, acc: 0.765625, f1: 0.290210] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 458/684] [D loss: 1.787162, acc: 0.755859, f1: 0.282577] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 459/684] [D loss: 1.773502, acc: 0.769531, f1: 0.234408] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 460/684] [D loss: 1.789100, acc: 0.753906, f1: 0.289756] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 461/684] [D loss: 1.746166, acc: 0.796875, f1: 0.265923] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 462/684] [D loss: 1.748054, acc: 0.794922, f1: 0.295537] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 463/684] [D loss: 1.793041, acc: 0.750000, f1: 0.254120] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 464/684] [D loss: 1.779369, acc: 0.763672, f1: 0.257632] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 465/684] [D loss: 1.752025, acc: 0.791016, f1: 0.238563] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 466/684] [D loss: 1.736382, acc: 0.806641, f1: 0.266280] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 467/684] [D loss: 1.787180, acc: 0.755859, f1: 0.254966] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 468/684] [D loss: 1.779372, acc: 0.763672, f1: 0.284979] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 469/684] [D loss: 1.777416, acc: 0.765625, f1: 0.258322] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 470/684] [D loss: 1.773499, acc: 0.769531, f1: 0.237002] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 471/684] [D loss: 1.771556, acc: 0.771484, f1: 0.320513] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 472/684] [D loss: 1.757869, acc: 0.785156, f1: 0.261750] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 473/684] [D loss: 1.755931, acc: 0.787109, f1: 0.292526] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 474/684] [D loss: 1.763752, acc: 0.779297, f1: 0.323473] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 475/684] [D loss: 1.773503, acc: 0.769531, f1: 0.257461] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 476/684] [D loss: 1.779300, acc: 0.763672, f1: 0.256105] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 477/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259938] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 478/684] [D loss: 1.795168, acc: 0.748047, f1: 0.282168] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 479/684] [D loss: 1.771720, acc: 0.771484, f1: 0.236858] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 480/684] [D loss: 1.748119, acc: 0.794922, f1: 0.266965] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 481/684] [D loss: 1.763744, acc: 0.779297, f1: 0.262215] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 482/684] [D loss: 1.779369, acc: 0.763672, f1: 0.233787] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 483/684] [D loss: 1.744213, acc: 0.798828, f1: 0.331966] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 484/684] [D loss: 1.746091, acc: 0.796875, f1: 0.329117] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 485/684] [D loss: 1.767608, acc: 0.775391, f1: 0.256298] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 486/684] [D loss: 1.755907, acc: 0.787109, f1: 0.291157] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 487/684] [D loss: 1.761773, acc: 0.781250, f1: 0.260192] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 488/684] [D loss: 1.763741, acc: 0.779297, f1: 0.261996] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 489/684] [D loss: 1.773346, acc: 0.769531, f1: 0.261110] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 490/684] [D loss: 1.777344, acc: 0.765625, f1: 0.257894] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 491/684] [D loss: 1.789129, acc: 0.753906, f1: 0.254567] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 492/684] [D loss: 1.802806, acc: 0.740234, f1: 0.255019] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 493/684] [D loss: 1.788953, acc: 0.753906, f1: 0.253400] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 494/684] [D loss: 1.781321, acc: 0.761719, f1: 0.255507] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 495/684] [D loss: 1.779368, acc: 0.763672, f1: 0.256331] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 496/684] [D loss: 1.762524, acc: 0.781250, f1: 0.287832] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 497/684] [D loss: 1.781296, acc: 0.761719, f1: 0.260523] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 498/684] [D loss: 1.758159, acc: 0.785156, f1: 0.263270] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 499/684] [D loss: 1.769558, acc: 0.773438, f1: 0.262808] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 500/684] [D loss: 1.828135, acc: 0.714844, f1: 0.223874] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 501/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253335] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 502/684] [D loss: 1.783244, acc: 0.759766, f1: 0.258423] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 503/684] [D loss: 1.769603, acc: 0.773438, f1: 0.237994] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 504/684] [D loss: 1.761636, acc: 0.781250, f1: 0.259416] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 505/684] [D loss: 1.768113, acc: 0.775391, f1: 0.236260] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 506/684] [D loss: 1.769745, acc: 0.773438, f1: 0.259693] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 507/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259200] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 508/684] [D loss: 1.761791, acc: 0.781250, f1: 0.262333] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 509/684] [D loss: 1.757819, acc: 0.785156, f1: 0.238756] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 510/684] [D loss: 1.757877, acc: 0.785156, f1: 0.262051] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 511/684] [D loss: 1.771556, acc: 0.771484, f1: 0.258654] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 512/684] [D loss: 1.765919, acc: 0.777344, f1: 0.262446] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 513/684] [D loss: 1.775411, acc: 0.767578, f1: 0.286884] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 514/684] [D loss: 1.753913, acc: 0.789062, f1: 0.293807] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 515/684] [D loss: 1.763744, acc: 0.779297, f1: 0.289371] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 516/684] [D loss: 1.765668, acc: 0.777344, f1: 0.235320] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 517/684] [D loss: 1.767650, acc: 0.775391, f1: 0.260489] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 518/684] [D loss: 1.789102, acc: 0.753906, f1: 0.258047] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 519/684] [D loss: 1.775284, acc: 0.767578, f1: 0.235300] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 520/684] [D loss: 1.755842, acc: 0.787109, f1: 0.261998] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 521/684] [D loss: 1.771452, acc: 0.771484, f1: 0.288285] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 522/684] [D loss: 1.800850, acc: 0.742188, f1: 0.253643] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 523/684] [D loss: 1.767627, acc: 0.775391, f1: 0.263856] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 524/684] [D loss: 1.763732, acc: 0.779297, f1: 0.266220] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 525/684] [D loss: 1.765642, acc: 0.777344, f1: 0.292249] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 526/684] [D loss: 1.785228, acc: 0.757812, f1: 0.288245] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 527/684] [D loss: 1.777434, acc: 0.765625, f1: 0.256922] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 528/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257047] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 529/684] [D loss: 1.757885, acc: 0.785156, f1: 0.266036] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 530/684] [D loss: 1.750040, acc: 0.792969, f1: 0.261140] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 531/684] [D loss: 1.763743, acc: 0.779297, f1: 0.262002] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 532/684] [D loss: 1.775398, acc: 0.767578, f1: 0.257881] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 533/684] [D loss: 1.761782, acc: 0.781250, f1: 0.260007] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 534/684] [D loss: 1.748119, acc: 0.794922, f1: 0.263325] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 535/684] [D loss: 1.777416, acc: 0.765625, f1: 0.256011] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 536/684] [D loss: 1.806692, acc: 0.736328, f1: 0.279942] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 537/684] [D loss: 1.777345, acc: 0.765625, f1: 0.257542] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 538/684] [D loss: 1.750072, acc: 0.792969, f1: 0.264348] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 539/684] [D loss: 1.756723, acc: 0.787109, f1: 0.293343] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 540/684] [D loss: 1.742230, acc: 0.800781, f1: 0.242294] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 541/684] [D loss: 1.767615, acc: 0.775391, f1: 0.263067] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 542/684] [D loss: 1.767646, acc: 0.775391, f1: 0.289428] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 543/684] [D loss: 1.777879, acc: 0.765625, f1: 0.257034] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 544/684] [D loss: 1.767577, acc: 0.775391, f1: 0.261441] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 545/684] [D loss: 1.773510, acc: 0.769531, f1: 0.257845] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 546/684] [D loss: 1.775463, acc: 0.767578, f1: 0.286912] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 547/684] [D loss: 1.785228, acc: 0.757812, f1: 0.232617] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 548/684] [D loss: 1.816471, acc: 0.726562, f1: 0.226276] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 549/684] [D loss: 1.765682, acc: 0.777344, f1: 0.259918] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 550/684] [D loss: 1.750072, acc: 0.792969, f1: 0.264000] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 551/684] [D loss: 1.751990, acc: 0.791016, f1: 0.263881] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 552/684] [D loss: 1.759838, acc: 0.783203, f1: 0.263066] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 553/684] [D loss: 1.793041, acc: 0.750000, f1: 0.284435] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 554/684] [D loss: 1.757830, acc: 0.785156, f1: 0.259463] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 555/684] [D loss: 1.753601, acc: 0.789062, f1: 0.265448] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 556/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284789] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 557/684] [D loss: 1.759838, acc: 0.783203, f1: 0.238757] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 558/684] [D loss: 1.789135, acc: 0.753906, f1: 0.256356] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 559/684] [D loss: 1.740307, acc: 0.802734, f1: 0.265385] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 560/684] [D loss: 1.750072, acc: 0.792969, f1: 0.293902] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 561/684] [D loss: 1.781321, acc: 0.761719, f1: 0.283373] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 562/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258996] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 563/684] [D loss: 1.773510, acc: 0.769531, f1: 0.254791] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 564/684] [D loss: 1.771539, acc: 0.771484, f1: 0.289211] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 565/684] [D loss: 1.763744, acc: 0.779297, f1: 0.288279] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 566/684] [D loss: 1.751993, acc: 0.791016, f1: 0.240464] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 567/684] [D loss: 1.783275, acc: 0.759766, f1: 0.255330] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 568/684] [D loss: 1.781322, acc: 0.761719, f1: 0.257120] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 569/684] [D loss: 1.773470, acc: 0.769531, f1: 0.261391] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 570/684] [D loss: 1.798900, acc: 0.744141, f1: 0.255133] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 571/684] [D loss: 1.796947, acc: 0.746094, f1: 0.231921] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 572/684] [D loss: 1.785228, acc: 0.757812, f1: 0.257977] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 573/684] [D loss: 1.771556, acc: 0.771484, f1: 0.257526] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 574/684] [D loss: 1.753975, acc: 0.789062, f1: 0.290645] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 575/684] [D loss: 1.791088, acc: 0.751953, f1: 0.284335] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 576/684] [D loss: 1.765693, acc: 0.777344, f1: 0.259797] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 577/684] [D loss: 1.769603, acc: 0.773438, f1: 0.291082] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 578/684] [D loss: 1.765633, acc: 0.777344, f1: 0.259623] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 579/684] [D loss: 1.775295, acc: 0.767578, f1: 0.258803] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 580/684] [D loss: 1.775462, acc: 0.767578, f1: 0.232423] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 581/684] [D loss: 1.777404, acc: 0.765625, f1: 0.254978] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 582/684] [D loss: 1.781316, acc: 0.761719, f1: 0.256546] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 583/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258232] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 584/684] [D loss: 1.763743, acc: 0.779297, f1: 0.260087] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 585/684] [D loss: 1.757885, acc: 0.785156, f1: 0.287924] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 586/684] [D loss: 1.787182, acc: 0.755859, f1: 0.255688] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 587/684] [D loss: 1.800839, acc: 0.742188, f1: 0.253379] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 588/684] [D loss: 1.746032, acc: 0.796875, f1: 0.293509] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 589/684] [D loss: 1.773510, acc: 0.769531, f1: 0.283727] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 590/684] [D loss: 1.773509, acc: 0.769531, f1: 0.234517] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 591/684] [D loss: 1.773491, acc: 0.769531, f1: 0.260466] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 592/684] [D loss: 1.793041, acc: 0.750000, f1: 0.229115] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 593/684] [D loss: 1.781322, acc: 0.761719, f1: 0.236337] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 594/684] [D loss: 1.759838, acc: 0.783203, f1: 0.261873] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 595/684] [D loss: 1.761791, acc: 0.781250, f1: 0.258623] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 596/684] [D loss: 1.757786, acc: 0.785156, f1: 0.264318] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 597/684] [D loss: 1.785228, acc: 0.757812, f1: 0.285638] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 598/684] [D loss: 1.765695, acc: 0.777344, f1: 0.260869] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 599/684] [D loss: 1.748119, acc: 0.794922, f1: 0.264561] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 600/684] [D loss: 1.763744, acc: 0.779297, f1: 0.261858] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 601/684] [D loss: 1.773510, acc: 0.769531, f1: 0.255291] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 602/684] [D loss: 1.763740, acc: 0.779297, f1: 0.289003] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 603/684] [D loss: 1.759838, acc: 0.783203, f1: 0.237637] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 604/684] [D loss: 1.781321, acc: 0.761719, f1: 0.284870] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 605/684] [D loss: 1.791045, acc: 0.751953, f1: 0.257017] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 606/684] [D loss: 1.800853, acc: 0.742188, f1: 0.250254] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 607/684] [D loss: 1.785106, acc: 0.757812, f1: 0.256075] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 608/684] [D loss: 1.767639, acc: 0.775391, f1: 0.259643] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 609/684] [D loss: 1.789135, acc: 0.753906, f1: 0.230834] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 610/684] [D loss: 1.787182, acc: 0.755859, f1: 0.254804] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 611/684] [D loss: 1.779369, acc: 0.763672, f1: 0.258263] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 612/684] [D loss: 1.793041, acc: 0.750000, f1: 0.251034] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 613/684] [D loss: 1.765539, acc: 0.777344, f1: 0.259933] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 614/684] [D loss: 1.765692, acc: 0.777344, f1: 0.291983] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 615/684] [D loss: 1.744177, acc: 0.798828, f1: 0.240949] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 616/684] [D loss: 1.793041, acc: 0.750000, f1: 0.256546] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 617/684] [D loss: 1.779369, acc: 0.763672, f1: 0.288192] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 618/684] [D loss: 1.781263, acc: 0.761719, f1: 0.256742] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 619/684] [D loss: 1.783275, acc: 0.759766, f1: 0.253834] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 620/684] [D loss: 1.752025, acc: 0.791016, f1: 0.237645] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 621/684] [D loss: 1.746146, acc: 0.796875, f1: 0.264531] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 622/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256262] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 623/684] [D loss: 1.757885, acc: 0.785156, f1: 0.259031] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 624/684] [D loss: 1.763535, acc: 0.779297, f1: 0.262295] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 625/684] [D loss: 1.769595, acc: 0.773438, f1: 0.260348] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 626/684] [D loss: 1.773509, acc: 0.769531, f1: 0.259612] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 627/684] [D loss: 1.789135, acc: 0.753906, f1: 0.255803] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 628/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259801] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 629/684] [D loss: 1.787180, acc: 0.755859, f1: 0.319119] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 630/684] [D loss: 1.763712, acc: 0.779297, f1: 0.238017] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 631/684] [D loss: 1.775463, acc: 0.767578, f1: 0.288312] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 632/684] [D loss: 1.769603, acc: 0.773438, f1: 0.287832] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 633/684] [D loss: 1.798877, acc: 0.744141, f1: 0.281506] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 634/684] [D loss: 1.804759, acc: 0.738281, f1: 0.248328] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 635/684] [D loss: 1.779369, acc: 0.763672, f1: 0.255323] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 636/684] [D loss: 1.789135, acc: 0.753906, f1: 0.284072] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 637/684] [D loss: 1.761777, acc: 0.781250, f1: 0.261752] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 638/684] [D loss: 1.773510, acc: 0.769531, f1: 0.234410] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 639/684] [D loss: 1.767613, acc: 0.775391, f1: 0.260653] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 640/684] [D loss: 1.783275, acc: 0.759766, f1: 0.256542] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 641/684] [D loss: 1.761748, acc: 0.781250, f1: 0.258488] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 642/684] [D loss: 1.757885, acc: 0.785156, f1: 0.262150] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 643/684] [D loss: 1.765697, acc: 0.777344, f1: 0.260074] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 644/684] [D loss: 1.798848, acc: 0.744141, f1: 0.253317] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 645/684] [D loss: 1.738353, acc: 0.804688, f1: 0.243224] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 646/684] [D loss: 1.798900, acc: 0.744141, f1: 0.285495] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 647/684] [D loss: 1.808647, acc: 0.734375, f1: 0.230413] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 648/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259064] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 649/684] [D loss: 1.791028, acc: 0.751953, f1: 0.234387] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 650/684] [D loss: 1.777416, acc: 0.765625, f1: 0.285974] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 651/684] [D loss: 1.781315, acc: 0.761719, f1: 0.252566] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 652/684] [D loss: 1.798888, acc: 0.744141, f1: 0.250927] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 653/684] [D loss: 1.781322, acc: 0.761719, f1: 0.257206] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 654/684] [D loss: 1.781322, acc: 0.761719, f1: 0.260213] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 655/684] [D loss: 1.775462, acc: 0.767578, f1: 0.258279] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 656/684] [D loss: 1.775463, acc: 0.767578, f1: 0.259930] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 657/684] [D loss: 1.789134, acc: 0.753906, f1: 0.254015] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 658/684] [D loss: 1.785202, acc: 0.757812, f1: 0.280414] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 659/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258800] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 660/684] [D loss: 1.767581, acc: 0.775391, f1: 0.261553] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 661/684] [D loss: 1.783275, acc: 0.759766, f1: 0.233815] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 662/684] [D loss: 1.765697, acc: 0.777344, f1: 0.285422] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 663/684] [D loss: 1.785118, acc: 0.757812, f1: 0.255887] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 664/684] [D loss: 1.789098, acc: 0.753906, f1: 0.253095] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 665/684] [D loss: 1.793020, acc: 0.750000, f1: 0.255248] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 666/684] [D loss: 1.794989, acc: 0.748047, f1: 0.232796] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 667/684] [D loss: 1.775462, acc: 0.767578, f1: 0.259794] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 668/684] [D loss: 1.771550, acc: 0.771484, f1: 0.239980] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 669/684] [D loss: 1.755931, acc: 0.787109, f1: 0.261260] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 670/684] [D loss: 1.796917, acc: 0.746094, f1: 0.254683] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 671/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253401] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 672/684] [D loss: 1.779325, acc: 0.763672, f1: 0.258671] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 673/684] [D loss: 1.746166, acc: 0.796875, f1: 0.266011] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 674/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257960] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 675/684] [D loss: 1.791010, acc: 0.751953, f1: 0.253244] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 676/684] [D loss: 1.757879, acc: 0.785156, f1: 0.264592] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 677/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256071] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 678/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258888] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 679/684] [D loss: 1.783275, acc: 0.759766, f1: 0.258368] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 680/684] [D loss: 1.771556, acc: 0.771484, f1: 0.236352] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 681/684] [D loss: 1.759779, acc: 0.783203, f1: 0.258752] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 682/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258711] [G loss: -1.000000]\n",
      "[Epoch 2/5] [Batch 683/684] [D loss: 1.771557, acc: 0.771484, f1: 0.234264] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 0/684] [D loss: 1.777399, acc: 0.765625, f1: 0.257407] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 1/684] [D loss: 1.777390, acc: 0.765625, f1: 0.288620] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 2/684] [D loss: 1.761791, acc: 0.781250, f1: 0.288099] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 3/684] [D loss: 1.765429, acc: 0.777344, f1: 0.259133] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 4/684] [D loss: 1.763893, acc: 0.779297, f1: 0.262046] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 5/684] [D loss: 1.757885, acc: 0.785156, f1: 0.261383] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 6/684] [D loss: 1.767650, acc: 0.775391, f1: 0.322665] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 7/684] [D loss: 1.793041, acc: 0.750000, f1: 0.259361] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 8/684] [D loss: 1.749951, acc: 0.792969, f1: 0.262898] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 9/684] [D loss: 1.783274, acc: 0.759766, f1: 0.254685] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 10/684] [D loss: 1.785175, acc: 0.757812, f1: 0.253928] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 11/684] [D loss: 1.781322, acc: 0.761719, f1: 0.320933] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 12/684] [D loss: 1.793000, acc: 0.750000, f1: 0.253744] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 13/684] [D loss: 1.791014, acc: 0.751953, f1: 0.254843] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 14/684] [D loss: 1.763684, acc: 0.779297, f1: 0.260511] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 15/684] [D loss: 1.746132, acc: 0.796875, f1: 0.265167] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 16/684] [D loss: 1.775442, acc: 0.767578, f1: 0.258348] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 17/684] [D loss: 1.744152, acc: 0.798828, f1: 0.266179] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 18/684] [D loss: 1.734447, acc: 0.808594, f1: 0.297969] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 19/684] [D loss: 1.765697, acc: 0.777344, f1: 0.291198] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 20/684] [D loss: 1.767614, acc: 0.775391, f1: 0.258549] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 21/684] [D loss: 1.773510, acc: 0.769531, f1: 0.260521] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 22/684] [D loss: 1.785228, acc: 0.757812, f1: 0.233768] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 23/684] [D loss: 1.781261, acc: 0.761719, f1: 0.254924] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 24/684] [D loss: 1.757829, acc: 0.785156, f1: 0.264636] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 25/684] [D loss: 1.771528, acc: 0.771484, f1: 0.259234] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 26/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257272] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 27/684] [D loss: 1.773475, acc: 0.769531, f1: 0.257371] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 28/684] [D loss: 1.777351, acc: 0.765625, f1: 0.258537] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 29/684] [D loss: 1.791088, acc: 0.751953, f1: 0.230728] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 30/684] [D loss: 1.767635, acc: 0.775391, f1: 0.289631] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 31/684] [D loss: 1.785226, acc: 0.757812, f1: 0.254924] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 32/684] [D loss: 1.753977, acc: 0.789062, f1: 0.292742] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 33/684] [D loss: 1.757885, acc: 0.785156, f1: 0.262056] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 34/684] [D loss: 1.771557, acc: 0.771484, f1: 0.236431] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 35/684] [D loss: 1.769601, acc: 0.773438, f1: 0.258013] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 36/684] [D loss: 1.773455, acc: 0.769531, f1: 0.261161] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 37/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260094] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 38/684] [D loss: 1.742260, acc: 0.800781, f1: 0.263500] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 39/684] [D loss: 1.746157, acc: 0.796875, f1: 0.295773] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 40/684] [D loss: 1.755904, acc: 0.787109, f1: 0.239888] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 41/684] [D loss: 1.771491, acc: 0.771484, f1: 0.258980] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 42/684] [D loss: 1.767650, acc: 0.775391, f1: 0.261604] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 43/684] [D loss: 1.794991, acc: 0.748047, f1: 0.282839] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 44/684] [D loss: 1.773486, acc: 0.769531, f1: 0.256689] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 45/684] [D loss: 1.771544, acc: 0.771484, f1: 0.256685] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 46/684] [D loss: 1.763744, acc: 0.779297, f1: 0.261370] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 47/684] [D loss: 1.777416, acc: 0.765625, f1: 0.283292] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 48/684] [D loss: 1.789125, acc: 0.753906, f1: 0.232439] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 49/684] [D loss: 1.771557, acc: 0.771484, f1: 0.286685] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 50/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256099] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 51/684] [D loss: 1.775448, acc: 0.767578, f1: 0.260879] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 52/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261798] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 53/684] [D loss: 1.785162, acc: 0.757812, f1: 0.287435] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 54/684] [D loss: 1.746163, acc: 0.796875, f1: 0.262013] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 55/684] [D loss: 1.773508, acc: 0.769531, f1: 0.258399] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 56/684] [D loss: 1.794992, acc: 0.748047, f1: 0.251934] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 57/684] [D loss: 1.777416, acc: 0.765625, f1: 0.286310] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 58/684] [D loss: 1.765635, acc: 0.777344, f1: 0.263620] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 59/684] [D loss: 1.810619, acc: 0.732422, f1: 0.251026] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 60/684] [D loss: 1.761779, acc: 0.781250, f1: 0.260983] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 61/684] [D loss: 1.777415, acc: 0.765625, f1: 0.257746] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 62/684] [D loss: 1.794994, acc: 0.748047, f1: 0.258301] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 63/684] [D loss: 1.755902, acc: 0.787109, f1: 0.263660] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 64/684] [D loss: 1.775457, acc: 0.767578, f1: 0.258570] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 65/684] [D loss: 1.775463, acc: 0.767578, f1: 0.288707] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 66/684] [D loss: 1.750079, acc: 0.792969, f1: 0.294109] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 67/684] [D loss: 1.746165, acc: 0.796875, f1: 0.265161] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 68/684] [D loss: 1.792944, acc: 0.750000, f1: 0.254958] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 69/684] [D loss: 1.757819, acc: 0.785156, f1: 0.327935] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 70/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256987] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 71/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256723] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 72/684] [D loss: 1.781313, acc: 0.761719, f1: 0.287256] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 73/684] [D loss: 1.759836, acc: 0.783203, f1: 0.262826] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 74/684] [D loss: 1.783128, acc: 0.759766, f1: 0.283474] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 75/684] [D loss: 1.785221, acc: 0.757812, f1: 0.254851] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 76/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259587] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 77/684] [D loss: 1.726635, acc: 0.816406, f1: 0.337137] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 78/684] [D loss: 1.775460, acc: 0.767578, f1: 0.322912] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 79/684] [D loss: 1.757860, acc: 0.785156, f1: 0.239510] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 80/684] [D loss: 1.765697, acc: 0.777344, f1: 0.260301] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 81/684] [D loss: 1.775445, acc: 0.767578, f1: 0.290457] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 82/684] [D loss: 1.773510, acc: 0.769531, f1: 0.234606] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 83/684] [D loss: 1.761790, acc: 0.781250, f1: 0.262737] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 84/684] [D loss: 1.767650, acc: 0.775391, f1: 0.235903] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 85/684] [D loss: 1.779361, acc: 0.763672, f1: 0.258547] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 86/684] [D loss: 1.777389, acc: 0.765625, f1: 0.255722] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 87/684] [D loss: 1.785228, acc: 0.757812, f1: 0.257105] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 88/684] [D loss: 1.787181, acc: 0.755859, f1: 0.282284] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 89/684] [D loss: 1.769603, acc: 0.773438, f1: 0.260958] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 90/684] [D loss: 1.750013, acc: 0.792969, f1: 0.289463] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 91/684] [D loss: 1.779305, acc: 0.763672, f1: 0.259134] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 92/684] [D loss: 1.759814, acc: 0.783203, f1: 0.262197] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 93/684] [D loss: 1.796947, acc: 0.746094, f1: 0.250919] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 94/684] [D loss: 1.787182, acc: 0.755859, f1: 0.250075] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 95/684] [D loss: 1.773507, acc: 0.769531, f1: 0.257398] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 96/684] [D loss: 1.748118, acc: 0.794922, f1: 0.260921] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 97/684] [D loss: 1.771555, acc: 0.771484, f1: 0.291551] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 98/684] [D loss: 1.777416, acc: 0.765625, f1: 0.258158] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 99/684] [D loss: 1.785228, acc: 0.757812, f1: 0.257211] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 100/684] [D loss: 1.775417, acc: 0.767578, f1: 0.287295] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 101/684] [D loss: 1.798900, acc: 0.744141, f1: 0.255134] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 102/684] [D loss: 1.779369, acc: 0.763672, f1: 0.286287] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 103/684] [D loss: 1.777393, acc: 0.765625, f1: 0.260679] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 104/684] [D loss: 1.763740, acc: 0.779297, f1: 0.262876] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 105/684] [D loss: 1.759838, acc: 0.783203, f1: 0.235955] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 106/684] [D loss: 1.771552, acc: 0.771484, f1: 0.258289] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 107/684] [D loss: 1.798883, acc: 0.744141, f1: 0.252667] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 108/684] [D loss: 1.765631, acc: 0.777344, f1: 0.259137] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 109/684] [D loss: 1.791088, acc: 0.751953, f1: 0.285954] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 110/684] [D loss: 1.763744, acc: 0.779297, f1: 0.288248] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 111/684] [D loss: 1.771556, acc: 0.771484, f1: 0.256622] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 112/684] [D loss: 1.775462, acc: 0.767578, f1: 0.289246] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 113/684] [D loss: 1.740307, acc: 0.802734, f1: 0.291725] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 114/684] [D loss: 1.812565, acc: 0.730469, f1: 0.254931] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 115/684] [D loss: 1.787182, acc: 0.755859, f1: 0.255081] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 116/684] [D loss: 1.775452, acc: 0.767578, f1: 0.259559] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 117/684] [D loss: 1.779349, acc: 0.763672, f1: 0.255634] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 118/684] [D loss: 1.777411, acc: 0.765625, f1: 0.257059] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 119/684] [D loss: 1.779361, acc: 0.763672, f1: 0.257498] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 120/684] [D loss: 1.789135, acc: 0.753906, f1: 0.256588] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 121/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257106] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 122/684] [D loss: 1.750009, acc: 0.792969, f1: 0.294542] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 123/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259167] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 124/684] [D loss: 1.767650, acc: 0.775391, f1: 0.236477] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 125/684] [D loss: 1.781306, acc: 0.761719, f1: 0.229786] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 126/684] [D loss: 1.773508, acc: 0.769531, f1: 0.258478] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 127/684] [D loss: 1.791088, acc: 0.751953, f1: 0.254370] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 128/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259589] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 129/684] [D loss: 1.742260, acc: 0.800781, f1: 0.295223] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 130/684] [D loss: 1.789135, acc: 0.753906, f1: 0.254436] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 131/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284707] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 132/684] [D loss: 1.753978, acc: 0.789062, f1: 0.263255] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 133/684] [D loss: 1.781322, acc: 0.761719, f1: 0.233024] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 134/684] [D loss: 1.757828, acc: 0.785156, f1: 0.263706] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 135/684] [D loss: 1.750072, acc: 0.792969, f1: 0.266769] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 136/684] [D loss: 1.798900, acc: 0.744141, f1: 0.283606] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 137/684] [D loss: 1.793011, acc: 0.750000, f1: 0.250765] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 138/684] [D loss: 1.802682, acc: 0.740234, f1: 0.254223] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 139/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259686] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 140/684] [D loss: 1.802795, acc: 0.740234, f1: 0.251490] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 141/684] [D loss: 1.752025, acc: 0.791016, f1: 0.291572] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 142/684] [D loss: 1.789135, acc: 0.753906, f1: 0.258940] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 143/684] [D loss: 1.765697, acc: 0.777344, f1: 0.291755] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 144/684] [D loss: 1.769603, acc: 0.773438, f1: 0.264174] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 145/684] [D loss: 1.753978, acc: 0.789062, f1: 0.292859] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 146/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259055] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 147/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256764] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 148/684] [D loss: 1.771548, acc: 0.771484, f1: 0.260201] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 149/684] [D loss: 1.759805, acc: 0.783203, f1: 0.293098] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 150/684] [D loss: 1.792974, acc: 0.750000, f1: 0.257619] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 151/684] [D loss: 1.779369, acc: 0.763672, f1: 0.257746] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 152/684] [D loss: 1.761791, acc: 0.781250, f1: 0.288403] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 153/684] [D loss: 1.759826, acc: 0.783203, f1: 0.264175] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 154/684] [D loss: 1.763619, acc: 0.779297, f1: 0.262991] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 155/684] [D loss: 1.753975, acc: 0.789062, f1: 0.261687] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 156/684] [D loss: 1.755929, acc: 0.787109, f1: 0.260828] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 157/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260407] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 158/684] [D loss: 1.761791, acc: 0.781250, f1: 0.237726] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 159/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259785] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 160/684] [D loss: 1.738353, acc: 0.804688, f1: 0.267471] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 161/684] [D loss: 1.748119, acc: 0.794922, f1: 0.266842] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 162/684] [D loss: 1.794991, acc: 0.748047, f1: 0.228070] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 163/684] [D loss: 1.791088, acc: 0.751953, f1: 0.254024] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 164/684] [D loss: 1.757878, acc: 0.785156, f1: 0.261044] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 165/684] [D loss: 1.791088, acc: 0.751953, f1: 0.258015] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 166/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257569] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 167/684] [D loss: 1.773429, acc: 0.769531, f1: 0.258873] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 168/684] [D loss: 1.769591, acc: 0.773438, f1: 0.289971] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 169/684] [D loss: 1.767591, acc: 0.775391, f1: 0.260318] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 170/684] [D loss: 1.730541, acc: 0.812500, f1: 0.243860] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 171/684] [D loss: 1.769572, acc: 0.773438, f1: 0.261484] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 172/684] [D loss: 1.746131, acc: 0.796875, f1: 0.293050] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 173/684] [D loss: 1.794994, acc: 0.748047, f1: 0.248625] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 174/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257905] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 175/684] [D loss: 1.828618, acc: 0.714844, f1: 0.244756] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 176/684] [D loss: 1.793041, acc: 0.750000, f1: 0.281118] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 177/684] [D loss: 1.794958, acc: 0.748047, f1: 0.231540] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 178/684] [D loss: 1.773510, acc: 0.769531, f1: 0.254616] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 179/684] [D loss: 1.771557, acc: 0.771484, f1: 0.255120] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 180/684] [D loss: 1.779369, acc: 0.763672, f1: 0.286082] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 181/684] [D loss: 1.775463, acc: 0.767578, f1: 0.236732] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 182/684] [D loss: 1.785165, acc: 0.757812, f1: 0.285208] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 183/684] [D loss: 1.787182, acc: 0.755859, f1: 0.257868] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 184/684] [D loss: 1.787182, acc: 0.755859, f1: 0.232763] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 185/684] [D loss: 1.767635, acc: 0.775391, f1: 0.237119] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 186/684] [D loss: 1.781322, acc: 0.761719, f1: 0.232179] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 187/684] [D loss: 1.752025, acc: 0.791016, f1: 0.262658] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 188/684] [D loss: 1.777336, acc: 0.765625, f1: 0.256996] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 189/684] [D loss: 1.777416, acc: 0.765625, f1: 0.255939] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 190/684] [D loss: 1.787182, acc: 0.755859, f1: 0.234263] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 191/684] [D loss: 1.785228, acc: 0.757812, f1: 0.233530] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 192/684] [D loss: 1.793041, acc: 0.750000, f1: 0.281596] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 193/684] [D loss: 1.785189, acc: 0.757812, f1: 0.254378] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 194/684] [D loss: 1.734431, acc: 0.808594, f1: 0.267573] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 195/684] [D loss: 1.793034, acc: 0.750000, f1: 0.253762] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 196/684] [D loss: 1.775362, acc: 0.767578, f1: 0.256824] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 197/684] [D loss: 1.789135, acc: 0.753906, f1: 0.281404] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 198/684] [D loss: 1.767642, acc: 0.775391, f1: 0.263207] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 199/684] [D loss: 1.771467, acc: 0.771484, f1: 0.260422] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 200/684] [D loss: 1.777416, acc: 0.765625, f1: 0.260565] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 201/684] [D loss: 1.763744, acc: 0.779297, f1: 0.237420] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 202/684] [D loss: 1.761789, acc: 0.781250, f1: 0.289205] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 203/684] [D loss: 1.771557, acc: 0.771484, f1: 0.287468] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 204/684] [D loss: 1.769584, acc: 0.773438, f1: 0.258891] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 205/684] [D loss: 1.781258, acc: 0.761719, f1: 0.233512] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 206/684] [D loss: 1.789142, acc: 0.753906, f1: 0.257163] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 207/684] [D loss: 1.785226, acc: 0.757812, f1: 0.254525] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 208/684] [D loss: 1.771556, acc: 0.771484, f1: 0.289219] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 209/684] [D loss: 1.759821, acc: 0.783203, f1: 0.261632] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 210/684] [D loss: 1.765697, acc: 0.777344, f1: 0.288515] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 211/684] [D loss: 1.769584, acc: 0.773438, f1: 0.259058] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 212/684] [D loss: 1.771554, acc: 0.771484, f1: 0.259951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 213/684] [D loss: 1.771538, acc: 0.771484, f1: 0.258759] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 214/684] [D loss: 1.793031, acc: 0.750000, f1: 0.281102] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 215/684] [D loss: 1.773508, acc: 0.769531, f1: 0.256744] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 216/684] [D loss: 1.789133, acc: 0.753906, f1: 0.232136] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 217/684] [D loss: 1.791086, acc: 0.751953, f1: 0.283347] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 218/684] [D loss: 1.791087, acc: 0.751953, f1: 0.285523] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 219/684] [D loss: 1.775439, acc: 0.767578, f1: 0.287681] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 220/684] [D loss: 1.793041, acc: 0.750000, f1: 0.319849] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 221/684] [D loss: 1.777416, acc: 0.765625, f1: 0.256825] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 222/684] [D loss: 1.771443, acc: 0.771484, f1: 0.259710] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 223/684] [D loss: 1.765678, acc: 0.777344, f1: 0.262932] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 224/684] [D loss: 1.783234, acc: 0.759766, f1: 0.254311] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 225/684] [D loss: 1.792983, acc: 0.750000, f1: 0.249998] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 226/684] [D loss: 1.767609, acc: 0.775391, f1: 0.260911] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 227/684] [D loss: 1.791087, acc: 0.751953, f1: 0.258713] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 228/684] [D loss: 1.775413, acc: 0.767578, f1: 0.287171] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 229/684] [D loss: 1.777416, acc: 0.765625, f1: 0.256475] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 230/684] [D loss: 1.783274, acc: 0.759766, f1: 0.255889] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 231/684] [D loss: 1.759820, acc: 0.783203, f1: 0.261869] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 232/684] [D loss: 1.783240, acc: 0.759766, f1: 0.257685] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 233/684] [D loss: 1.769599, acc: 0.773438, f1: 0.237478] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 234/684] [D loss: 1.763744, acc: 0.779297, f1: 0.291363] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 235/684] [D loss: 1.763702, acc: 0.779297, f1: 0.259487] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 236/684] [D loss: 1.787173, acc: 0.755859, f1: 0.259045] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 237/684] [D loss: 1.773464, acc: 0.769531, f1: 0.258996] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 238/684] [D loss: 1.769543, acc: 0.773438, f1: 0.323803] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 239/684] [D loss: 1.771557, acc: 0.771484, f1: 0.234472] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 240/684] [D loss: 1.767596, acc: 0.775391, f1: 0.262223] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 241/684] [D loss: 1.783271, acc: 0.759766, f1: 0.260328] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 242/684] [D loss: 1.773417, acc: 0.769531, f1: 0.255705] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 243/684] [D loss: 1.794994, acc: 0.748047, f1: 0.229639] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 244/684] [D loss: 1.757853, acc: 0.785156, f1: 0.261201] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 245/684] [D loss: 1.767650, acc: 0.775391, f1: 0.262027] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 246/684] [D loss: 1.761791, acc: 0.781250, f1: 0.259859] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 247/684] [D loss: 1.765664, acc: 0.777344, f1: 0.261036] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 248/684] [D loss: 1.755862, acc: 0.787109, f1: 0.263875] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 249/684] [D loss: 1.796947, acc: 0.746094, f1: 0.253765] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 250/684] [D loss: 1.777416, acc: 0.765625, f1: 0.258330] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 251/684] [D loss: 1.798892, acc: 0.744141, f1: 0.252703] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 252/684] [D loss: 1.808567, acc: 0.734375, f1: 0.250393] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 253/684] [D loss: 1.769564, acc: 0.773438, f1: 0.291203] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 254/684] [D loss: 1.765631, acc: 0.777344, f1: 0.259588] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 255/684] [D loss: 1.734428, acc: 0.808594, f1: 0.298384] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 256/684] [D loss: 1.755835, acc: 0.787109, f1: 0.237602] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 257/684] [D loss: 1.777338, acc: 0.765625, f1: 0.256899] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 258/684] [D loss: 1.783274, acc: 0.759766, f1: 0.285685] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 259/684] [D loss: 1.746158, acc: 0.796875, f1: 0.264366] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 260/684] [D loss: 1.771556, acc: 0.771484, f1: 0.257221] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 261/684] [D loss: 1.777416, acc: 0.765625, f1: 0.261176] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 262/684] [D loss: 1.728581, acc: 0.814453, f1: 0.269643] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 263/684] [D loss: 1.777327, acc: 0.765625, f1: 0.258195] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 264/684] [D loss: 1.785098, acc: 0.757812, f1: 0.253276] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 265/684] [D loss: 1.767611, acc: 0.775391, f1: 0.259306] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 266/684] [D loss: 1.802717, acc: 0.740234, f1: 0.250378] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 267/684] [D loss: 1.744133, acc: 0.798828, f1: 0.294870] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 268/684] [D loss: 1.755857, acc: 0.787109, f1: 0.259940] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 269/684] [D loss: 1.785342, acc: 0.757812, f1: 0.255371] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 270/684] [D loss: 1.734438, acc: 0.808594, f1: 0.243999] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 271/684] [D loss: 1.767482, acc: 0.775391, f1: 0.254679] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 272/684] [D loss: 1.763614, acc: 0.779297, f1: 0.238547] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 273/684] [D loss: 1.785223, acc: 0.757812, f1: 0.257253] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 274/684] [D loss: 1.769536, acc: 0.773438, f1: 0.286143] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 275/684] [D loss: 1.781302, acc: 0.761719, f1: 0.283809] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 276/684] [D loss: 1.752024, acc: 0.791016, f1: 0.261922] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 277/684] [D loss: 1.779292, acc: 0.763672, f1: 0.232438] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 278/684] [D loss: 1.783275, acc: 0.759766, f1: 0.256032] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 279/684] [D loss: 1.759814, acc: 0.783203, f1: 0.289490] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 280/684] [D loss: 1.765687, acc: 0.777344, f1: 0.327534] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 281/684] [D loss: 1.777400, acc: 0.765625, f1: 0.254360] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 282/684] [D loss: 1.752025, acc: 0.791016, f1: 0.293860] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 283/684] [D loss: 1.763682, acc: 0.779297, f1: 0.324705] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 284/684] [D loss: 1.752025, acc: 0.791016, f1: 0.262603] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 285/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260786] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 286/684] [D loss: 1.796947, acc: 0.746094, f1: 0.251114] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 287/684] [D loss: 1.791016, acc: 0.751953, f1: 0.255505] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 288/684] [D loss: 1.800786, acc: 0.742188, f1: 0.252234] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 289/684] [D loss: 1.789135, acc: 0.753906, f1: 0.232090] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 290/684] [D loss: 1.765666, acc: 0.777344, f1: 0.235581] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 291/684] [D loss: 1.789009, acc: 0.753906, f1: 0.284633] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 292/684] [D loss: 1.771557, acc: 0.771484, f1: 0.290331] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 293/684] [D loss: 1.757853, acc: 0.785156, f1: 0.264888] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 294/684] [D loss: 1.757798, acc: 0.785156, f1: 0.292486] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 295/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261698] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 296/684] [D loss: 1.781322, acc: 0.761719, f1: 0.253581] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 297/684] [D loss: 1.785228, acc: 0.757812, f1: 0.258705] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 298/684] [D loss: 1.783275, acc: 0.759766, f1: 0.288636] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 299/684] [D loss: 1.756924, acc: 0.785156, f1: 0.292029] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 300/684] [D loss: 1.775400, acc: 0.767578, f1: 0.324848] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 301/684] [D loss: 1.789015, acc: 0.753906, f1: 0.232655] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 302/684] [D loss: 1.771557, acc: 0.771484, f1: 0.232021] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 303/684] [D loss: 1.765643, acc: 0.777344, f1: 0.289519] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 304/684] [D loss: 1.751916, acc: 0.791016, f1: 0.263907] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 305/684] [D loss: 1.781240, acc: 0.761719, f1: 0.257509] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 306/684] [D loss: 1.787143, acc: 0.755859, f1: 0.253050] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 307/684] [D loss: 1.773427, acc: 0.769531, f1: 0.260951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 308/684] [D loss: 1.761777, acc: 0.781250, f1: 0.260298] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 309/684] [D loss: 1.769580, acc: 0.773438, f1: 0.290052] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 310/684] [D loss: 1.761788, acc: 0.781250, f1: 0.260181] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 311/684] [D loss: 1.753978, acc: 0.789062, f1: 0.238671] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 312/684] [D loss: 1.771961, acc: 0.771484, f1: 0.258961] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 313/684] [D loss: 1.749936, acc: 0.792969, f1: 0.261294] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 314/684] [D loss: 1.773463, acc: 0.769531, f1: 0.262958] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 315/684] [D loss: 1.761749, acc: 0.781250, f1: 0.291061] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 316/684] [D loss: 1.785089, acc: 0.757812, f1: 0.255545] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 317/684] [D loss: 1.781290, acc: 0.761719, f1: 0.254064] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 318/684] [D loss: 1.790948, acc: 0.751953, f1: 0.254879] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 319/684] [D loss: 1.746095, acc: 0.796875, f1: 0.263340] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 320/684] [D loss: 1.769583, acc: 0.773438, f1: 0.258823] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 321/684] [D loss: 1.753907, acc: 0.789062, f1: 0.290205] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 322/684] [D loss: 1.753854, acc: 0.789062, f1: 0.262248] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 323/684] [D loss: 1.781223, acc: 0.761719, f1: 0.259155] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 324/684] [D loss: 1.769373, acc: 0.773438, f1: 0.285564] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 325/684] [D loss: 1.775377, acc: 0.767578, f1: 0.258307] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 326/684] [D loss: 1.742243, acc: 0.800781, f1: 0.293262] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 327/684] [D loss: 1.783273, acc: 0.759766, f1: 0.254185] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 328/684] [D loss: 1.792761, acc: 0.750000, f1: 0.251834] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 329/684] [D loss: 1.765636, acc: 0.777344, f1: 0.257916] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 330/684] [D loss: 1.773258, acc: 0.769531, f1: 0.255185] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 331/684] [D loss: 1.765597, acc: 0.777344, f1: 0.287063] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 332/684] [D loss: 1.806584, acc: 0.736328, f1: 0.249441] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 333/684] [D loss: 1.777130, acc: 0.765625, f1: 0.257477] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 334/684] [D loss: 1.759763, acc: 0.783203, f1: 0.239362] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 335/684] [D loss: 1.783259, acc: 0.759766, f1: 0.285934] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 336/684] [D loss: 1.781150, acc: 0.761719, f1: 0.254906] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 337/684] [D loss: 1.779296, acc: 0.763672, f1: 0.288269] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 338/684] [D loss: 1.769599, acc: 0.773438, f1: 0.256634] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 339/684] [D loss: 1.781230, acc: 0.761719, f1: 0.234449] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 340/684] [D loss: 1.775396, acc: 0.767578, f1: 0.259084] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 341/684] [D loss: 1.769538, acc: 0.773438, f1: 0.237134] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 342/684] [D loss: 1.757884, acc: 0.785156, f1: 0.263261] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 343/684] [D loss: 1.769465, acc: 0.773438, f1: 0.289398] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 344/684] [D loss: 1.763729, acc: 0.779297, f1: 0.257861] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 345/684] [D loss: 1.769499, acc: 0.773438, f1: 0.258581] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 346/684] [D loss: 1.759836, acc: 0.783203, f1: 0.259424] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 347/684] [D loss: 1.783275, acc: 0.759766, f1: 0.258497] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 348/684] [D loss: 1.771430, acc: 0.771484, f1: 0.288449] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 349/684] [D loss: 1.757883, acc: 0.785156, f1: 0.261725] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 350/684] [D loss: 1.781299, acc: 0.761719, f1: 0.257732] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 351/684] [D loss: 1.783263, acc: 0.759766, f1: 0.232188] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 352/684] [D loss: 1.751992, acc: 0.791016, f1: 0.262781] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 353/684] [D loss: 1.751871, acc: 0.791016, f1: 0.262816] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 354/684] [D loss: 1.781243, acc: 0.761719, f1: 0.259364] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 355/684] [D loss: 1.765617, acc: 0.777344, f1: 0.261417] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 356/684] [D loss: 1.775397, acc: 0.767578, f1: 0.255692] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 357/684] [D loss: 1.773454, acc: 0.769531, f1: 0.259396] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 358/684] [D loss: 1.775417, acc: 0.767578, f1: 0.257441] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 359/684] [D loss: 1.781315, acc: 0.761719, f1: 0.258636] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 360/684] [D loss: 1.789135, acc: 0.753906, f1: 0.250101] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 361/684] [D loss: 1.761790, acc: 0.781250, f1: 0.325911] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 362/684] [D loss: 1.738353, acc: 0.804688, f1: 0.240247] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 363/684] [D loss: 1.740286, acc: 0.802734, f1: 0.263953] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 364/684] [D loss: 1.793041, acc: 0.750000, f1: 0.278887] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 365/684] [D loss: 1.783129, acc: 0.759766, f1: 0.253214] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 366/684] [D loss: 1.765697, acc: 0.777344, f1: 0.257716] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 367/684] [D loss: 1.808590, acc: 0.734375, f1: 0.252729] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 368/684] [D loss: 1.796936, acc: 0.746094, f1: 0.230130] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 369/684] [D loss: 1.806446, acc: 0.736328, f1: 0.227574] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 370/684] [D loss: 1.777356, acc: 0.765625, f1: 0.287832] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 371/684] [D loss: 1.781208, acc: 0.761719, f1: 0.258766] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 372/684] [D loss: 1.757717, acc: 0.785156, f1: 0.259930] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 373/684] [D loss: 1.746165, acc: 0.796875, f1: 0.261917] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 374/684] [D loss: 1.794760, acc: 0.748047, f1: 0.253189] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 375/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259632] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 376/684] [D loss: 1.757800, acc: 0.785156, f1: 0.289091] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 377/684] [D loss: 1.763715, acc: 0.779297, f1: 0.237634] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 378/684] [D loss: 1.767647, acc: 0.775391, f1: 0.262054] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 379/684] [D loss: 1.796932, acc: 0.746094, f1: 0.252564] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 380/684] [D loss: 1.749914, acc: 0.792969, f1: 0.264089] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 381/684] [D loss: 1.777378, acc: 0.765625, f1: 0.257472] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 382/684] [D loss: 1.745938, acc: 0.796875, f1: 0.291900] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 383/684] [D loss: 1.765599, acc: 0.777344, f1: 0.235912] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 384/684] [D loss: 1.757839, acc: 0.785156, f1: 0.289874] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 385/684] [D loss: 1.771535, acc: 0.771484, f1: 0.289227] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 386/684] [D loss: 1.759838, acc: 0.783203, f1: 0.262494] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 387/684] [D loss: 1.781279, acc: 0.761719, f1: 0.256120] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 388/684] [D loss: 1.796843, acc: 0.746094, f1: 0.251451] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 389/684] [D loss: 1.788976, acc: 0.753906, f1: 0.282023] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 390/684] [D loss: 1.753904, acc: 0.789062, f1: 0.259261] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 391/684] [D loss: 1.775397, acc: 0.767578, f1: 0.258854] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 392/684] [D loss: 1.759817, acc: 0.783203, f1: 0.261336] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 393/684] [D loss: 1.787049, acc: 0.755859, f1: 0.256943] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 394/684] [D loss: 1.765505, acc: 0.777344, f1: 0.256269] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 395/684] [D loss: 1.777381, acc: 0.765625, f1: 0.256671] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 396/684] [D loss: 1.775382, acc: 0.767578, f1: 0.258640] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 397/684] [D loss: 1.794994, acc: 0.748047, f1: 0.225304] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 398/684] [D loss: 1.775278, acc: 0.767578, f1: 0.286301] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 399/684] [D loss: 1.777351, acc: 0.765625, f1: 0.231913] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 400/684] [D loss: 1.757861, acc: 0.785156, f1: 0.261491] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 401/684] [D loss: 1.771499, acc: 0.771484, f1: 0.261234] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 402/684] [D loss: 1.763716, acc: 0.779297, f1: 0.282194] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 403/684] [D loss: 1.746166, acc: 0.796875, f1: 0.290192] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 404/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259252] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 405/684] [D loss: 1.757818, acc: 0.785156, f1: 0.261202] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 406/684] [D loss: 1.787179, acc: 0.755859, f1: 0.256697] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 407/684] [D loss: 1.753976, acc: 0.789062, f1: 0.262237] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 408/684] [D loss: 1.779369, acc: 0.763672, f1: 0.256175] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 409/684] [D loss: 1.765695, acc: 0.777344, f1: 0.257193] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 410/684] [D loss: 1.755931, acc: 0.787109, f1: 0.235465] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 411/684] [D loss: 1.767644, acc: 0.775391, f1: 0.259191] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 412/684] [D loss: 1.787182, acc: 0.755859, f1: 0.318786] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 413/684] [D loss: 1.767650, acc: 0.775391, f1: 0.260747] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 414/684] [D loss: 1.771493, acc: 0.771484, f1: 0.258821] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 415/684] [D loss: 1.755931, acc: 0.787109, f1: 0.262503] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 416/684] [D loss: 1.742232, acc: 0.800781, f1: 0.240490] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 417/684] [D loss: 1.777416, acc: 0.765625, f1: 0.256079] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 418/684] [D loss: 1.777400, acc: 0.765625, f1: 0.251828] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 419/684] [D loss: 1.771434, acc: 0.771484, f1: 0.258380] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 420/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260039] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 421/684] [D loss: 1.771534, acc: 0.771484, f1: 0.259804] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 422/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258659] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 423/684] [D loss: 1.755932, acc: 0.787109, f1: 0.289734] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 424/684] [D loss: 1.779369, acc: 0.763672, f1: 0.258971] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 425/684] [D loss: 1.761791, acc: 0.781250, f1: 0.235872] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 426/684] [D loss: 1.769603, acc: 0.773438, f1: 0.257937] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 427/684] [D loss: 1.765619, acc: 0.777344, f1: 0.288470] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 428/684] [D loss: 1.781202, acc: 0.761719, f1: 0.256330] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 429/684] [D loss: 1.779352, acc: 0.763672, f1: 0.258998] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 430/684] [D loss: 1.753908, acc: 0.789062, f1: 0.294629] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 431/684] [D loss: 1.771556, acc: 0.771484, f1: 0.255689] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 432/684] [D loss: 1.763716, acc: 0.779297, f1: 0.260545] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 433/684] [D loss: 1.769603, acc: 0.773438, f1: 0.258951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 434/684] [D loss: 1.777251, acc: 0.765625, f1: 0.258236] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 435/684] [D loss: 1.775463, acc: 0.767578, f1: 0.254338] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 436/684] [D loss: 1.757885, acc: 0.785156, f1: 0.261889] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 437/684] [D loss: 1.759838, acc: 0.783203, f1: 0.260673] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 438/684] [D loss: 1.759815, acc: 0.783203, f1: 0.262396] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 439/684] [D loss: 1.790997, acc: 0.751953, f1: 0.250669] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 440/684] [D loss: 1.777372, acc: 0.765625, f1: 0.254900] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 441/684] [D loss: 1.771501, acc: 0.771484, f1: 0.258763] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 442/684] [D loss: 1.794994, acc: 0.748047, f1: 0.253992] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 443/684] [D loss: 1.779374, acc: 0.763672, f1: 0.230807] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 444/684] [D loss: 1.787182, acc: 0.755859, f1: 0.232495] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 445/684] [D loss: 1.767657, acc: 0.775391, f1: 0.259903] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 446/684] [D loss: 1.771557, acc: 0.771484, f1: 0.255759] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 447/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260567] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 448/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259963] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 449/684] [D loss: 1.757885, acc: 0.785156, f1: 0.259302] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 450/684] [D loss: 1.761791, acc: 0.781250, f1: 0.291319] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 451/684] [D loss: 1.794991, acc: 0.748047, f1: 0.253639] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 452/684] [D loss: 1.755932, acc: 0.787109, f1: 0.237706] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 453/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256932] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 454/684] [D loss: 1.769538, acc: 0.773438, f1: 0.251759] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 455/684] [D loss: 1.763744, acc: 0.779297, f1: 0.257895] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 456/684] [D loss: 1.757885, acc: 0.785156, f1: 0.257033] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 457/684] [D loss: 1.781322, acc: 0.761719, f1: 0.255429] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 458/684] [D loss: 1.783275, acc: 0.759766, f1: 0.257086] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 459/684] [D loss: 1.787182, acc: 0.755859, f1: 0.283986] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 460/684] [D loss: 1.777278, acc: 0.765625, f1: 0.258163] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 461/684] [D loss: 1.793041, acc: 0.750000, f1: 0.252787] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 462/684] [D loss: 1.761791, acc: 0.781250, f1: 0.283859] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 463/684] [D loss: 1.753978, acc: 0.789062, f1: 0.289517] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 464/684] [D loss: 1.761791, acc: 0.781250, f1: 0.259394] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 465/684] [D loss: 1.820336, acc: 0.722656, f1: 0.246379] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 466/684] [D loss: 1.769603, acc: 0.773438, f1: 0.288967] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 467/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257745] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 468/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258597] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 469/684] [D loss: 1.748119, acc: 0.794922, f1: 0.262568] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 470/684] [D loss: 1.775463, acc: 0.767578, f1: 0.288293] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 471/684] [D loss: 1.765662, acc: 0.777344, f1: 0.324078] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 472/684] [D loss: 1.765696, acc: 0.777344, f1: 0.285495] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 473/684] [D loss: 1.794994, acc: 0.748047, f1: 0.281385] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 474/684] [D loss: 1.753978, acc: 0.789062, f1: 0.258935] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 475/684] [D loss: 1.775463, acc: 0.767578, f1: 0.259806] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 476/684] [D loss: 1.791088, acc: 0.751953, f1: 0.281129] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 477/684] [D loss: 1.785228, acc: 0.757812, f1: 0.282344] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 478/684] [D loss: 1.796947, acc: 0.746094, f1: 0.249487] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 479/684] [D loss: 1.774177, acc: 0.769531, f1: 0.257126] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 480/684] [D loss: 1.777416, acc: 0.765625, f1: 0.279885] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 481/684] [D loss: 1.788684, acc: 0.753906, f1: 0.252052] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 482/684] [D loss: 1.769616, acc: 0.773438, f1: 0.259172] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 483/684] [D loss: 1.785228, acc: 0.757812, f1: 0.231126] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 484/684] [D loss: 1.767650, acc: 0.775391, f1: 0.261985] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 485/684] [D loss: 1.764511, acc: 0.779297, f1: 0.256764] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 486/684] [D loss: 1.759838, acc: 0.783203, f1: 0.285680] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 487/684] [D loss: 1.771556, acc: 0.771484, f1: 0.289385] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 488/684] [D loss: 1.753978, acc: 0.789062, f1: 0.236531] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 489/684] [D loss: 1.794994, acc: 0.748047, f1: 0.251515] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 490/684] [D loss: 1.761184, acc: 0.781250, f1: 0.289795] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 491/684] [D loss: 1.771530, acc: 0.771484, f1: 0.256709] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 492/684] [D loss: 1.759838, acc: 0.783203, f1: 0.287046] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 493/684] [D loss: 1.767650, acc: 0.775391, f1: 0.288341] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 494/684] [D loss: 1.777416, acc: 0.765625, f1: 0.254951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 495/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256012] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 496/684] [D loss: 1.777416, acc: 0.765625, f1: 0.285629] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 497/684] [D loss: 1.793041, acc: 0.750000, f1: 0.257405] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 498/684] [D loss: 1.742260, acc: 0.800781, f1: 0.263090] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 499/684] [D loss: 1.755867, acc: 0.787109, f1: 0.258951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 500/684] [D loss: 1.765697, acc: 0.777344, f1: 0.255307] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 501/684] [D loss: 1.763744, acc: 0.779297, f1: 0.290601] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 502/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256586] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 503/684] [D loss: 1.783275, acc: 0.759766, f1: 0.288400] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 504/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258917] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 505/684] [D loss: 1.765697, acc: 0.777344, f1: 0.261246] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 506/684] [D loss: 1.791088, acc: 0.751953, f1: 0.257996] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 507/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259342] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 508/684] [D loss: 1.767650, acc: 0.775391, f1: 0.257327] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 509/684] [D loss: 1.767650, acc: 0.775391, f1: 0.286101] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 510/684] [D loss: 1.771552, acc: 0.771484, f1: 0.255773] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 511/684] [D loss: 1.759838, acc: 0.783203, f1: 0.260548] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 512/684] [D loss: 1.769603, acc: 0.773438, f1: 0.287060] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 513/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258373] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 514/684] [D loss: 1.728588, acc: 0.814453, f1: 0.295594] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 515/684] [D loss: 1.783275, acc: 0.759766, f1: 0.231607] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 516/684] [D loss: 1.812570, acc: 0.730469, f1: 0.249572] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 517/684] [D loss: 1.798900, acc: 0.744141, f1: 0.228473] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 518/684] [D loss: 1.752025, acc: 0.791016, f1: 0.265044] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 519/684] [D loss: 1.763717, acc: 0.779297, f1: 0.233218] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 520/684] [D loss: 1.789135, acc: 0.753906, f1: 0.255065] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 521/684] [D loss: 1.791088, acc: 0.751953, f1: 0.250601] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 522/684] [D loss: 1.773510, acc: 0.769531, f1: 0.234099] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 523/684] [D loss: 1.757834, acc: 0.785156, f1: 0.288523] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 524/684] [D loss: 1.791088, acc: 0.751953, f1: 0.252238] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 525/684] [D loss: 1.789135, acc: 0.753906, f1: 0.251994] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 526/684] [D loss: 1.789132, acc: 0.753906, f1: 0.229548] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 527/684] [D loss: 1.759820, acc: 0.783203, f1: 0.260416] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 528/684] [D loss: 1.769603, acc: 0.773438, f1: 0.287460] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 529/684] [D loss: 1.785223, acc: 0.757812, f1: 0.254405] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 530/684] [D loss: 1.789131, acc: 0.753906, f1: 0.254542] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 531/684] [D loss: 1.740307, acc: 0.802734, f1: 0.297806] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 532/684] [D loss: 1.769603, acc: 0.773438, f1: 0.255477] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 533/684] [D loss: 1.752025, acc: 0.791016, f1: 0.292239] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 534/684] [D loss: 1.763686, acc: 0.779297, f1: 0.260333] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 535/684] [D loss: 1.785228, acc: 0.757812, f1: 0.255586] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 536/684] [D loss: 1.793040, acc: 0.750000, f1: 0.256477] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 537/684] [D loss: 1.765697, acc: 0.777344, f1: 0.287037] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 538/684] [D loss: 1.791083, acc: 0.751953, f1: 0.280734] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 539/684] [D loss: 1.765694, acc: 0.777344, f1: 0.238069] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 540/684] [D loss: 1.750072, acc: 0.792969, f1: 0.238233] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 541/684] [D loss: 1.753978, acc: 0.789062, f1: 0.261926] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 542/684] [D loss: 1.752025, acc: 0.791016, f1: 0.261941] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 543/684] [D loss: 1.806713, acc: 0.736328, f1: 0.279023] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 544/684] [D loss: 1.791088, acc: 0.751953, f1: 0.280499] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 545/684] [D loss: 1.777416, acc: 0.765625, f1: 0.284362] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 546/684] [D loss: 1.752025, acc: 0.791016, f1: 0.291914] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 547/684] [D loss: 1.769603, acc: 0.773438, f1: 0.258436] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 548/684] [D loss: 1.798900, acc: 0.744141, f1: 0.245399] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 549/684] [D loss: 1.759838, acc: 0.783203, f1: 0.260042] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 550/684] [D loss: 1.771557, acc: 0.771484, f1: 0.286890] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 551/684] [D loss: 1.763744, acc: 0.779297, f1: 0.255768] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 552/684] [D loss: 1.787182, acc: 0.755859, f1: 0.251176] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 553/684] [D loss: 1.765697, acc: 0.777344, f1: 0.288906] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 554/684] [D loss: 1.759838, acc: 0.783203, f1: 0.236807] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 555/684] [D loss: 1.771556, acc: 0.771484, f1: 0.251814] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 556/684] [D loss: 1.757885, acc: 0.785156, f1: 0.324413] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 557/684] [D loss: 1.781322, acc: 0.761719, f1: 0.279795] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 558/684] [D loss: 1.759838, acc: 0.783203, f1: 0.286671] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 559/684] [D loss: 1.761790, acc: 0.781250, f1: 0.293356] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 560/684] [D loss: 1.781302, acc: 0.761719, f1: 0.256239] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 561/684] [D loss: 1.755932, acc: 0.787109, f1: 0.261798] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 562/684] [D loss: 1.775462, acc: 0.767578, f1: 0.287114] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 563/684] [D loss: 1.804760, acc: 0.738281, f1: 0.250577] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 564/684] [D loss: 1.773450, acc: 0.769531, f1: 0.256797] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 565/684] [D loss: 1.773510, acc: 0.769531, f1: 0.234891] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 566/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259232] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 567/684] [D loss: 1.773458, acc: 0.769531, f1: 0.289742] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 568/684] [D loss: 1.755932, acc: 0.787109, f1: 0.262582] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 569/684] [D loss: 1.779369, acc: 0.763672, f1: 0.255966] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 570/684] [D loss: 1.783242, acc: 0.759766, f1: 0.323739] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 571/684] [D loss: 1.755931, acc: 0.787109, f1: 0.261373] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 572/684] [D loss: 1.773510, acc: 0.769531, f1: 0.259542] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 573/684] [D loss: 1.773510, acc: 0.769531, f1: 0.232719] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 574/684] [D loss: 1.765697, acc: 0.777344, f1: 0.261994] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 575/684] [D loss: 1.791087, acc: 0.751953, f1: 0.247557] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 576/684] [D loss: 1.781322, acc: 0.761719, f1: 0.255456] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 577/684] [D loss: 1.771557, acc: 0.771484, f1: 0.291285] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 578/684] [D loss: 1.775463, acc: 0.767578, f1: 0.253224] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 579/684] [D loss: 1.755916, acc: 0.787109, f1: 0.287478] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 580/684] [D loss: 1.785228, acc: 0.757812, f1: 0.250548] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 581/684] [D loss: 1.779308, acc: 0.763672, f1: 0.232690] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 582/684] [D loss: 1.748118, acc: 0.794922, f1: 0.262066] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 583/684] [D loss: 1.773510, acc: 0.769531, f1: 0.283892] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 584/684] [D loss: 1.793041, acc: 0.750000, f1: 0.248693] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 585/684] [D loss: 1.755932, acc: 0.787109, f1: 0.262633] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 586/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259930] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 587/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259526] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 588/684] [D loss: 1.773510, acc: 0.769531, f1: 0.287048] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 589/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258100] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 590/684] [D loss: 1.746166, acc: 0.796875, f1: 0.263831] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 591/684] [D loss: 1.755929, acc: 0.787109, f1: 0.262317] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 592/684] [D loss: 1.757885, acc: 0.785156, f1: 0.260019] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 593/684] [D loss: 1.763744, acc: 0.779297, f1: 0.235147] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 594/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284663] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 595/684] [D loss: 1.793039, acc: 0.750000, f1: 0.253519] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 596/684] [D loss: 1.789135, acc: 0.753906, f1: 0.253896] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 597/684] [D loss: 1.755932, acc: 0.787109, f1: 0.261190] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 598/684] [D loss: 1.783168, acc: 0.759766, f1: 0.254325] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 599/684] [D loss: 1.796947, acc: 0.746094, f1: 0.251279] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 600/684] [D loss: 1.771556, acc: 0.771484, f1: 0.233778] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 601/684] [D loss: 1.781322, acc: 0.761719, f1: 0.281670] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 602/684] [D loss: 1.779369, acc: 0.763672, f1: 0.256481] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 603/684] [D loss: 1.781322, acc: 0.761719, f1: 0.257024] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 604/684] [D loss: 1.787182, acc: 0.755859, f1: 0.254101] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 605/684] [D loss: 1.753978, acc: 0.789062, f1: 0.234855] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 606/684] [D loss: 1.761791, acc: 0.781250, f1: 0.257009] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 607/684] [D loss: 1.750072, acc: 0.792969, f1: 0.263926] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 608/684] [D loss: 1.746166, acc: 0.796875, f1: 0.264202] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 609/684] [D loss: 1.746112, acc: 0.796875, f1: 0.294599] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 610/684] [D loss: 1.787182, acc: 0.755859, f1: 0.281468] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 611/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258715] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 612/684] [D loss: 1.763730, acc: 0.779297, f1: 0.285822] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 613/684] [D loss: 1.769603, acc: 0.773438, f1: 0.286489] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 614/684] [D loss: 1.791047, acc: 0.751953, f1: 0.251469] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 615/684] [D loss: 1.779356, acc: 0.763672, f1: 0.254306] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 616/684] [D loss: 1.742260, acc: 0.800781, f1: 0.265025] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 617/684] [D loss: 1.777416, acc: 0.765625, f1: 0.254762] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 618/684] [D loss: 1.783275, acc: 0.759766, f1: 0.254044] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 619/684] [D loss: 1.773510, acc: 0.769531, f1: 0.254951] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 620/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258420] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 621/684] [D loss: 1.771557, acc: 0.771484, f1: 0.238238] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 622/684] [D loss: 1.794994, acc: 0.748047, f1: 0.229503] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 623/684] [D loss: 1.796947, acc: 0.746094, f1: 0.228331] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 624/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260048] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 625/684] [D loss: 1.779369, acc: 0.763672, f1: 0.253094] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 626/684] [D loss: 1.767650, acc: 0.775391, f1: 0.287745] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 627/684] [D loss: 1.779369, acc: 0.763672, f1: 0.253497] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 628/684] [D loss: 1.775411, acc: 0.767578, f1: 0.286953] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 629/684] [D loss: 1.765697, acc: 0.777344, f1: 0.285868] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 630/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259212] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 631/684] [D loss: 1.755896, acc: 0.787109, f1: 0.327003] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 632/684] [D loss: 1.785224, acc: 0.757812, f1: 0.258167] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 633/684] [D loss: 1.748072, acc: 0.794922, f1: 0.292142] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 634/684] [D loss: 1.744213, acc: 0.798828, f1: 0.264206] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 635/684] [D loss: 1.738341, acc: 0.804688, f1: 0.262014] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 636/684] [D loss: 1.763680, acc: 0.779297, f1: 0.327934] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 637/684] [D loss: 1.769603, acc: 0.773438, f1: 0.287658] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 638/684] [D loss: 1.769572, acc: 0.773438, f1: 0.288671] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 639/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260286] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 640/684] [D loss: 1.765697, acc: 0.777344, f1: 0.233917] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 641/684] [D loss: 1.763744, acc: 0.779297, f1: 0.257903] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 642/684] [D loss: 1.779369, acc: 0.763672, f1: 0.258533] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 643/684] [D loss: 1.796943, acc: 0.746094, f1: 0.254535] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 644/684] [D loss: 1.787181, acc: 0.755859, f1: 0.256944] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 645/684] [D loss: 1.761791, acc: 0.781250, f1: 0.257488] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 646/684] [D loss: 1.773506, acc: 0.769531, f1: 0.284520] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 647/684] [D loss: 1.785228, acc: 0.757812, f1: 0.252696] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 648/684] [D loss: 1.781321, acc: 0.761719, f1: 0.280594] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 649/684] [D loss: 1.804760, acc: 0.738281, f1: 0.252391] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 650/684] [D loss: 1.798900, acc: 0.744141, f1: 0.250557] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 651/684] [D loss: 1.755908, acc: 0.787109, f1: 0.261014] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 652/684] [D loss: 1.793041, acc: 0.750000, f1: 0.253400] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 653/684] [D loss: 1.750072, acc: 0.792969, f1: 0.262624] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 654/684] [D loss: 1.777416, acc: 0.765625, f1: 0.255970] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 655/684] [D loss: 1.759838, acc: 0.783203, f1: 0.257965] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 656/684] [D loss: 1.763744, acc: 0.779297, f1: 0.254988] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 657/684] [D loss: 1.787182, acc: 0.755859, f1: 0.254578] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 658/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258305] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 659/684] [D loss: 1.752025, acc: 0.791016, f1: 0.262584] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 660/684] [D loss: 1.771557, acc: 0.771484, f1: 0.285210] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 661/684] [D loss: 1.763742, acc: 0.779297, f1: 0.260003] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 662/684] [D loss: 1.769603, acc: 0.773438, f1: 0.235911] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 663/684] [D loss: 1.755932, acc: 0.787109, f1: 0.289720] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 664/684] [D loss: 1.791088, acc: 0.751953, f1: 0.232023] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 665/684] [D loss: 1.771543, acc: 0.771484, f1: 0.257156] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 666/684] [D loss: 1.736400, acc: 0.806641, f1: 0.268504] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 667/684] [D loss: 1.787148, acc: 0.755859, f1: 0.254225] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 668/684] [D loss: 1.785228, acc: 0.757812, f1: 0.252510] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 669/684] [D loss: 1.759838, acc: 0.783203, f1: 0.259622] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 670/684] [D loss: 1.789135, acc: 0.753906, f1: 0.254081] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 671/684] [D loss: 1.763739, acc: 0.779297, f1: 0.257515] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 672/684] [D loss: 1.744184, acc: 0.798828, f1: 0.265333] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 673/684] [D loss: 1.761741, acc: 0.781250, f1: 0.256328] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 674/684] [D loss: 1.757885, acc: 0.785156, f1: 0.259062] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 675/684] [D loss: 1.759832, acc: 0.783203, f1: 0.258781] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 676/684] [D loss: 1.744213, acc: 0.798828, f1: 0.292074] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 677/684] [D loss: 1.759835, acc: 0.783203, f1: 0.259693] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 678/684] [D loss: 1.757885, acc: 0.785156, f1: 0.259167] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 679/684] [D loss: 1.753978, acc: 0.789062, f1: 0.259714] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 680/684] [D loss: 1.750065, acc: 0.792969, f1: 0.240471] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 681/684] [D loss: 1.787182, acc: 0.755859, f1: 0.255724] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 682/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258935] [G loss: -1.000000]\n",
      "[Epoch 3/5] [Batch 683/684] [D loss: 1.777416, acc: 0.765625, f1: 0.282253] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 0/684] [D loss: 1.816478, acc: 0.726562, f1: 0.223560] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 1/684] [D loss: 1.761791, acc: 0.781250, f1: 0.236885] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 2/684] [D loss: 1.787106, acc: 0.755859, f1: 0.252713] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 3/684] [D loss: 1.767648, acc: 0.775391, f1: 0.286569] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 4/684] [D loss: 1.773510, acc: 0.769531, f1: 0.285395] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 5/684] [D loss: 1.765697, acc: 0.777344, f1: 0.256789] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 6/684] [D loss: 1.794994, acc: 0.748047, f1: 0.255408] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 7/684] [D loss: 1.781315, acc: 0.761719, f1: 0.256395] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 8/684] [D loss: 1.793041, acc: 0.750000, f1: 0.227096] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 9/684] [D loss: 1.763743, acc: 0.779297, f1: 0.261360] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 10/684] [D loss: 1.773510, acc: 0.769531, f1: 0.257676] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 11/684] [D loss: 1.779344, acc: 0.763672, f1: 0.255350] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 12/684] [D loss: 1.772164, acc: 0.771484, f1: 0.258277] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 13/684] [D loss: 1.761801, acc: 0.781250, f1: 0.256478] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 14/684] [D loss: 1.796947, acc: 0.746094, f1: 0.252604] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 15/684] [D loss: 1.755932, acc: 0.787109, f1: 0.324989] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 16/684] [D loss: 1.785211, acc: 0.757812, f1: 0.254499] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 17/684] [D loss: 1.755932, acc: 0.787109, f1: 0.236152] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 18/684] [D loss: 1.773510, acc: 0.769531, f1: 0.255872] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 19/684] [D loss: 1.804704, acc: 0.738281, f1: 0.251967] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 20/684] [D loss: 1.793041, acc: 0.750000, f1: 0.253575] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 21/684] [D loss: 1.787090, acc: 0.755859, f1: 0.254831] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 22/684] [D loss: 1.769603, acc: 0.773438, f1: 0.234884] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 23/684] [D loss: 1.779363, acc: 0.763672, f1: 0.254558] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 24/684] [D loss: 1.779369, acc: 0.763672, f1: 0.318120] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 25/684] [D loss: 1.794993, acc: 0.748047, f1: 0.250635] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 26/684] [D loss: 1.798858, acc: 0.744141, f1: 0.280231] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 27/684] [D loss: 1.802738, acc: 0.740234, f1: 0.249932] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 28/684] [D loss: 1.796939, acc: 0.746094, f1: 0.249536] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 29/684] [D loss: 1.759838, acc: 0.783203, f1: 0.257221] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 30/684] [D loss: 1.732476, acc: 0.810547, f1: 0.267024] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 31/684] [D loss: 1.789135, acc: 0.753906, f1: 0.284191] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 32/684] [D loss: 1.759837, acc: 0.783203, f1: 0.260389] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 33/684] [D loss: 1.763719, acc: 0.779297, f1: 0.258843] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 34/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261654] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 35/684] [D loss: 1.785228, acc: 0.757812, f1: 0.229882] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 36/684] [D loss: 1.771551, acc: 0.771484, f1: 0.259993] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 37/684] [D loss: 1.757885, acc: 0.785156, f1: 0.238457] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 38/684] [D loss: 1.789130, acc: 0.753906, f1: 0.253202] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 39/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258294] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 40/684] [D loss: 1.773477, acc: 0.769531, f1: 0.283074] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 41/684] [D loss: 1.746166, acc: 0.796875, f1: 0.292226] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 42/684] [D loss: 1.752025, acc: 0.791016, f1: 0.261143] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 43/684] [D loss: 1.777416, acc: 0.765625, f1: 0.254864] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 44/684] [D loss: 1.736399, acc: 0.806641, f1: 0.263061] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 45/684] [D loss: 1.753933, acc: 0.789062, f1: 0.260725] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 46/684] [D loss: 1.777416, acc: 0.765625, f1: 0.256206] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 47/684] [D loss: 1.773509, acc: 0.769531, f1: 0.256019] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 48/684] [D loss: 1.765690, acc: 0.777344, f1: 0.255570] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 49/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259392] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 50/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256071] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 51/684] [D loss: 1.773509, acc: 0.769531, f1: 0.256478] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 52/684] [D loss: 1.752025, acc: 0.791016, f1: 0.260321] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 53/684] [D loss: 1.783275, acc: 0.759766, f1: 0.253891] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 54/684] [D loss: 1.775456, acc: 0.767578, f1: 0.253253] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 55/684] [D loss: 1.800691, acc: 0.742188, f1: 0.252652] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 56/684] [D loss: 1.771524, acc: 0.771484, f1: 0.261152] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 57/684] [D loss: 1.763740, acc: 0.779297, f1: 0.286739] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 58/684] [D loss: 1.800776, acc: 0.742188, f1: 0.240639] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 59/684] [D loss: 1.814494, acc: 0.728516, f1: 0.223707] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 60/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253390] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 61/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259114] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 62/684] [D loss: 1.755911, acc: 0.787109, f1: 0.260606] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 63/684] [D loss: 1.768975, acc: 0.773438, f1: 0.255582] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 64/684] [D loss: 1.806650, acc: 0.736328, f1: 0.273667] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 65/684] [D loss: 1.734447, acc: 0.808594, f1: 0.242480] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 66/684] [D loss: 1.781322, acc: 0.761719, f1: 0.281314] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 67/684] [D loss: 1.754437, acc: 0.787109, f1: 0.258589] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 68/684] [D loss: 1.773461, acc: 0.769531, f1: 0.285689] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 69/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257573] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 70/684] [D loss: 1.777416, acc: 0.765625, f1: 0.284943] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 71/684] [D loss: 1.763743, acc: 0.779297, f1: 0.288894] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 72/684] [D loss: 1.775463, acc: 0.767578, f1: 0.323674] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 73/684] [D loss: 1.767650, acc: 0.775391, f1: 0.257018] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 74/684] [D loss: 1.789129, acc: 0.753906, f1: 0.252299] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 75/684] [D loss: 1.761791, acc: 0.781250, f1: 0.290484] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 76/684] [D loss: 1.744213, acc: 0.798828, f1: 0.261306] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 77/684] [D loss: 1.742258, acc: 0.800781, f1: 0.238588] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 78/684] [D loss: 1.769603, acc: 0.773438, f1: 0.256483] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 79/684] [D loss: 1.753979, acc: 0.789062, f1: 0.239806] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 80/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256503] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 81/684] [D loss: 1.796905, acc: 0.746094, f1: 0.251506] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 82/684] [D loss: 1.752025, acc: 0.791016, f1: 0.262171] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 83/684] [D loss: 1.753975, acc: 0.789062, f1: 0.262035] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 84/684] [D loss: 1.753978, acc: 0.789062, f1: 0.259235] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 85/684] [D loss: 1.779369, acc: 0.763672, f1: 0.253569] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 86/684] [D loss: 1.775387, acc: 0.767578, f1: 0.254082] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 87/684] [D loss: 1.777416, acc: 0.765625, f1: 0.283685] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 88/684] [D loss: 1.783267, acc: 0.759766, f1: 0.254656] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 89/684] [D loss: 1.752017, acc: 0.791016, f1: 0.293791] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 90/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256823] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 91/684] [D loss: 1.796943, acc: 0.746094, f1: 0.229469] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 92/684] [D loss: 1.755911, acc: 0.787109, f1: 0.261225] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 93/684] [D loss: 1.757885, acc: 0.785156, f1: 0.288714] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 94/684] [D loss: 1.753978, acc: 0.789062, f1: 0.287974] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 95/684] [D loss: 1.785222, acc: 0.757812, f1: 0.256918] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 96/684] [D loss: 1.763679, acc: 0.779297, f1: 0.258655] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 97/684] [D loss: 1.771529, acc: 0.771484, f1: 0.287394] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 98/684] [D loss: 1.750072, acc: 0.792969, f1: 0.259548] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 99/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257884] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 100/684] [D loss: 1.796947, acc: 0.746094, f1: 0.252212] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 101/684] [D loss: 1.794992, acc: 0.748047, f1: 0.227530] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 102/684] [D loss: 1.771485, acc: 0.771484, f1: 0.254124] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 103/684] [D loss: 1.775463, acc: 0.767578, f1: 0.324569] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 104/684] [D loss: 1.757885, acc: 0.785156, f1: 0.260557] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 105/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258581] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 106/684] [D loss: 1.777414, acc: 0.765625, f1: 0.251934] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 107/684] [D loss: 1.781319, acc: 0.761719, f1: 0.254514] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 108/684] [D loss: 1.775460, acc: 0.767578, f1: 0.257087] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 109/684] [D loss: 1.742260, acc: 0.800781, f1: 0.259039] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 110/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259818] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 111/684] [D loss: 1.726635, acc: 0.816406, f1: 0.293909] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 112/684] [D loss: 1.775461, acc: 0.767578, f1: 0.259457] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 113/684] [D loss: 1.753949, acc: 0.789062, f1: 0.292692] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 114/684] [D loss: 1.736400, acc: 0.806641, f1: 0.264992] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 115/684] [D loss: 1.793013, acc: 0.750000, f1: 0.282271] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 116/684] [D loss: 1.763681, acc: 0.779297, f1: 0.236575] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 117/684] [D loss: 1.796923, acc: 0.746094, f1: 0.282115] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 118/684] [D loss: 1.765987, acc: 0.777344, f1: 0.261042] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 119/684] [D loss: 1.791088, acc: 0.751953, f1: 0.279940] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 120/684] [D loss: 1.783273, acc: 0.759766, f1: 0.249540] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 121/684] [D loss: 1.761791, acc: 0.781250, f1: 0.288997] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 122/684] [D loss: 1.752025, acc: 0.791016, f1: 0.258971] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 123/684] [D loss: 1.781322, acc: 0.761719, f1: 0.257947] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 124/684] [D loss: 1.757885, acc: 0.785156, f1: 0.257620] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 125/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256720] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 126/684] [D loss: 1.775453, acc: 0.767578, f1: 0.255775] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 127/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258665] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 128/684] [D loss: 1.779369, acc: 0.763672, f1: 0.256877] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 129/684] [D loss: 1.785228, acc: 0.757812, f1: 0.251933] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 130/684] [D loss: 1.763744, acc: 0.779297, f1: 0.262154] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 131/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259370] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 132/684] [D loss: 1.773296, acc: 0.769531, f1: 0.255376] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 133/684] [D loss: 1.783275, acc: 0.759766, f1: 0.252881] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 134/684] [D loss: 1.765697, acc: 0.777344, f1: 0.260081] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 135/684] [D loss: 1.759838, acc: 0.783203, f1: 0.289436] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 136/684] [D loss: 1.742260, acc: 0.800781, f1: 0.293817] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 137/684] [D loss: 1.769603, acc: 0.773438, f1: 0.232305] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 138/684] [D loss: 1.789135, acc: 0.753906, f1: 0.255670] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 139/684] [D loss: 1.771556, acc: 0.771484, f1: 0.257874] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 140/684] [D loss: 1.775463, acc: 0.767578, f1: 0.253982] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 141/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259237] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 142/684] [D loss: 1.806713, acc: 0.736328, f1: 0.249665] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 143/684] [D loss: 1.791082, acc: 0.751953, f1: 0.251252] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 144/684] [D loss: 1.752025, acc: 0.791016, f1: 0.286633] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 145/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258869] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 146/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257786] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 147/684] [D loss: 1.785228, acc: 0.757812, f1: 0.256146] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 148/684] [D loss: 1.787182, acc: 0.755859, f1: 0.229990] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 149/684] [D loss: 1.771557, acc: 0.771484, f1: 0.286641] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 150/684] [D loss: 1.767650, acc: 0.775391, f1: 0.260022] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 151/684] [D loss: 1.765697, acc: 0.777344, f1: 0.233269] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 152/684] [D loss: 1.761791, acc: 0.781250, f1: 0.327879] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 153/684] [D loss: 1.775463, acc: 0.767578, f1: 0.254711] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 154/684] [D loss: 1.759838, acc: 0.783203, f1: 0.290532] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 155/684] [D loss: 1.783275, acc: 0.759766, f1: 0.253776] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 156/684] [D loss: 1.763733, acc: 0.779297, f1: 0.260671] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 157/684] [D loss: 1.802807, acc: 0.740234, f1: 0.253484] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 158/684] [D loss: 1.765688, acc: 0.777344, f1: 0.256605] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 159/684] [D loss: 1.765697, acc: 0.777344, f1: 0.286995] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 160/684] [D loss: 1.753960, acc: 0.789062, f1: 0.259501] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 161/684] [D loss: 1.767650, acc: 0.775391, f1: 0.285997] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 162/684] [D loss: 1.783275, acc: 0.759766, f1: 0.284276] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 163/684] [D loss: 1.750069, acc: 0.792969, f1: 0.242052] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 164/684] [D loss: 1.765697, acc: 0.777344, f1: 0.251148] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 165/684] [D loss: 1.775423, acc: 0.767578, f1: 0.258009] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 166/684] [D loss: 1.761791, acc: 0.781250, f1: 0.259576] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 167/684] [D loss: 1.779369, acc: 0.763672, f1: 0.258238] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 168/684] [D loss: 1.785228, acc: 0.757812, f1: 0.254422] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 169/684] [D loss: 1.767650, acc: 0.775391, f1: 0.257397] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 170/684] [D loss: 1.777416, acc: 0.765625, f1: 0.259320] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 171/684] [D loss: 1.744213, acc: 0.798828, f1: 0.261067] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 172/684] [D loss: 1.773510, acc: 0.769531, f1: 0.233765] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 173/684] [D loss: 1.740307, acc: 0.802734, f1: 0.238948] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 174/684] [D loss: 1.789135, acc: 0.753906, f1: 0.281263] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 175/684] [D loss: 1.783275, acc: 0.759766, f1: 0.230740] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 176/684] [D loss: 1.775463, acc: 0.767578, f1: 0.233325] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 177/684] [D loss: 1.785099, acc: 0.757812, f1: 0.252324] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 178/684] [D loss: 1.783212, acc: 0.759766, f1: 0.253622] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 179/684] [D loss: 1.763744, acc: 0.779297, f1: 0.288815] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 180/684] [D loss: 1.734447, acc: 0.808594, f1: 0.264412] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 181/684] [D loss: 1.779369, acc: 0.763672, f1: 0.253746] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 182/684] [D loss: 1.781322, acc: 0.761719, f1: 0.224991] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 183/684] [D loss: 1.783275, acc: 0.759766, f1: 0.252919] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 184/684] [D loss: 1.765697, acc: 0.777344, f1: 0.262797] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 185/684] [D loss: 1.775463, acc: 0.767578, f1: 0.253783] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 186/684] [D loss: 1.765697, acc: 0.777344, f1: 0.234158] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 187/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259310] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 188/684] [D loss: 1.783275, acc: 0.759766, f1: 0.252750] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 189/684] [D loss: 1.806715, acc: 0.736328, f1: 0.250866] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 190/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260086] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 191/684] [D loss: 1.771499, acc: 0.771484, f1: 0.257435] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 192/684] [D loss: 1.746166, acc: 0.796875, f1: 0.292684] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 193/684] [D loss: 1.740307, acc: 0.802734, f1: 0.294780] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 194/684] [D loss: 1.775462, acc: 0.767578, f1: 0.258368] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 195/684] [D loss: 1.757885, acc: 0.785156, f1: 0.255454] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 196/684] [D loss: 1.775463, acc: 0.767578, f1: 0.234486] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 197/684] [D loss: 1.752025, acc: 0.791016, f1: 0.292520] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 198/684] [D loss: 1.791088, acc: 0.751953, f1: 0.252993] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 199/684] [D loss: 1.771556, acc: 0.771484, f1: 0.257310] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 200/684] [D loss: 1.777358, acc: 0.765625, f1: 0.286124] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 201/684] [D loss: 1.781322, acc: 0.761719, f1: 0.281412] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 202/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253078] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 203/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260445] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 204/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260627] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 205/684] [D loss: 1.781322, acc: 0.761719, f1: 0.253030] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 206/684] [D loss: 1.753978, acc: 0.789062, f1: 0.261002] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 207/684] [D loss: 1.761707, acc: 0.781250, f1: 0.259930] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 208/684] [D loss: 1.775453, acc: 0.767578, f1: 0.256160] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 209/684] [D loss: 1.796947, acc: 0.746094, f1: 0.251050] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 210/684] [D loss: 1.800853, acc: 0.742188, f1: 0.253104] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 211/684] [D loss: 1.767650, acc: 0.775391, f1: 0.235089] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 212/684] [D loss: 1.773461, acc: 0.769531, f1: 0.256240] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 213/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261042] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 214/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259708] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 215/684] [D loss: 1.755932, acc: 0.787109, f1: 0.262118] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 216/684] [D loss: 1.769603, acc: 0.773438, f1: 0.257120] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 217/684] [D loss: 1.755853, acc: 0.787109, f1: 0.262331] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 218/684] [D loss: 1.767650, acc: 0.775391, f1: 0.235398] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 219/684] [D loss: 1.789135, acc: 0.753906, f1: 0.251520] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 220/684] [D loss: 1.732494, acc: 0.810547, f1: 0.264432] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 221/684] [D loss: 1.775463, acc: 0.767578, f1: 0.255198] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 222/684] [D loss: 1.765697, acc: 0.777344, f1: 0.257484] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 223/684] [D loss: 1.765683, acc: 0.777344, f1: 0.256967] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 224/684] [D loss: 1.726635, acc: 0.816406, f1: 0.267530] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 225/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258429] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 226/684] [D loss: 1.753970, acc: 0.789062, f1: 0.262695] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 227/684] [D loss: 1.773510, acc: 0.769531, f1: 0.256626] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 228/684] [D loss: 1.785170, acc: 0.757812, f1: 0.284589] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 229/684] [D loss: 1.767650, acc: 0.775391, f1: 0.233351] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 230/684] [D loss: 1.759838, acc: 0.783203, f1: 0.258039] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 231/684] [D loss: 1.777416, acc: 0.765625, f1: 0.232451] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 232/684] [D loss: 1.750072, acc: 0.792969, f1: 0.236991] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 233/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259739] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 234/684] [D loss: 1.761791, acc: 0.781250, f1: 0.233544] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 235/684] [D loss: 1.777416, acc: 0.765625, f1: 0.235144] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 236/684] [D loss: 1.787182, acc: 0.755859, f1: 0.281368] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 237/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258203] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 238/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257820] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 239/684] [D loss: 1.759838, acc: 0.783203, f1: 0.289604] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 240/684] [D loss: 1.810603, acc: 0.732422, f1: 0.278646] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 241/684] [D loss: 1.740307, acc: 0.802734, f1: 0.295746] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 242/684] [D loss: 1.761739, acc: 0.781250, f1: 0.286104] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 243/684] [D loss: 1.785228, acc: 0.757812, f1: 0.316317] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 244/684] [D loss: 1.771557, acc: 0.771484, f1: 0.234861] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 245/684] [D loss: 1.791088, acc: 0.751953, f1: 0.248158] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 246/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259121] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 247/684] [D loss: 1.789135, acc: 0.753906, f1: 0.256054] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 248/684] [D loss: 1.759838, acc: 0.783203, f1: 0.258777] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 249/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257511] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 250/684] [D loss: 1.796947, acc: 0.746094, f1: 0.278658] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 251/684] [D loss: 1.759838, acc: 0.783203, f1: 0.261333] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 252/684] [D loss: 1.755932, acc: 0.787109, f1: 0.236513] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 253/684] [D loss: 1.750072, acc: 0.792969, f1: 0.237198] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 254/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258908] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 255/684] [D loss: 1.773510, acc: 0.769531, f1: 0.284085] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 256/684] [D loss: 1.769603, acc: 0.773438, f1: 0.289071] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 257/684] [D loss: 1.800853, acc: 0.742188, f1: 0.250828] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 258/684] [D loss: 1.783276, acc: 0.759766, f1: 0.282099] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 259/684] [D loss: 1.793000, acc: 0.750000, f1: 0.279393] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 260/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259305] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 261/684] [D loss: 1.777416, acc: 0.765625, f1: 0.283606] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 262/684] [D loss: 1.746166, acc: 0.796875, f1: 0.290175] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 263/684] [D loss: 1.773510, acc: 0.769531, f1: 0.284644] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 264/684] [D loss: 1.771557, acc: 0.771484, f1: 0.285798] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 265/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257390] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 266/684] [D loss: 1.771556, acc: 0.771484, f1: 0.234157] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 267/684] [D loss: 1.761791, acc: 0.781250, f1: 0.289939] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 268/684] [D loss: 1.752025, acc: 0.791016, f1: 0.261767] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 269/684] [D loss: 1.771557, acc: 0.771484, f1: 0.255813] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 270/684] [D loss: 1.787182, acc: 0.755859, f1: 0.252961] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 271/684] [D loss: 1.761421, acc: 0.781250, f1: 0.259307] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 272/684] [D loss: 1.771557, acc: 0.771484, f1: 0.256369] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 273/684] [D loss: 1.748119, acc: 0.794922, f1: 0.238450] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 274/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257593] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 275/684] [D loss: 1.752025, acc: 0.791016, f1: 0.290557] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 276/684] [D loss: 1.779369, acc: 0.763672, f1: 0.254890] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 277/684] [D loss: 1.771557, acc: 0.771484, f1: 0.259587] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 278/684] [D loss: 1.748119, acc: 0.794922, f1: 0.263157] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 279/684] [D loss: 1.779369, acc: 0.763672, f1: 0.287105] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 280/684] [D loss: 1.789135, acc: 0.753906, f1: 0.256237] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 281/684] [D loss: 1.753978, acc: 0.789062, f1: 0.262035] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 282/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257447] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 283/684] [D loss: 1.730541, acc: 0.812500, f1: 0.267861] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 284/684] [D loss: 1.777416, acc: 0.765625, f1: 0.253285] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 285/684] [D loss: 1.777416, acc: 0.765625, f1: 0.233851] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 286/684] [D loss: 1.775463, acc: 0.767578, f1: 0.286163] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 287/684] [D loss: 1.783274, acc: 0.759766, f1: 0.234646] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 288/684] [D loss: 1.785228, acc: 0.757812, f1: 0.231492] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 289/684] [D loss: 1.793041, acc: 0.750000, f1: 0.253893] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 290/684] [D loss: 1.771557, acc: 0.771484, f1: 0.255525] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 291/684] [D loss: 1.763742, acc: 0.779297, f1: 0.257969] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 292/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284242] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 293/684] [D loss: 1.753978, acc: 0.789062, f1: 0.288838] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 294/684] [D loss: 1.777416, acc: 0.765625, f1: 0.257237] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 295/684] [D loss: 1.775463, acc: 0.767578, f1: 0.255595] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 296/684] [D loss: 1.755932, acc: 0.787109, f1: 0.260938] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 297/684] [D loss: 1.781322, acc: 0.761719, f1: 0.256786] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 298/684] [D loss: 1.779369, acc: 0.763672, f1: 0.255907] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 299/684] [D loss: 1.759838, acc: 0.783203, f1: 0.285706] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 300/684] [D loss: 1.771556, acc: 0.771484, f1: 0.258495] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 301/684] [D loss: 1.759838, acc: 0.783203, f1: 0.257069] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 302/684] [D loss: 1.783275, acc: 0.759766, f1: 0.251995] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 303/684] [D loss: 1.779369, acc: 0.763672, f1: 0.283392] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 304/684] [D loss: 1.757875, acc: 0.785156, f1: 0.259148] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 305/684] [D loss: 1.773510, acc: 0.769531, f1: 0.287550] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 306/684] [D loss: 1.781322, acc: 0.761719, f1: 0.255750] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 307/684] [D loss: 1.763711, acc: 0.779297, f1: 0.233627] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 308/684] [D loss: 1.761791, acc: 0.781250, f1: 0.288349] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 309/684] [D loss: 1.757885, acc: 0.785156, f1: 0.286886] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 310/684] [D loss: 1.763744, acc: 0.779297, f1: 0.285822] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 311/684] [D loss: 1.796947, acc: 0.746094, f1: 0.315230] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 312/684] [D loss: 1.736401, acc: 0.806641, f1: 0.262434] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 313/684] [D loss: 1.765673, acc: 0.777344, f1: 0.259290] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 314/684] [D loss: 1.773510, acc: 0.769531, f1: 0.284517] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 315/684] [D loss: 1.779369, acc: 0.763672, f1: 0.254817] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 316/684] [D loss: 1.750070, acc: 0.792969, f1: 0.261965] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 317/684] [D loss: 1.767650, acc: 0.775391, f1: 0.283619] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 318/684] [D loss: 1.773510, acc: 0.769531, f1: 0.253614] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 319/684] [D loss: 1.781322, acc: 0.761719, f1: 0.260391] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 320/684] [D loss: 1.763744, acc: 0.779297, f1: 0.262324] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 321/684] [D loss: 1.785228, acc: 0.757812, f1: 0.255518] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 322/684] [D loss: 1.802789, acc: 0.740234, f1: 0.251343] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 323/684] [D loss: 1.787182, acc: 0.755859, f1: 0.284614] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 324/684] [D loss: 1.789135, acc: 0.753906, f1: 0.254041] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 325/684] [D loss: 1.789135, acc: 0.753906, f1: 0.256479] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 326/684] [D loss: 1.787182, acc: 0.755859, f1: 0.280577] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 327/684] [D loss: 1.752025, acc: 0.791016, f1: 0.264342] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 328/684] [D loss: 1.793039, acc: 0.750000, f1: 0.253936] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 329/684] [D loss: 1.771554, acc: 0.771484, f1: 0.257657] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 330/684] [D loss: 1.759838, acc: 0.783203, f1: 0.260247] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 331/684] [D loss: 1.785228, acc: 0.757812, f1: 0.254620] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 332/684] [D loss: 1.732494, acc: 0.810547, f1: 0.267375] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 333/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259801] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 334/684] [D loss: 1.757884, acc: 0.785156, f1: 0.328769] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 335/684] [D loss: 1.769603, acc: 0.773438, f1: 0.236693] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 336/684] [D loss: 1.779369, acc: 0.763672, f1: 0.254671] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 337/684] [D loss: 1.749997, acc: 0.792969, f1: 0.260564] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 338/684] [D loss: 1.736400, acc: 0.806641, f1: 0.264745] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 339/684] [D loss: 1.738353, acc: 0.804688, f1: 0.265156] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 340/684] [D loss: 1.759838, acc: 0.783203, f1: 0.258399] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 341/684] [D loss: 1.779369, acc: 0.763672, f1: 0.256298] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 342/684] [D loss: 1.793041, acc: 0.750000, f1: 0.253182] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 343/684] [D loss: 1.787121, acc: 0.755859, f1: 0.283639] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 344/684] [D loss: 1.777416, acc: 0.765625, f1: 0.252947] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 345/684] [D loss: 1.750072, acc: 0.792969, f1: 0.292794] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 346/684] [D loss: 1.773510, acc: 0.769531, f1: 0.257467] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 347/684] [D loss: 1.783275, acc: 0.759766, f1: 0.253541] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 348/684] [D loss: 1.750072, acc: 0.792969, f1: 0.260414] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 349/684] [D loss: 1.753968, acc: 0.789062, f1: 0.289908] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 350/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258770] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 351/684] [D loss: 1.791088, acc: 0.751953, f1: 0.255931] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 352/684] [D loss: 1.777413, acc: 0.765625, f1: 0.258417] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 353/684] [D loss: 1.759838, acc: 0.783203, f1: 0.286678] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 354/684] [D loss: 1.775463, acc: 0.767578, f1: 0.282764] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 355/684] [D loss: 1.775463, acc: 0.767578, f1: 0.256157] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 356/684] [D loss: 1.746166, acc: 0.796875, f1: 0.260176] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 357/684] [D loss: 1.783275, acc: 0.759766, f1: 0.232511] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 358/684] [D loss: 1.759838, acc: 0.783203, f1: 0.259117] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 359/684] [D loss: 1.734447, acc: 0.808594, f1: 0.263573] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 360/684] [D loss: 1.794994, acc: 0.748047, f1: 0.231824] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 361/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253059] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 362/684] [D loss: 1.781322, acc: 0.761719, f1: 0.281320] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 363/684] [D loss: 1.767650, acc: 0.775391, f1: 0.286405] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 364/684] [D loss: 1.783272, acc: 0.759766, f1: 0.280681] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 365/684] [D loss: 1.771557, acc: 0.771484, f1: 0.256872] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 366/684] [D loss: 1.777416, acc: 0.765625, f1: 0.283856] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 367/684] [D loss: 1.771556, acc: 0.771484, f1: 0.258430] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 368/684] [D loss: 1.753978, acc: 0.789062, f1: 0.259114] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 369/684] [D loss: 1.753978, acc: 0.789062, f1: 0.291265] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 370/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257712] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 371/684] [D loss: 1.775463, acc: 0.767578, f1: 0.234912] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 372/684] [D loss: 1.763744, acc: 0.779297, f1: 0.326016] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 373/684] [D loss: 1.771557, acc: 0.771484, f1: 0.254658] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 374/684] [D loss: 1.783275, acc: 0.759766, f1: 0.253485] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 375/684] [D loss: 1.767650, acc: 0.775391, f1: 0.255105] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 376/684] [D loss: 1.771553, acc: 0.771484, f1: 0.286116] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 377/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257604] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 378/684] [D loss: 1.755932, acc: 0.787109, f1: 0.263202] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 379/684] [D loss: 1.748119, acc: 0.794922, f1: 0.261845] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 380/684] [D loss: 1.750072, acc: 0.792969, f1: 0.260593] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 381/684] [D loss: 1.789135, acc: 0.753906, f1: 0.251111] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 382/684] [D loss: 1.793041, acc: 0.750000, f1: 0.251646] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 383/684] [D loss: 1.748119, acc: 0.794922, f1: 0.290914] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 384/684] [D loss: 1.777390, acc: 0.765625, f1: 0.257531] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 385/684] [D loss: 1.765697, acc: 0.777344, f1: 0.254093] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 386/684] [D loss: 1.748119, acc: 0.794922, f1: 0.292195] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 387/684] [D loss: 1.781325, acc: 0.761719, f1: 0.254551] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 388/684] [D loss: 1.744213, acc: 0.798828, f1: 0.262375] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 389/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258343] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 390/684] [D loss: 1.759838, acc: 0.783203, f1: 0.234286] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 391/684] [D loss: 1.781296, acc: 0.761719, f1: 0.318962] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 392/684] [D loss: 1.757885, acc: 0.785156, f1: 0.258640] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 393/684] [D loss: 1.773311, acc: 0.769531, f1: 0.321754] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 394/684] [D loss: 1.783211, acc: 0.759766, f1: 0.253385] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 395/684] [D loss: 1.769603, acc: 0.773438, f1: 0.257914] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 396/684] [D loss: 1.755911, acc: 0.787109, f1: 0.260837] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 397/684] [D loss: 1.771557, acc: 0.771484, f1: 0.257375] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 398/684] [D loss: 1.771557, acc: 0.771484, f1: 0.234448] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 399/684] [D loss: 1.779369, acc: 0.763672, f1: 0.285037] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 400/684] [D loss: 1.752025, acc: 0.791016, f1: 0.260209] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 401/684] [D loss: 1.802807, acc: 0.740234, f1: 0.249848] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 402/684] [D loss: 1.787182, acc: 0.755859, f1: 0.252566] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 403/684] [D loss: 1.775463, acc: 0.767578, f1: 0.283444] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 404/684] [D loss: 1.783275, acc: 0.759766, f1: 0.255087] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 405/684] [D loss: 1.775447, acc: 0.767578, f1: 0.254317] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 406/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253247] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 407/684] [D loss: 1.779369, acc: 0.763672, f1: 0.255622] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 408/684] [D loss: 1.765697, acc: 0.777344, f1: 0.288979] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 409/684] [D loss: 1.781322, acc: 0.761719, f1: 0.282608] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 410/684] [D loss: 1.787182, acc: 0.755859, f1: 0.250508] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 411/684] [D loss: 1.783275, acc: 0.759766, f1: 0.254535] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 412/684] [D loss: 1.769603, acc: 0.773438, f1: 0.285595] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 413/684] [D loss: 1.755932, acc: 0.787109, f1: 0.259298] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 414/684] [D loss: 1.765697, acc: 0.777344, f1: 0.260306] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 415/684] [D loss: 1.787182, acc: 0.755859, f1: 0.252205] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 416/684] [D loss: 1.763744, acc: 0.779297, f1: 0.237958] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 417/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261123] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 418/684] [D loss: 1.755932, acc: 0.787109, f1: 0.264360] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 419/684] [D loss: 1.781322, acc: 0.761719, f1: 0.255719] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 420/684] [D loss: 1.752025, acc: 0.791016, f1: 0.262971] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 421/684] [D loss: 1.777416, acc: 0.765625, f1: 0.236687] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 422/684] [D loss: 1.779369, acc: 0.763672, f1: 0.284952] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 423/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253777] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 424/684] [D loss: 1.773510, acc: 0.769531, f1: 0.258057] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 425/684] [D loss: 1.773501, acc: 0.769531, f1: 0.324524] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 426/684] [D loss: 1.773510, acc: 0.769531, f1: 0.286211] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 427/684] [D loss: 1.781322, acc: 0.761719, f1: 0.253401] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 428/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258832] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 429/684] [D loss: 1.757885, acc: 0.785156, f1: 0.259051] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 430/684] [D loss: 1.769603, acc: 0.773438, f1: 0.255836] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 431/684] [D loss: 1.761791, acc: 0.781250, f1: 0.236564] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 432/684] [D loss: 1.777416, acc: 0.765625, f1: 0.319950] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 433/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260688] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 434/684] [D loss: 1.755931, acc: 0.787109, f1: 0.290695] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 435/684] [D loss: 1.798900, acc: 0.744141, f1: 0.249496] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 436/684] [D loss: 1.771552, acc: 0.771484, f1: 0.284048] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 437/684] [D loss: 1.783275, acc: 0.759766, f1: 0.284563] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 438/684] [D loss: 1.765697, acc: 0.777344, f1: 0.288774] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 439/684] [D loss: 1.771556, acc: 0.771484, f1: 0.259758] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 440/684] [D loss: 1.781322, acc: 0.761719, f1: 0.234216] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 441/684] [D loss: 1.771557, acc: 0.771484, f1: 0.289805] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 442/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259929] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 443/684] [D loss: 1.765697, acc: 0.777344, f1: 0.291862] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 444/684] [D loss: 1.750997, acc: 0.791016, f1: 0.260758] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 445/684] [D loss: 1.771552, acc: 0.771484, f1: 0.259834] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 446/684] [D loss: 1.736377, acc: 0.806641, f1: 0.263476] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 447/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257676] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 448/684] [D loss: 1.771557, acc: 0.771484, f1: 0.256819] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 449/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259749] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 450/684] [D loss: 1.787182, acc: 0.755859, f1: 0.254665] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 451/684] [D loss: 1.777416, acc: 0.765625, f1: 0.234824] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 452/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259390] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 453/684] [D loss: 1.810619, acc: 0.732422, f1: 0.276157] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 454/684] [D loss: 1.752025, acc: 0.791016, f1: 0.263420] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 455/684] [D loss: 1.761791, acc: 0.781250, f1: 0.285112] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 456/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258477] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 457/684] [D loss: 1.750072, acc: 0.792969, f1: 0.264462] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 458/684] [D loss: 1.783275, acc: 0.759766, f1: 0.254927] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 459/684] [D loss: 1.793041, acc: 0.750000, f1: 0.230766] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 460/684] [D loss: 1.750072, acc: 0.792969, f1: 0.262994] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 461/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260681] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 462/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253666] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 463/684] [D loss: 1.767649, acc: 0.775391, f1: 0.256425] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 464/684] [D loss: 1.767650, acc: 0.775391, f1: 0.288091] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 465/684] [D loss: 1.769603, acc: 0.773438, f1: 0.258788] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 466/684] [D loss: 1.771557, acc: 0.771484, f1: 0.321265] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 467/684] [D loss: 1.783275, acc: 0.759766, f1: 0.319239] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 468/684] [D loss: 1.791088, acc: 0.751953, f1: 0.278921] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 469/684] [D loss: 1.775460, acc: 0.767578, f1: 0.257171] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 470/684] [D loss: 1.791088, acc: 0.751953, f1: 0.251846] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 471/684] [D loss: 1.773510, acc: 0.769531, f1: 0.255847] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 472/684] [D loss: 1.796947, acc: 0.746094, f1: 0.248213] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 473/684] [D loss: 1.783275, acc: 0.759766, f1: 0.318516] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 474/684] [D loss: 1.773510, acc: 0.769531, f1: 0.257742] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 475/684] [D loss: 1.759838, acc: 0.783203, f1: 0.258809] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 476/684] [D loss: 1.755927, acc: 0.787109, f1: 0.291289] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 477/684] [D loss: 1.779369, acc: 0.763672, f1: 0.234931] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 478/684] [D loss: 1.796947, acc: 0.746094, f1: 0.228160] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 479/684] [D loss: 1.779369, acc: 0.763672, f1: 0.254117] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 480/684] [D loss: 1.802806, acc: 0.740234, f1: 0.248642] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 481/684] [D loss: 1.773510, acc: 0.769531, f1: 0.254952] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 482/684] [D loss: 1.767650, acc: 0.775391, f1: 0.321630] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 483/684] [D loss: 1.781322, acc: 0.761719, f1: 0.254440] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 484/684] [D loss: 1.771557, acc: 0.771484, f1: 0.283649] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 485/684] [D loss: 1.755932, acc: 0.787109, f1: 0.260063] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 486/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259404] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 487/684] [D loss: 1.785228, acc: 0.757812, f1: 0.252454] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 488/684] [D loss: 1.763744, acc: 0.779297, f1: 0.257257] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 489/684] [D loss: 1.787182, acc: 0.755859, f1: 0.281127] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 490/684] [D loss: 1.761782, acc: 0.781250, f1: 0.281701] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 491/684] [D loss: 1.773510, acc: 0.769531, f1: 0.288640] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 492/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259681] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 493/684] [D loss: 1.794994, acc: 0.748047, f1: 0.254884] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 494/684] [D loss: 1.781322, acc: 0.761719, f1: 0.282474] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 495/684] [D loss: 1.783275, acc: 0.759766, f1: 0.233363] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 496/684] [D loss: 1.808666, acc: 0.734375, f1: 0.248844] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 497/684] [D loss: 1.755932, acc: 0.787109, f1: 0.262585] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 498/684] [D loss: 1.783275, acc: 0.759766, f1: 0.285150] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 499/684] [D loss: 1.779369, acc: 0.763672, f1: 0.234106] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 500/684] [D loss: 1.759838, acc: 0.783203, f1: 0.289937] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 501/684] [D loss: 1.777416, acc: 0.765625, f1: 0.259288] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 502/684] [D loss: 1.808666, acc: 0.734375, f1: 0.227843] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 503/684] [D loss: 1.753978, acc: 0.789062, f1: 0.263640] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 504/684] [D loss: 1.810619, acc: 0.732422, f1: 0.247693] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 505/684] [D loss: 1.777416, acc: 0.765625, f1: 0.255471] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 506/684] [D loss: 1.769603, acc: 0.773438, f1: 0.258555] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 507/684] [D loss: 1.787116, acc: 0.755859, f1: 0.253457] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 508/684] [D loss: 1.779369, acc: 0.763672, f1: 0.257521] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 509/684] [D loss: 1.787182, acc: 0.755859, f1: 0.229913] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 510/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259860] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 511/684] [D loss: 1.763744, acc: 0.779297, f1: 0.287718] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 512/684] [D loss: 1.798900, acc: 0.744141, f1: 0.252182] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 513/684] [D loss: 1.814524, acc: 0.728516, f1: 0.247879] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 514/684] [D loss: 1.785228, acc: 0.757812, f1: 0.227462] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 515/684] [D loss: 1.777416, acc: 0.765625, f1: 0.254731] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 516/684] [D loss: 1.796947, acc: 0.746094, f1: 0.250543] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 517/684] [D loss: 1.767650, acc: 0.775391, f1: 0.289576] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 518/684] [D loss: 1.765697, acc: 0.777344, f1: 0.256754] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 519/684] [D loss: 1.802807, acc: 0.740234, f1: 0.250045] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 520/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259942] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 521/684] [D loss: 1.750024, acc: 0.792969, f1: 0.291213] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 522/684] [D loss: 1.769603, acc: 0.773438, f1: 0.260782] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 523/684] [D loss: 1.746166, acc: 0.796875, f1: 0.293272] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 524/684] [D loss: 1.781322, acc: 0.761719, f1: 0.255441] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 525/684] [D loss: 1.781322, acc: 0.761719, f1: 0.252415] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 526/684] [D loss: 1.785228, acc: 0.757812, f1: 0.253212] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 527/684] [D loss: 1.761791, acc: 0.781250, f1: 0.260205] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 528/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258842] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 529/684] [D loss: 1.779369, acc: 0.763672, f1: 0.229942] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 530/684] [D loss: 1.757885, acc: 0.785156, f1: 0.261889] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 531/684] [D loss: 1.785208, acc: 0.757812, f1: 0.286184] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 532/684] [D loss: 1.775463, acc: 0.767578, f1: 0.323483] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 533/684] [D loss: 1.753978, acc: 0.789062, f1: 0.260542] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 534/684] [D loss: 1.781322, acc: 0.761719, f1: 0.253780] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 535/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258560] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 536/684] [D loss: 1.793041, acc: 0.750000, f1: 0.229442] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 537/684] [D loss: 1.763725, acc: 0.779297, f1: 0.258316] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 538/684] [D loss: 1.783275, acc: 0.759766, f1: 0.257733] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 539/684] [D loss: 1.781322, acc: 0.761719, f1: 0.252971] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 540/684] [D loss: 1.789083, acc: 0.753906, f1: 0.257963] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 541/684] [D loss: 1.800853, acc: 0.742188, f1: 0.249985] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 542/684] [D loss: 1.779369, acc: 0.763672, f1: 0.235302] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 543/684] [D loss: 1.732494, acc: 0.810547, f1: 0.264820] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 544/684] [D loss: 1.738353, acc: 0.804688, f1: 0.260809] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 545/684] [D loss: 1.759838, acc: 0.783203, f1: 0.259983] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 546/684] [D loss: 1.793041, acc: 0.750000, f1: 0.279664] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 547/684] [D loss: 1.777416, acc: 0.765625, f1: 0.259237] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 548/684] [D loss: 1.775463, acc: 0.767578, f1: 0.287592] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 549/684] [D loss: 1.794994, acc: 0.748047, f1: 0.251029] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 550/684] [D loss: 1.759821, acc: 0.783203, f1: 0.260140] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 551/684] [D loss: 1.765697, acc: 0.777344, f1: 0.261976] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 552/684] [D loss: 1.753978, acc: 0.789062, f1: 0.258422] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 553/684] [D loss: 1.789134, acc: 0.753906, f1: 0.254992] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 554/684] [D loss: 1.752025, acc: 0.791016, f1: 0.292662] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 555/684] [D loss: 1.753978, acc: 0.789062, f1: 0.288514] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 556/684] [D loss: 1.759838, acc: 0.783203, f1: 0.291250] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 557/684] [D loss: 1.748119, acc: 0.794922, f1: 0.291352] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 558/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284719] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 559/684] [D loss: 1.779369, acc: 0.763672, f1: 0.288480] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 560/684] [D loss: 1.789135, acc: 0.753906, f1: 0.315090] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 561/684] [D loss: 1.781322, acc: 0.761719, f1: 0.286481] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 562/684] [D loss: 1.779335, acc: 0.763672, f1: 0.257232] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 563/684] [D loss: 1.740307, acc: 0.802734, f1: 0.262334] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 564/684] [D loss: 1.793041, acc: 0.750000, f1: 0.250923] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 565/684] [D loss: 1.765697, acc: 0.777344, f1: 0.235872] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 566/684] [D loss: 1.759838, acc: 0.783203, f1: 0.261985] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 567/684] [D loss: 1.748119, acc: 0.794922, f1: 0.264972] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 568/684] [D loss: 1.787182, acc: 0.755859, f1: 0.281985] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 569/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253736] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 570/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260527] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 571/684] [D loss: 1.796947, acc: 0.746094, f1: 0.278355] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 572/684] [D loss: 1.755932, acc: 0.787109, f1: 0.259951] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 573/684] [D loss: 1.775463, acc: 0.767578, f1: 0.285218] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 574/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258298] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 575/684] [D loss: 1.789135, acc: 0.753906, f1: 0.231153] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 576/684] [D loss: 1.775463, acc: 0.767578, f1: 0.253666] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 577/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259180] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 578/684] [D loss: 1.765687, acc: 0.777344, f1: 0.260587] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 579/684] [D loss: 1.789135, acc: 0.753906, f1: 0.255793] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 580/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253773] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 581/684] [D loss: 1.755932, acc: 0.787109, f1: 0.293800] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 582/684] [D loss: 1.773510, acc: 0.769531, f1: 0.260633] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 583/684] [D loss: 1.777416, acc: 0.765625, f1: 0.286073] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 584/684] [D loss: 1.789078, acc: 0.753906, f1: 0.230787] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 585/684] [D loss: 1.771557, acc: 0.771484, f1: 0.254841] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 586/684] [D loss: 1.765697, acc: 0.777344, f1: 0.287548] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 587/684] [D loss: 1.779369, acc: 0.763672, f1: 0.253549] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 588/684] [D loss: 1.796947, acc: 0.746094, f1: 0.252152] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 589/684] [D loss: 1.755932, acc: 0.787109, f1: 0.259808] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 590/684] [D loss: 1.765697, acc: 0.777344, f1: 0.259996] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 591/684] [D loss: 1.793041, acc: 0.750000, f1: 0.281114] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 592/684] [D loss: 1.804760, acc: 0.738281, f1: 0.274605] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 593/684] [D loss: 1.771557, acc: 0.771484, f1: 0.287140] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 594/684] [D loss: 1.763744, acc: 0.779297, f1: 0.260438] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 595/684] [D loss: 1.779369, acc: 0.763672, f1: 0.229147] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 596/684] [D loss: 1.761794, acc: 0.781250, f1: 0.238741] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 597/684] [D loss: 1.763744, acc: 0.779297, f1: 0.258777] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 598/684] [D loss: 1.791088, acc: 0.751953, f1: 0.253989] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 599/684] [D loss: 1.771557, acc: 0.771484, f1: 0.235459] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 600/684] [D loss: 1.779369, acc: 0.763672, f1: 0.282211] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 601/684] [D loss: 1.763744, acc: 0.779297, f1: 0.259695] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 602/684] [D loss: 1.781322, acc: 0.761719, f1: 0.256024] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 603/684] [D loss: 1.791088, acc: 0.751953, f1: 0.251568] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 604/684] [D loss: 1.767650, acc: 0.775391, f1: 0.258609] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 605/684] [D loss: 1.730541, acc: 0.812500, f1: 0.293805] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 606/684] [D loss: 1.762034, acc: 0.781250, f1: 0.258765] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 607/684] [D loss: 1.783275, acc: 0.759766, f1: 0.280040] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 608/684] [D loss: 1.742266, acc: 0.800781, f1: 0.262349] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 609/684] [D loss: 1.794994, acc: 0.748047, f1: 0.254345] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 610/684] [D loss: 1.777416, acc: 0.765625, f1: 0.255106] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 611/684] [D loss: 1.771557, acc: 0.771484, f1: 0.256913] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 612/684] [D loss: 1.794994, acc: 0.748047, f1: 0.278108] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 613/684] [D loss: 1.775463, acc: 0.767578, f1: 0.255146] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 614/684] [D loss: 1.750072, acc: 0.792969, f1: 0.259709] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 615/684] [D loss: 1.738262, acc: 0.804688, f1: 0.268259] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 616/684] [D loss: 1.783275, acc: 0.759766, f1: 0.284042] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 617/684] [D loss: 1.769603, acc: 0.773438, f1: 0.258456] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 618/684] [D loss: 1.763744, acc: 0.779297, f1: 0.257323] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 619/684] [D loss: 1.761791, acc: 0.781250, f1: 0.256023] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 620/684] [D loss: 1.771557, acc: 0.771484, f1: 0.258923] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 621/684] [D loss: 1.783275, acc: 0.759766, f1: 0.282640] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 622/684] [D loss: 1.771557, acc: 0.771484, f1: 0.236083] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 623/684] [D loss: 1.783230, acc: 0.759766, f1: 0.257870] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 624/684] [D loss: 1.794994, acc: 0.748047, f1: 0.251303] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 625/684] [D loss: 1.767649, acc: 0.775391, f1: 0.287787] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 626/684] [D loss: 1.781322, acc: 0.761719, f1: 0.251676] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 627/684] [D loss: 1.775463, acc: 0.767578, f1: 0.255775] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 628/684] [D loss: 1.787182, acc: 0.755859, f1: 0.253465] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 629/684] [D loss: 1.785228, acc: 0.757812, f1: 0.283256] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 630/684] [D loss: 1.765697, acc: 0.777344, f1: 0.258338] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 631/684] [D loss: 1.798900, acc: 0.744141, f1: 0.230855] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 632/684] [D loss: 1.773510, acc: 0.769531, f1: 0.234839] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 633/684] [D loss: 1.796947, acc: 0.746094, f1: 0.228322] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 634/684] [D loss: 1.783275, acc: 0.759766, f1: 0.254573] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 635/684] [D loss: 1.759837, acc: 0.783203, f1: 0.259748] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 636/684] [D loss: 1.769603, acc: 0.773438, f1: 0.286228] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 637/684] [D loss: 1.802807, acc: 0.740234, f1: 0.251117] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 638/684] [D loss: 1.767650, acc: 0.775391, f1: 0.286328] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 639/684] [D loss: 1.775463, acc: 0.767578, f1: 0.258348] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 640/684] [D loss: 1.781322, acc: 0.761719, f1: 0.283736] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 641/684] [D loss: 1.752025, acc: 0.791016, f1: 0.293646] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 642/684] [D loss: 1.752025, acc: 0.791016, f1: 0.239746] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 643/684] [D loss: 1.757885, acc: 0.785156, f1: 0.325445] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 644/684] [D loss: 1.752025, acc: 0.791016, f1: 0.288659] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 645/684] [D loss: 1.779369, acc: 0.763672, f1: 0.257164] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 646/684] [D loss: 1.771556, acc: 0.771484, f1: 0.284136] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 647/684] [D loss: 1.781322, acc: 0.761719, f1: 0.284136] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 648/684] [D loss: 1.755932, acc: 0.787109, f1: 0.263210] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 649/684] [D loss: 1.759838, acc: 0.783203, f1: 0.326401] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 650/684] [D loss: 1.765697, acc: 0.777344, f1: 0.235231] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 651/684] [D loss: 1.767650, acc: 0.775391, f1: 0.288927] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 652/684] [D loss: 1.759838, acc: 0.783203, f1: 0.258636] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 653/684] [D loss: 1.793041, acc: 0.750000, f1: 0.253861] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 654/684] [D loss: 1.793041, acc: 0.750000, f1: 0.279469] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 655/684] [D loss: 1.779369, acc: 0.763672, f1: 0.231712] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 656/684] [D loss: 1.775463, acc: 0.767578, f1: 0.257906] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 657/684] [D loss: 1.771557, acc: 0.771484, f1: 0.236130] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 658/684] [D loss: 1.793019, acc: 0.750000, f1: 0.279081] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 659/684] [D loss: 1.755923, acc: 0.787109, f1: 0.259979] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 660/684] [D loss: 1.806712, acc: 0.736328, f1: 0.249519] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 661/684] [D loss: 1.750072, acc: 0.792969, f1: 0.262159] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 662/684] [D loss: 1.761791, acc: 0.781250, f1: 0.261524] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 663/684] [D loss: 1.773498, acc: 0.769531, f1: 0.258797] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 664/684] [D loss: 1.767650, acc: 0.775391, f1: 0.259439] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 665/684] [D loss: 1.761791, acc: 0.781250, f1: 0.262356] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 666/684] [D loss: 1.771557, acc: 0.771484, f1: 0.230743] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 667/684] [D loss: 1.783275, acc: 0.759766, f1: 0.255947] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 668/684] [D loss: 1.765697, acc: 0.777344, f1: 0.261423] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 669/684] [D loss: 1.750072, acc: 0.792969, f1: 0.262640] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 670/684] [D loss: 1.765697, acc: 0.777344, f1: 0.235212] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 671/684] [D loss: 1.759838, acc: 0.783203, f1: 0.288512] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 672/684] [D loss: 1.787182, acc: 0.755859, f1: 0.251704] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 673/684] [D loss: 1.808666, acc: 0.734375, f1: 0.228088] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 674/684] [D loss: 1.794994, acc: 0.748047, f1: 0.227037] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 675/684] [D loss: 1.761791, acc: 0.781250, f1: 0.290439] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 676/684] [D loss: 1.794986, acc: 0.748047, f1: 0.255805] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 677/684] [D loss: 1.763744, acc: 0.779297, f1: 0.285865] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 678/684] [D loss: 1.769603, acc: 0.773438, f1: 0.259257] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 679/684] [D loss: 1.769603, acc: 0.773438, f1: 0.237223] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 680/684] [D loss: 1.798900, acc: 0.744141, f1: 0.246647] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 681/684] [D loss: 1.757885, acc: 0.785156, f1: 0.261957] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 682/684] [D loss: 1.794994, acc: 0.748047, f1: 0.252670] [G loss: -1.000000]\n",
      "[Epoch 4/5] [Batch 683/684] [D loss: 1.787182, acc: 0.755859, f1: 0.231743] [G loss: -1.000000]\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "f1score = 0.0\n",
    "clip_value = 0.01\n",
    "n_critic = 1\n",
    "steps = 0\n",
    "tb = SummaryWriter(log_dir='lightning_logs')\n",
    "for epoch in range(n_epoch):\n",
    "    for i, (imgs, labels) in enumerate(tr_dataloader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(torch.FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).cuda()\n",
    "        fake = Variable(torch.FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).cuda()\n",
    "        fake_aux_gt = Variable(torch.LongTensor(batch_size).fill_(num_classes), requires_grad=False).cuda()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        z = torch.randn(batch_size, z_dim).cuda()\n",
    "        gen_imgs = G(z)\n",
    "        # Loss for real images\n",
    "        # print(imgs.device)\n",
    "        real_pred, real_aux = D(imgs)\n",
    "        # print(real_pred.device, valid.device, real_aux.device, labels.device)\n",
    "        # d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        # fake_pred, fake_aux = D(gen_imgs)\n",
    "        fake_pred, fake_aux = D(gen_imgs.detach())\n",
    "        # d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, fake_aux_gt)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        # d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        # d_loss = -torch.mean(d_real_loss) + torch.mean(d_fake_loss)\n",
    "        d_loss = -torch.mean(real_pred) + torch.mean(fake_pred) + ((auxiliary_loss(real_aux, labels)) + (auxiliary_loss(fake_aux, fake_aux_gt))) / 2\n",
    "        \n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), fake_aux_gt.data.cpu().numpy()], axis=0)\n",
    "        # d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "        y_pred = np.argmax(pred, axis=1)\n",
    "        accuracy = accuracy_score(gt, y_pred)\n",
    "        precision = precision_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        f1score = f1_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        recall = recall_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        d_loss.backward()\n",
    "\n",
    "        opt_D.step()\n",
    "\n",
    "        # for p in D.parameters():\n",
    "        #    p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        if steps % n_critic == 0:\n",
    "            z = torch.randn(batch_size, z_dim).cuda()\n",
    "            gen_imgs = G(z)\n",
    "            # validity, _ = D(gen_imgs)\n",
    "            # g_loss = -torch.mean(adversarial_loss(validity, valid))\n",
    "            g_loss = -torch.mean(D(gen_imgs)[0])\n",
    "            \n",
    "            G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "        tb.add_scalar('f1_score', f1score, (epoch+1)*i)\n",
    "        tb.add_scalar('accuracy', accuracy, (epoch+1)*i)\n",
    "        \n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %f, f1: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epoch, i, len(tr_dataloader), d_loss.item(), accuracy, f1score, g_loss.item())\n",
    "        )\n",
    "\n",
    "        # batches_done = epoch * len(tr_dataloader) + i\n",
    "        # if batches_done % sample_interval == 0:\n",
    "        #     save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2382447429906542 0.10450917929474088\n"
     ]
    }
   ],
   "source": [
    "D.eval()\n",
    "f1score = 0.0\n",
    "accuracy = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, labels) in enumerate(te_dataloader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        pred_true, pred_labels = D(imgs)\n",
    "        pred = pred_labels.data.cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        real = labels.data.cpu().numpy()\n",
    "        accuracy += accuracy_score(real, pred)\n",
    "        # precision = precision_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        f1score += f1_score(real, pred, average='macro', zero_division=1)\n",
    "        # recall = recall_score(gt, y_pred, average='macro', zero_division=1)\n",
    "length = len(te_dataloader)\n",
    "print(accuracy/length, f1score/length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5, 10, 10, 10,  6,  6,  6, 10, 10,  6, 10,  6, 10, 10, 10, 10,\n",
       "        6, 10,  6, 10, 10, 10,  6,  6,  6, 10,  6, 10, 10, 10,  6, 10, 10,\n",
       "        5,  5,  5, 10,  5, 10, 10,  6, 10, 10, 10,  6, 10, 10,  6,  6, 10,\n",
       "        6, 10,  6,  5,  6,  6,  6, 10,  5,  6, 10, 10, 10,  6, 10,  5,  6,\n",
       "        5, 10, 10,  5, 10, 10, 10, 10,  6,  5, 10, 10,  6, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10,  5, 10,  6,  5, 10,  5,  6, 10, 10, 10, 10, 10, 10,\n",
       "       10,  5, 10,  6, 10, 10, 10,  5,  6,  6, 10, 10, 10, 10,  5, 10,  6,\n",
       "        6, 10,  6,  6,  6, 10,  6, 10, 10,  6,  6,  6,  5, 10, 10, 10,  6,\n",
       "        6, 10,  6, 10, 10,  6, 10,  6, 10, 10, 10, 10, 10,  6, 10, 10, 10,\n",
       "        6,  6, 10, 10, 10,  5, 10, 10, 10,  6,  6,  6, 10, 10,  5,  6, 10,\n",
       "       10, 10,  6, 10,  6, 10,  5, 10,  5, 10,  6,  5, 10, 10, 10, 10,  5,\n",
       "        6,  6,  6, 10, 10,  6,  6,  6, 10,  5, 10,  5, 10, 10,  6, 10, 10,\n",
       "       10, 10,  6, 10,  5, 10, 10,  6,  6,  5,  5, 10, 10,  6, 10, 10,  6,\n",
       "       10, 10, 10,  6,  6, 10,  6, 10, 10,  6, 10,  5, 10,  6, 10, 10,  6,\n",
       "        6,  6, 10, 10, 10, 10, 10, 10,  6, 10, 10,  6,  6, 10, 10, 10, 10,\n",
       "        6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 3, 6, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:5]\n",
    "real[:5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b82254768225213474ab4669cea3d52fe6b864ad6c9d79489ae1089fd4498"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
