{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from qqdm.notebook import qqdm\n",
    "import random\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "#sys\n",
    "import os\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 为了结果可复现\n",
    "Seed = 42\n",
    "same_seeds(Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "raw_data = pd.read_csv('/home/jsm/code/python/IoT-botnet/data/UNSW-NB15 - CSV Files/unsw15_train.csv')\n",
    "temp = raw_data.loc[raw_data['attack_cat'] == 'Normal']\n",
    "temp = temp.drop(['attack_cat', 'label'], axis=1, inplace=False)\n",
    "temp = temp.sample(1000*3, random_state=Seed)\n",
    "# temp = gdata.iloc[:,-3]\n",
    "# gdata = pd.concat([gdata, temp], axis=1)\n",
    "# gdata.columns = range(gdata.shape[-1])\n",
    "# print(gdata.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=128, batch_size=150)\n",
    "tr_data = ipca.fit_transform(temp.values)\n",
    "print(tr_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 在数据1维处增加1个维度 example: (64, 197) --> (64, 1, 197)\n",
    "        self.data = data.unsqueeze(1)\n",
    "        # self.data = torch.FloatTensor(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset(torch.from_numpy(tr_data).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在处理好数据后定义\n",
    "# InputLength = 64\n",
    "workspace_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # 初始化网络层\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, 1, in_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.dim = dim\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, self.in_dim, bias=False),\n",
    "            # tf 默认为0.3， torch 默认为0.01\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.midlayer = nn.Sequential(\n",
    "            # tf中一维卷积filter表示卷积核的个数，与torch中的out_channel相同\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Conv1d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = self.midlayer(y)\n",
    "        y = self.outlayer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, )\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, in_channel=1, batch=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.in_dim = in_dim\n",
    "        self.batch = batch\n",
    "        # self.channel = channel\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.MaxPool1d(kernel_size = 2) # shape: (N, 32, in_dim/2)\n",
    "        )\n",
    "        self.midlayer1 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.MaxPool1d(kernel_size=2), # shape: (N, 32, in_dim/2/2)\n",
    "            nn.Flatten(), # shape: (N, 32*in_dim/2/2)\n",
    "        )\n",
    "        self.temp_dim = 32 * math.floor(math.floor(self.in_dim / 2) / 2)\n",
    "        self.midlayer2 = nn.Sequential(\n",
    "            nn.Linear(self.temp_dim, 64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.outlayer = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = self.midlayer1(y)\n",
    "        y = self.midlayer2(y)\n",
    "        y = self.outlayer(y)\n",
    "        y = y.view(-1)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainnig hyperparmeters\n",
    "batch_size = 128\n",
    "in_dim = tr_data.shape[-1]\n",
    "z_dim = in_dim\n",
    "z_sample = Variable(torch.randn(batch_size, 1, z_dim)).cuda()\n",
    "lr = 1e-4\n",
    "\n",
    "n_epoch = 1000\n",
    "n_critic = 10\n",
    "# 待改\n",
    "clip_value = 0.1\n",
    "\n",
    "ckpt_dir = os.path.join(workspace_dir, 'checkpoints')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# Model\n",
    "G = Generator(in_dim).cuda()\n",
    "D = Discriminator(in_dim, 1).cuda()\n",
    "G.train()\n",
    "D.train()\n",
    "\n",
    "# Loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "opt_D = torch.optim.RMSprop(D.parameters(), lr=lr)\n",
    "opt_G = torch.optim.RMSprop(D.parameters(), lr=lr)\n",
    "\n",
    "#DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 0\n",
    "for e, epoch in enumerate(range(n_epoch)):\n",
    "    progress_bar = qqdm(dataloader)\n",
    "    for i, data in enumerate(progress_bar):\n",
    "        mid_data = data\n",
    "        # print(mid_data.size())\n",
    "        mid_data = mid_data.cuda()\n",
    "        bs = mid_data.size(0)\n",
    "\n",
    "        # ============================================\n",
    "        #  Train D\n",
    "        # ============================================\n",
    "        z = Variable(torch.randn(bs, 1, z_dim)).cuda()\n",
    "        r_data = Variable(mid_data).cuda()\n",
    "        f_data = G(z)\n",
    "        # print(f_data)\n",
    "        # \"\"\" Medium: Use WGAN Loss. \"\"\"\n",
    "        # Label\n",
    "        r_label = torch.ones((bs)).cuda()\n",
    "        f_label = torch.zeros((bs)).cuda()\n",
    "\n",
    "        # Model forwarding\n",
    "        r_logit = D(r_data.detach())\n",
    "        f_logit = D(f_data.detach())\n",
    "        # print('r_logit: {}'.format(r_logit))\n",
    "        # print('f_logit: {}'.format(f_logit))\n",
    "        # print('r_logit size {}, f_logit size{}'.format(r_logit.size(), f_logit.size()))\n",
    "        # print('r_logit size {}, r_label size{}'.format(r_logit.size(), r_label.size()))\n",
    "        # # Compute the loss for the discriminator\n",
    "        # r_loss = criterion(r_logit, r_label) \n",
    "        # f_loss = criterion(f_logit, f_label)\n",
    "        # # loss_D = (r_loss + f_loss) / 2\n",
    "\n",
    "        # WGAN Loss\n",
    "        loss_D = -torch.mean(D(r_data)) + torch.mean(D(f_data))\n",
    "\n",
    "        # Model backwarding\n",
    "        D.zero_grad()\n",
    "        loss_D.backward()\n",
    "\n",
    "        # Updata the discriminator\n",
    "        opt_D.step()\n",
    "\n",
    "        \"\"\" Medium: Clip weights of discriminator. \"\"\"\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-clip_value, clip_value)\n",
    "        \n",
    "        # ============================================\n",
    "        #  Train G\n",
    "        # ============================================\n",
    "        if steps % n_critic == 0:\n",
    "            # Generate some fake data\n",
    "            z = Variable(torch.randn(bs, 1, z_dim)).cuda()\n",
    "            f_data = G(z)\n",
    "\n",
    "            # Model forearding\n",
    "            f_logit = D(f_data)\n",
    "\n",
    "            # WGAN Loss\n",
    "            loss_G = -torch.mean(D(f_data))\n",
    "\n",
    "            # Model backwarding\n",
    "            G.zero_grad()\n",
    "            loss_G.backward()\n",
    "\n",
    "            # Updata the generator\n",
    "            opt_G.step()\n",
    "        \n",
    "        steps += 1\n",
    "\n",
    "        # Set the info of the progress bar\n",
    "        #   Note that the value of the GAN loss is not directly related to\n",
    "        #   the quality of the generated images.\n",
    "        progress_bar.set_infos({\n",
    "            'Loss_D': round(loss_D.item(), 4),\n",
    "            'Loss_G': round(loss_G.item(), 4),\n",
    "            'Epoch': e+1,\n",
    "            'Step': steps,\n",
    "        })\n",
    "\n",
    "        G.eval()\n",
    "        f_data_sample = G(z_sample).data\n",
    "        G.train()\n",
    "\n",
    "        if (e+1) % 5 == 0 or e == 0:\n",
    "            # Save the checkpoints\n",
    "            torch.save(G.state_dict(), os.path.join(ckpt_dir, 'G.pth'))\n",
    "            torch.save(D.state_dict(), os.path.join(ckpt_dir, 'D.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b82254768225213474ab4669cea3d52fe6b864ad6c9d79489ae1089fd4498"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
