{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "# import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "#sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 为了结果可复现\n",
    "Seed = 42\n",
    "same_seeds(Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "raw_data = pd.read_csv('/home/jsm/code/python/IoT-botnet/data/UNSW-NB15 - CSV Files/unsw15_train.csv')\n",
    "temp = raw_data.loc[raw_data['attack_cat'] == 'Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_drop = temp.drop(['196', 'attack_cat', 'label'], axis=1, inplace=False)\n",
    "temp_sameple = temp_drop.sample(1024*60, random_state=Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sameple.shape\n",
    "tr_data = temp_sameple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # batch_size,\n",
    "        # num_workers,\n",
    "        data\n",
    "    ):\n",
    "        # 在数据1维处增加1个维度 example: (64, 197) --> (64, 1, 197)\n",
    "        # self.batch_size = batch_size\n",
    "        # self.num_workers = num_workers\n",
    "        self.data = data.unsqueeze(1)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = MyDataset(torch.from_numpy(tr_data.values).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在处理好数据后定义\n",
    "# InputLength = 64\n",
    "workspace_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # 初始化网络层\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, 1, in_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.dim = dim\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, self.in_dim, bias=False),\n",
    "            # tf 默认为0.3， torch 默认为0.01\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.midlayer = nn.Sequential(\n",
    "            # tf中一维卷积filter表示卷积核的个数，与torch中的out_channel相同\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Conv1d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = self.midlayer(y)\n",
    "        y = self.outlayer(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, )\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, in_channel=1, batch=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.in_dim = in_dim\n",
    "        self.batch = batch\n",
    "        # self.channel = channel\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.MaxPool1d(kernel_size = 2) # shape: (N, 32, in_dim/2)\n",
    "        )\n",
    "        self.midlayer1 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.MaxPool1d(kernel_size=2), # shape: (N, 32, in_dim/2/2)\n",
    "            nn.Flatten(), # shape: (N, 32*in_dim/2/2)\n",
    "        )\n",
    "        self.temp_dim = 32 * math.floor(math.floor(self.in_dim / 2) / 2)\n",
    "        self.midlayer2 = nn.Sequential(\n",
    "            nn.Linear(self.temp_dim, 64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.outlayer = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = self.midlayer1(y)\n",
    "        y = self.midlayer2(y)\n",
    "        y = self.outlayer(y)\n",
    "        y = y.view(-1)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int = 16,\n",
    "        in_channels: int = 1,\n",
    "        lr: float = 1e-4,\n",
    "        n_critic: int = 5,\n",
    "        clip_value: float = 0.1,\n",
    "        batch_size: int = BATCH_SIZE,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # networks\n",
    "        self.generator = Generator(in_dim=self.hparams.in_dim)\n",
    "        self.discriminator = Discriminator(in_dim=self.hparams.in_dim, in_channel=self.hparams.in_channels)\n",
    "        self.validation_z = torch.randn(10, self.hparams.in_channels, self.hparams.in_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return -torch.mean(self.discriminator(y)) + torch.mean(self.discriminator(y_hat))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "\n",
    "        data = batch\n",
    "        z = torch.randn(self.hparams.batch_size, self.hparams.in_channels, self.hparams.in_dim)\n",
    "        z = z.type_as(data)\n",
    "        # train generator\n",
    "        if optimizer_idx == 0 and (batch_idx % self.hparams.n_critic == 0 and batch_idx != 0):\n",
    "            # print('batch_idx {}, optimizer_idx{}'.format(batch_idx, optimizer_idx))\n",
    "            # generate data\n",
    "            self.generated_data = self(z)\n",
    "            \n",
    "            # log sampled data\n",
    "            # sample_data = self.generated_data[:10]\n",
    "            # self.logger.experiment.add_scalar(\"generated_data\", sample_data[0], 0)\n",
    "\n",
    "            # generator of WGAN loss\n",
    "            g_loss = -torch.mean(self.discriminator(self(z)))\n",
    "            self.logger.experiment.add_scalar(\"g_loss\", g_loss, self.current_epoch)\n",
    "            tqdm_dict = {\"g_loss\": g_loss}\n",
    "            output = OrderedDict({\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # print('batch_idx {}, optimizer_idx{}'.format(batch_idx, optimizer_idx))\n",
    "            # discriminator of WGAN loss\n",
    "            d_loss = -torch.mean(self.discriminator(data)) + torch.mean(self.discriminator(self(z)))\n",
    "            self.logger.experiment.add_scalar(\"d_loss\", d_loss, self.current_epoch)\n",
    "            # Clip weights of discriminator\n",
    "            for p in self.discriminator.parameters():\n",
    "                p.data.clamp_(-self.hparams.clip_value, self.hparams.clip_value)\n",
    "\n",
    "            tqdm_dict = {\"d_loss\": d_loss}\n",
    "            output = OrderedDict({\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "\n",
    "        opt_g = torch.optim.RMSprop(self.generator.parameters(), lr=lr)\n",
    "        opt_d = torch.optim.RMSprop(self.discriminator.parameters(), lr=lr)\n",
    "        \n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    # def on_epoch_end(self):\n",
    "        # z = self.validation_z.type_as(self.generator.model[0].weight)\n",
    "\n",
    "        # # log sampled data\n",
    "        # sample_data = self(z)\n",
    "        # # self.logger.experiment.add_scalar(\"generated_data\", sample_data[0], self.current_epoch)\n",
    "        # self.log(\"generated_data\", sample_data, logger=True)\n",
    "        # print(\"g_loss {}, d_loss {}\".format(g_loss, d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataloder = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "in_dim = tr_data.shape[-1]\n",
    "wgan = WGAN(in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 44.8 K\n",
      "1 | discriminator | Discriminator | 103 K \n",
      "------------------------------------------------\n",
      "148 K     Trainable params\n",
      "0         Non-trainable params\n",
      "148 K     Total params\n",
      "0.594     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dcb634e9ea4c759764c364a790945e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    gpus = AVAIL_GPUS,\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate = 20\n",
    ")\n",
    "trainer.fit(wgan, tr_dataloder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b82254768225213474ab4669cea3d52fe6b864ad6c9d79489ae1089fd4498"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
