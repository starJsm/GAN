{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch import nn\n",
    "# import pytorch_lightning as pl\n",
    "from pytorch_lightning import  LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "#sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import random\n",
    "\n",
    "# data process\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    # python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 为了结果可复现\n",
    "Seed = 42\n",
    "same_seeds(Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # shuffle 是否将官方给的的测试集和训练集重新打乱，再分成新的的训练集和测试集\n",
    " # ss标准化\n",
    "def process_data(tr_data, te_data=None, ss=None, shuffle=False):\n",
    "    split_num = len(tr_data)\n",
    "    data_temp = pd.concat([tr_data, te_data], axis=0)\n",
    "    data = pd.get_dummies(data_temp.iloc[:, 1:-2])\n",
    "    data['cat_code'] = LabelEncoder().fit_transform(data_temp.loc[:, 'attack_cat'])\n",
    "    # data['label'] = data_temp['label']\n",
    "    # data['attack_cat'] = data_temp['attack_cat']\n",
    "    if ss != None:\n",
    "        data.iloc[:,:-3] = ss.fit_transform(data.iloc[:,:-3])\n",
    "    if shuffle:\n",
    "        pass\n",
    "    else:\n",
    "        return data.iloc[:split_num,:], data.iloc[split_num:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>state_ACC</th>\n",
       "      <th>state_CLO</th>\n",
       "      <th>state_CON</th>\n",
       "      <th>state_ECO</th>\n",
       "      <th>state_FIN</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>state_PAR</th>\n",
       "      <th>state_REQ</th>\n",
       "      <th>state_RST</th>\n",
       "      <th>cat_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.188346</td>\n",
       "      <td>-0.101342</td>\n",
       "      <td>-0.129612</td>\n",
       "      <td>-0.047849</td>\n",
       "      <td>-0.097232</td>\n",
       "      <td>-0.568650</td>\n",
       "      <td>0.702512</td>\n",
       "      <td>1.500906</td>\n",
       "      <td>-0.380090</td>\n",
       "      <td>-0.269328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.099897</td>\n",
       "      <td>-0.042496</td>\n",
       "      <td>0.173998</td>\n",
       "      <td>-0.045110</td>\n",
       "      <td>0.188966</td>\n",
       "      <td>-0.568623</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380121</td>\n",
       "      <td>-0.064104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063006</td>\n",
       "      <td>-0.086630</td>\n",
       "      <td>-0.022456</td>\n",
       "      <td>-0.047239</td>\n",
       "      <td>-0.008217</td>\n",
       "      <td>-0.569024</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380158</td>\n",
       "      <td>-0.247593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072800</td>\n",
       "      <td>-0.057207</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>-0.045720</td>\n",
       "      <td>-0.093142</td>\n",
       "      <td>-0.569027</td>\n",
       "      <td>-1.151363</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380152</td>\n",
       "      <td>-0.271458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.133449</td>\n",
       "      <td>-0.071919</td>\n",
       "      <td>-0.111753</td>\n",
       "      <td>-0.046261</td>\n",
       "      <td>-0.096576</td>\n",
       "      <td>-0.568904</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>1.483170</td>\n",
       "      <td>-0.380121</td>\n",
       "      <td>-0.271197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00394</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.291137</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>1.095103</td>\n",
       "      <td>-0.90798</td>\n",
       "      <td>-0.00197</td>\n",
       "      <td>-0.122882</td>\n",
       "      <td>-0.018058</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
       "0 -0.188346 -0.101342 -0.129612 -0.047849 -0.097232 -0.568650  0.702512   \n",
       "1 -0.099897 -0.042496  0.173998 -0.045110  0.188966 -0.568623 -1.151363   \n",
       "2  0.063006 -0.086630 -0.022456 -0.047239 -0.008217 -0.569024 -1.151363   \n",
       "3  0.072800 -0.057207 -0.058174 -0.045720 -0.093142 -0.569027 -1.151363   \n",
       "4 -0.133449 -0.071919 -0.111753 -0.046261 -0.096576 -0.568904  0.722026   \n",
       "\n",
       "       dttl     sload     dload  ...  state_ACC  state_CLO  state_CON  \\\n",
       "0  1.500906 -0.380090 -0.269328  ...   -0.00394   -0.00197  -0.291137   \n",
       "1  1.483170 -0.380121 -0.064104  ...   -0.00394   -0.00197  -0.291137   \n",
       "2  1.483170 -0.380158 -0.247593  ...   -0.00394   -0.00197  -0.291137   \n",
       "3  1.483170 -0.380152 -0.271458  ...   -0.00394   -0.00197  -0.291137   \n",
       "4  1.483170 -0.380121 -0.271197  ...   -0.00394   -0.00197  -0.291137   \n",
       "\n",
       "   state_ECO  state_FIN  state_INT  state_PAR  state_REQ  state_RST  cat_code  \n",
       "0  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "1  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "2  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "3  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "4  -0.006824   1.095103   -0.90798   -0.00197  -0.122882  -0.018058         6  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据未处理的数据\n",
    "tr_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_testing-set.csv')\n",
    "te_raw_data = pd.read_csv('/home/jsm/code/python/unsupervisedGAN/data/UNSW-NB15/part/UNSW_NB15_training-set.csv')\n",
    "ss = StandardScaler()\n",
    "# 调用数据处理函数\n",
    "tr_data, te_data = process_data(tr_raw_data, te_raw_data, ss)\n",
    "# 挑选'Normal'的列，'cat_code'=6\n",
    "# tr_data = tr_data.loc[tr_data['cat_code'] == 6]\n",
    "# tr_data.drop(['cat_code'], axis=1, inplace=True)\n",
    "# 去掉无用的列\n",
    "tr_data.drop(['state_URN', 'state_no'], axis=1, inplace=True)\n",
    "te_data.drop(['state_URN', 'state_no'], axis=1, inplace=True)\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None:\n",
    "            y = y.astype(np.int64)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = MyDataset(tr_data.values[:,:-1], tr_data.values[:,-1])\n",
    "te_dataset = MyDataset(te_data.values[:,:-1], te_data.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # 初始化网络层\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, in_dim)\n",
    "    Output shape: (N, 1, out_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        def dconv_bn_relu(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose1d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n",
    "                nn.BatchNorm1d(out_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(in_dim, dim*4*4*4, bias=False),\n",
    "            # tf 默认为0.3， torch 默认为0.01\n",
    "            nn.BatchNorm1d(dim*4*4*4),\n",
    "            nn.ReLU()\n",
    "            # nn.LeakyReLU(negative_slope=0.2)\n",
    "        )\n",
    "        self.midlayer = nn.Sequential(\n",
    "           dconv_bn_relu(dim*4, dim*2),\n",
    "        #    dconv_bn_relu(dim*2, dim*2),\n",
    "           dconv_bn_relu(dim*2, dim),\n",
    "           dconv_bn_relu(dim, 1)\n",
    "        )\n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Linear(128, out_dim, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.inlayer(x)\n",
    "        y = y.view(y.size(0), -1, 16)\n",
    "        y = self.midlayer(y)\n",
    "        y = y.squeeze(1)\n",
    "        y = self.outlayer(y)\n",
    "        y = y.unsqueeze(1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Input shape: (N, 1, in_dim)\n",
    "    Output shape: (N, )\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, dlatent_dim=128, in_channel=1, channel=8, num_classes=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_bn_lrelu(in_channel, out_channel):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channel, out_channel, 5, 2, 2),\n",
    "                nn.BatchNorm1d(out_channel),\n",
    "                nn.LeakyReLU(0.2),\n",
    "            )\n",
    "\n",
    "        self.inlayer = nn.Sequential(\n",
    "            nn.Linear(in_dim, dlatent_dim, bias=False),\n",
    "            nn.BatchNorm1d(dlatent_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.ls = nn.Sequential(\n",
    "            conv_bn_lrelu(in_channel, channel),\n",
    "            conv_bn_lrelu(channel, channel * 2),\n",
    "            conv_bn_lrelu(channel * 2, channel * 4),\n",
    "            conv_bn_lrelu(channel * 4, channel * 8),\n",
    "            conv_bn_lrelu(channel * 8, channel * 16),\n",
    "            nn.Conv1d(channel * 16, dlatent_dim, 4),\n",
    "        )\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Linear(dlatent_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        self.aux_layer = nn.Sequential(\n",
    "            nn.Linear(dlatent_dim, num_classes + 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        # self.apply(weights_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x.squeeze(1)\n",
    "        y = self.inlayer(y)\n",
    "        y = y.unsqueeze(1)\n",
    "        y = self.ls(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        validity = self.adv_layer(y)\n",
    "        label = self.aux_layer(y)\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "batch_size = 512\n",
    "z_dim = 100\n",
    "gout_dim = tr_data.shape[-1] - 1\n",
    "# 将tensor(张量)转化成variable(变量)。之所以需要将tensor转化成variable是因为pytorch中tensor(张量)只能放在CPU上运算，而(variable)变量是可以只用GPU进行加速计算的。\n",
    "z_sample = Variable(torch.randn(100, z_dim)).cuda()\n",
    "lr = 1e-4\n",
    "\n",
    "\"\"\" Medium: WGAN, 50 epoch, n_critic=5, clip_value=0.01 \"\"\"\n",
    "n_epoch = 50 # 50\n",
    "n_critic = 5 # 5\n",
    "clip_value = 0.01\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "workspace_dir = '.'\n",
    "log_dir = os.path.join(workspace_dir, 'lightning_logs')\n",
    "ckpt_dir = os.path.join(workspace_dir, 'checkpoints')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# Model\n",
    "G = Generator(in_dim=z_dim, out_dim=gout_dim)\n",
    "D = Discriminator(in_dim=gout_dim)\n",
    "G.train()\n",
    "D.train()\n",
    "\n",
    "# Loss\n",
    "# 一个二分类损失函数。可以是单标签的损失函数也可是多标签的损失函数。\n",
    "# https://blog.csdn.net/weixin_37724529/article/details/107084970\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\"\"\" Medium: Use RMSprop for WGAN. \"\"\"\n",
    "# Optimizer\n",
    "opt_D = torch.optim.RMSprop(D.parameters(), lr=lr)\n",
    "opt_G = torch.optim.RMSprop(G.parameters(), lr=lr)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# DataLoader\n",
    "tr_dataloader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "te_dataloader = DataLoader(te_dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [Batch 0/342] [D loss: -0.048119, acc: 0.500000, f1: 0.066667] [G loss: 0.734228]\n",
      "[Epoch 0/50] [Batch 1/342] [D loss: -0.048123, acc: 0.500000, f1: 0.060606] [G loss: 0.734230]\n",
      "[Epoch 0/50] [Batch 2/342] [D loss: -0.048125, acc: 0.500000, f1: 0.066667] [G loss: 0.734232]\n",
      "[Epoch 0/50] [Batch 3/342] [D loss: -0.048129, acc: 0.500000, f1: 0.066667] [G loss: 0.734235]\n",
      "[Epoch 0/50] [Batch 4/342] [D loss: -0.048133, acc: 0.500000, f1: 0.066667] [G loss: 0.734239]\n",
      "[Epoch 0/50] [Batch 5/342] [D loss: -0.048136, acc: 0.500000, f1: 0.066667] [G loss: 0.734241]\n",
      "[Epoch 0/50] [Batch 6/342] [D loss: -0.048142, acc: 0.500000, f1: 0.066667] [G loss: 0.734246]\n",
      "[Epoch 0/50] [Batch 7/342] [D loss: -0.048146, acc: 0.500000, f1: 0.066667] [G loss: 0.734250]\n",
      "[Epoch 0/50] [Batch 8/342] [D loss: -0.048154, acc: 0.500000, f1: 0.060606] [G loss: 0.734256]\n",
      "[Epoch 0/50] [Batch 9/342] [D loss: -0.048160, acc: 0.500000, f1: 0.060606] [G loss: 0.734261]\n",
      "[Epoch 0/50] [Batch 10/342] [D loss: -0.048166, acc: 0.500000, f1: 0.066667] [G loss: 0.734267]\n",
      "[Epoch 0/50] [Batch 11/342] [D loss: -0.048173, acc: 0.500000, f1: 0.066667] [G loss: 0.734272]\n",
      "[Epoch 0/50] [Batch 12/342] [D loss: -0.048174, acc: 0.500000, f1: 0.066667] [G loss: 0.734275]\n",
      "[Epoch 0/50] [Batch 13/342] [D loss: -0.048179, acc: 0.500000, f1: 0.066667] [G loss: 0.734278]\n",
      "[Epoch 0/50] [Batch 14/342] [D loss: -0.048182, acc: 0.500000, f1: 0.066667] [G loss: 0.734281]\n",
      "[Epoch 0/50] [Batch 15/342] [D loss: -0.048184, acc: 0.500000, f1: 0.066667] [G loss: 0.734283]\n",
      "[Epoch 0/50] [Batch 16/342] [D loss: -0.048188, acc: 0.500000, f1: 0.066667] [G loss: 0.734286]\n",
      "[Epoch 0/50] [Batch 17/342] [D loss: -0.048191, acc: 0.500000, f1: 0.060606] [G loss: 0.734288]\n",
      "[Epoch 0/50] [Batch 18/342] [D loss: -0.048191, acc: 0.500000, f1: 0.074074] [G loss: 0.734290]\n",
      "[Epoch 0/50] [Batch 19/342] [D loss: -0.048196, acc: 0.500000, f1: 0.066667] [G loss: 0.734293]\n",
      "[Epoch 0/50] [Batch 20/342] [D loss: -0.048199, acc: 0.500000, f1: 0.066667] [G loss: 0.734295]\n",
      "[Epoch 0/50] [Batch 21/342] [D loss: -0.048201, acc: 0.500000, f1: 0.060606] [G loss: 0.734297]\n",
      "[Epoch 0/50] [Batch 22/342] [D loss: -0.048202, acc: 0.500000, f1: 0.066667] [G loss: 0.734299]\n",
      "[Epoch 0/50] [Batch 23/342] [D loss: -0.048207, acc: 0.500000, f1: 0.066667] [G loss: 0.734301]\n",
      "[Epoch 0/50] [Batch 24/342] [D loss: -0.048208, acc: 0.500000, f1: 0.066667] [G loss: 0.734303]\n",
      "[Epoch 0/50] [Batch 25/342] [D loss: -0.048209, acc: 0.500000, f1: 0.060606] [G loss: 0.734305]\n",
      "[Epoch 0/50] [Batch 26/342] [D loss: -0.048210, acc: 0.500000, f1: 0.060606] [G loss: 0.734307]\n",
      "[Epoch 0/50] [Batch 27/342] [D loss: -0.048215, acc: 0.500000, f1: 0.060606] [G loss: 0.734309]\n",
      "[Epoch 0/50] [Batch 28/342] [D loss: -0.048215, acc: 0.500000, f1: 0.066667] [G loss: 0.734311]\n",
      "[Epoch 0/50] [Batch 29/342] [D loss: -0.048218, acc: 0.500000, f1: 0.074074] [G loss: 0.734312]\n",
      "[Epoch 0/50] [Batch 30/342] [D loss: -0.048221, acc: 0.500000, f1: 0.066667] [G loss: 0.734315]\n",
      "[Epoch 0/50] [Batch 31/342] [D loss: -0.048225, acc: 0.500000, f1: 0.060606] [G loss: 0.734316]\n",
      "[Epoch 0/50] [Batch 32/342] [D loss: -0.048218, acc: 0.500000, f1: 0.066667] [G loss: 0.734319]\n",
      "[Epoch 0/50] [Batch 33/342] [D loss: -0.048229, acc: 0.500000, f1: 0.066667] [G loss: 0.734321]\n",
      "[Epoch 0/50] [Batch 34/342] [D loss: -0.048231, acc: 0.500000, f1: 0.060606] [G loss: 0.734322]\n",
      "[Epoch 0/50] [Batch 35/342] [D loss: -0.048233, acc: 0.500000, f1: 0.060606] [G loss: 0.734324]\n",
      "[Epoch 0/50] [Batch 36/342] [D loss: -0.048235, acc: 0.500000, f1: 0.060606] [G loss: 0.734326]\n",
      "[Epoch 0/50] [Batch 37/342] [D loss: -0.048236, acc: 0.500000, f1: 0.060606] [G loss: 0.734328]\n",
      "[Epoch 0/50] [Batch 38/342] [D loss: -0.048239, acc: 0.500000, f1: 0.066667] [G loss: 0.734330]\n",
      "[Epoch 0/50] [Batch 39/342] [D loss: -0.048241, acc: 0.500000, f1: 0.060606] [G loss: 0.734331]\n",
      "[Epoch 0/50] [Batch 40/342] [D loss: -0.048243, acc: 0.500000, f1: 0.066667] [G loss: 0.734333]\n",
      "[Epoch 0/50] [Batch 41/342] [D loss: -0.048247, acc: 0.500000, f1: 0.060606] [G loss: 0.734335]\n",
      "[Epoch 0/50] [Batch 42/342] [D loss: -0.048246, acc: 0.500000, f1: 0.060606] [G loss: 0.734337]\n",
      "[Epoch 0/50] [Batch 43/342] [D loss: -0.048249, acc: 0.500000, f1: 0.060606] [G loss: 0.734338]\n",
      "[Epoch 0/50] [Batch 44/342] [D loss: -0.048252, acc: 0.500000, f1: 0.066667] [G loss: 0.734340]\n",
      "[Epoch 0/50] [Batch 45/342] [D loss: -0.048254, acc: 0.500000, f1: 0.060606] [G loss: 0.734342]\n",
      "[Epoch 0/50] [Batch 46/342] [D loss: -0.048257, acc: 0.500000, f1: 0.066667] [G loss: 0.734345]\n",
      "[Epoch 0/50] [Batch 47/342] [D loss: -0.048259, acc: 0.500000, f1: 0.066667] [G loss: 0.734346]\n",
      "[Epoch 0/50] [Batch 48/342] [D loss: -0.048261, acc: 0.500000, f1: 0.066667] [G loss: 0.734349]\n",
      "[Epoch 0/50] [Batch 49/342] [D loss: -0.048265, acc: 0.500000, f1: 0.066667] [G loss: 0.734351]\n",
      "[Epoch 0/50] [Batch 50/342] [D loss: -0.048266, acc: 0.500000, f1: 0.066667] [G loss: 0.734353]\n",
      "[Epoch 0/50] [Batch 51/342] [D loss: -0.048270, acc: 0.500000, f1: 0.066667] [G loss: 0.734356]\n",
      "[Epoch 0/50] [Batch 52/342] [D loss: -0.048272, acc: 0.500000, f1: 0.066667] [G loss: 0.734357]\n",
      "[Epoch 0/50] [Batch 53/342] [D loss: -0.048274, acc: 0.500000, f1: 0.066667] [G loss: 0.734360]\n",
      "[Epoch 0/50] [Batch 54/342] [D loss: -0.048277, acc: 0.500000, f1: 0.066667] [G loss: 0.734362]\n",
      "[Epoch 0/50] [Batch 55/342] [D loss: -0.048280, acc: 0.500000, f1: 0.060606] [G loss: 0.734365]\n",
      "[Epoch 0/50] [Batch 56/342] [D loss: -0.048283, acc: 0.500000, f1: 0.066667] [G loss: 0.734367]\n",
      "[Epoch 0/50] [Batch 57/342] [D loss: -0.048286, acc: 0.500000, f1: 0.060606] [G loss: 0.734370]\n",
      "[Epoch 0/50] [Batch 58/342] [D loss: -0.048288, acc: 0.500000, f1: 0.060606] [G loss: 0.734372]\n",
      "[Epoch 0/50] [Batch 59/342] [D loss: -0.048292, acc: 0.500000, f1: 0.066667] [G loss: 0.734375]\n",
      "[Epoch 0/50] [Batch 60/342] [D loss: -0.048295, acc: 0.500000, f1: 0.066667] [G loss: 0.734378]\n",
      "[Epoch 0/50] [Batch 61/342] [D loss: -0.048297, acc: 0.500000, f1: 0.074074] [G loss: 0.734380]\n",
      "[Epoch 0/50] [Batch 62/342] [D loss: -0.048302, acc: 0.500000, f1: 0.066667] [G loss: 0.734383]\n",
      "[Epoch 0/50] [Batch 63/342] [D loss: -0.048305, acc: 0.500000, f1: 0.060606] [G loss: 0.734386]\n",
      "[Epoch 0/50] [Batch 64/342] [D loss: -0.048308, acc: 0.500000, f1: 0.066667] [G loss: 0.734389]\n",
      "[Epoch 0/50] [Batch 65/342] [D loss: -0.048312, acc: 0.500000, f1: 0.060606] [G loss: 0.734392]\n",
      "[Epoch 0/50] [Batch 66/342] [D loss: -0.048314, acc: 0.500000, f1: 0.060606] [G loss: 0.734395]\n",
      "[Epoch 0/50] [Batch 67/342] [D loss: -0.048319, acc: 0.500000, f1: 0.066667] [G loss: 0.734399]\n",
      "[Epoch 0/50] [Batch 68/342] [D loss: -0.048324, acc: 0.500000, f1: 0.066667] [G loss: 0.734401]\n",
      "[Epoch 0/50] [Batch 69/342] [D loss: -0.048325, acc: 0.500000, f1: 0.060606] [G loss: 0.734404]\n",
      "[Epoch 0/50] [Batch 70/342] [D loss: -0.048330, acc: 0.500000, f1: 0.066667] [G loss: 0.734409]\n",
      "[Epoch 0/50] [Batch 71/342] [D loss: -0.048334, acc: 0.500000, f1: 0.066667] [G loss: 0.734411]\n",
      "[Epoch 0/50] [Batch 72/342] [D loss: -0.048336, acc: 0.500000, f1: 0.066667] [G loss: 0.734414]\n",
      "[Epoch 0/50] [Batch 73/342] [D loss: -0.048340, acc: 0.500000, f1: 0.066667] [G loss: 0.734418]\n",
      "[Epoch 0/50] [Batch 74/342] [D loss: -0.048343, acc: 0.500000, f1: 0.060606] [G loss: 0.734421]\n",
      "[Epoch 0/50] [Batch 75/342] [D loss: -0.048347, acc: 0.500000, f1: 0.060606] [G loss: 0.734424]\n",
      "[Epoch 0/50] [Batch 76/342] [D loss: -0.048352, acc: 0.500000, f1: 0.066667] [G loss: 0.734428]\n",
      "[Epoch 0/50] [Batch 77/342] [D loss: -0.048357, acc: 0.500000, f1: 0.066667] [G loss: 0.734433]\n",
      "[Epoch 0/50] [Batch 78/342] [D loss: -0.048364, acc: 0.500000, f1: 0.066667] [G loss: 0.734438]\n",
      "[Epoch 0/50] [Batch 79/342] [D loss: -0.048370, acc: 0.500000, f1: 0.066667] [G loss: 0.734443]\n",
      "[Epoch 0/50] [Batch 80/342] [D loss: -0.048377, acc: 0.500000, f1: 0.060606] [G loss: 0.734449]\n",
      "[Epoch 0/50] [Batch 81/342] [D loss: -0.048382, acc: 0.500000, f1: 0.066667] [G loss: 0.734455]\n",
      "[Epoch 0/50] [Batch 82/342] [D loss: -0.048392, acc: 0.500000, f1: 0.066667] [G loss: 0.734463]\n",
      "[Epoch 0/50] [Batch 83/342] [D loss: -0.048400, acc: 0.500000, f1: 0.060606] [G loss: 0.734468]\n",
      "[Epoch 0/50] [Batch 84/342] [D loss: -0.048406, acc: 0.500000, f1: 0.066667] [G loss: 0.734474]\n",
      "[Epoch 0/50] [Batch 85/342] [D loss: -0.048409, acc: 0.500000, f1: 0.066667] [G loss: 0.734477]\n",
      "[Epoch 0/50] [Batch 86/342] [D loss: -0.048414, acc: 0.500000, f1: 0.060606] [G loss: 0.734482]\n",
      "[Epoch 0/50] [Batch 87/342] [D loss: -0.048419, acc: 0.500000, f1: 0.066667] [G loss: 0.734486]\n",
      "[Epoch 0/50] [Batch 88/342] [D loss: -0.048413, acc: 0.500000, f1: 0.066667] [G loss: 0.734489]\n",
      "[Epoch 0/50] [Batch 89/342] [D loss: -0.048427, acc: 0.500000, f1: 0.066667] [G loss: 0.734493]\n",
      "[Epoch 0/50] [Batch 90/342] [D loss: -0.048431, acc: 0.500000, f1: 0.066667] [G loss: 0.734496]\n",
      "[Epoch 0/50] [Batch 91/342] [D loss: -0.048436, acc: 0.500000, f1: 0.066667] [G loss: 0.734500]\n",
      "[Epoch 0/50] [Batch 92/342] [D loss: -0.048439, acc: 0.500000, f1: 0.060606] [G loss: 0.734504]\n",
      "[Epoch 0/50] [Batch 93/342] [D loss: -0.048446, acc: 0.500000, f1: 0.060606] [G loss: 0.734510]\n",
      "[Epoch 0/50] [Batch 94/342] [D loss: -0.048451, acc: 0.500000, f1: 0.060606] [G loss: 0.734514]\n",
      "[Epoch 0/50] [Batch 95/342] [D loss: -0.048456, acc: 0.500000, f1: 0.066667] [G loss: 0.734519]\n",
      "[Epoch 0/50] [Batch 96/342] [D loss: -0.048466, acc: 0.500000, f1: 0.060606] [G loss: 0.734525]\n",
      "[Epoch 0/50] [Batch 97/342] [D loss: -0.048471, acc: 0.500000, f1: 0.060606] [G loss: 0.734530]\n",
      "[Epoch 0/50] [Batch 98/342] [D loss: -0.048480, acc: 0.500000, f1: 0.066667] [G loss: 0.734537]\n",
      "[Epoch 0/50] [Batch 99/342] [D loss: -0.048488, acc: 0.500000, f1: 0.066667] [G loss: 0.734544]\n",
      "[Epoch 0/50] [Batch 100/342] [D loss: -0.048496, acc: 0.500000, f1: 0.060606] [G loss: 0.734551]\n",
      "[Epoch 0/50] [Batch 101/342] [D loss: -0.048501, acc: 0.500000, f1: 0.066667] [G loss: 0.734555]\n",
      "[Epoch 0/50] [Batch 102/342] [D loss: -0.048505, acc: 0.500000, f1: 0.066667] [G loss: 0.734560]\n",
      "[Epoch 0/50] [Batch 103/342] [D loss: -0.048511, acc: 0.500000, f1: 0.066667] [G loss: 0.734565]\n",
      "[Epoch 0/50] [Batch 104/342] [D loss: -0.048515, acc: 0.500000, f1: 0.060606] [G loss: 0.734568]\n",
      "[Epoch 0/50] [Batch 105/342] [D loss: -0.048513, acc: 0.500000, f1: 0.066667] [G loss: 0.734573]\n",
      "[Epoch 0/50] [Batch 106/342] [D loss: -0.048525, acc: 0.500000, f1: 0.066667] [G loss: 0.734577]\n",
      "[Epoch 0/50] [Batch 107/342] [D loss: -0.048528, acc: 0.500000, f1: 0.060606] [G loss: 0.734580]\n",
      "[Epoch 0/50] [Batch 108/342] [D loss: -0.048535, acc: 0.500000, f1: 0.066667] [G loss: 0.734585]\n",
      "[Epoch 0/50] [Batch 109/342] [D loss: -0.048539, acc: 0.500000, f1: 0.066667] [G loss: 0.734588]\n",
      "[Epoch 0/50] [Batch 110/342] [D loss: -0.048543, acc: 0.500000, f1: 0.066667] [G loss: 0.734592]\n",
      "[Epoch 0/50] [Batch 111/342] [D loss: -0.048548, acc: 0.500000, f1: 0.066667] [G loss: 0.734595]\n",
      "[Epoch 0/50] [Batch 112/342] [D loss: -0.048553, acc: 0.500000, f1: 0.066667] [G loss: 0.734601]\n",
      "[Epoch 0/50] [Batch 113/342] [D loss: -0.048558, acc: 0.500000, f1: 0.066667] [G loss: 0.734605]\n",
      "[Epoch 0/50] [Batch 114/342] [D loss: -0.048564, acc: 0.500000, f1: 0.066667] [G loss: 0.734610]\n",
      "[Epoch 0/50] [Batch 115/342] [D loss: -0.048569, acc: 0.500000, f1: 0.066667] [G loss: 0.734614]\n",
      "[Epoch 0/50] [Batch 116/342] [D loss: -0.048576, acc: 0.500000, f1: 0.066667] [G loss: 0.734621]\n",
      "[Epoch 0/50] [Batch 117/342] [D loss: -0.048584, acc: 0.500000, f1: 0.066667] [G loss: 0.734627]\n",
      "[Epoch 0/50] [Batch 118/342] [D loss: -0.048592, acc: 0.500000, f1: 0.066667] [G loss: 0.734634]\n",
      "[Epoch 0/50] [Batch 119/342] [D loss: -0.048600, acc: 0.500000, f1: 0.066667] [G loss: 0.734641]\n",
      "[Epoch 0/50] [Batch 120/342] [D loss: -0.048607, acc: 0.500000, f1: 0.066667] [G loss: 0.734649]\n",
      "[Epoch 0/50] [Batch 121/342] [D loss: -0.048614, acc: 0.500000, f1: 0.066667] [G loss: 0.734653]\n",
      "[Epoch 0/50] [Batch 122/342] [D loss: -0.048620, acc: 0.500000, f1: 0.060606] [G loss: 0.734658]\n",
      "[Epoch 0/50] [Batch 123/342] [D loss: -0.048624, acc: 0.500000, f1: 0.060606] [G loss: 0.734662]\n",
      "[Epoch 0/50] [Batch 124/342] [D loss: -0.048629, acc: 0.500000, f1: 0.066667] [G loss: 0.734667]\n",
      "[Epoch 0/50] [Batch 125/342] [D loss: -0.048634, acc: 0.500000, f1: 0.066667] [G loss: 0.734671]\n",
      "[Epoch 0/50] [Batch 126/342] [D loss: -0.048638, acc: 0.500000, f1: 0.066667] [G loss: 0.734674]\n",
      "[Epoch 0/50] [Batch 127/342] [D loss: -0.048644, acc: 0.500000, f1: 0.066667] [G loss: 0.734679]\n",
      "[Epoch 0/50] [Batch 128/342] [D loss: -0.048649, acc: 0.500000, f1: 0.060606] [G loss: 0.734683]\n",
      "[Epoch 0/50] [Batch 129/342] [D loss: -0.048653, acc: 0.500000, f1: 0.066667] [G loss: 0.734688]\n",
      "[Epoch 0/50] [Batch 130/342] [D loss: -0.048657, acc: 0.500000, f1: 0.066667] [G loss: 0.734690]\n",
      "[Epoch 0/50] [Batch 131/342] [D loss: -0.048663, acc: 0.500000, f1: 0.066667] [G loss: 0.734695]\n",
      "[Epoch 0/50] [Batch 132/342] [D loss: -0.048663, acc: 0.500000, f1: 0.066667] [G loss: 0.734699]\n",
      "[Epoch 0/50] [Batch 133/342] [D loss: -0.048672, acc: 0.500000, f1: 0.066667] [G loss: 0.734705]\n",
      "[Epoch 0/50] [Batch 134/342] [D loss: -0.048676, acc: 0.500000, f1: 0.066667] [G loss: 0.734707]\n",
      "[Epoch 0/50] [Batch 135/342] [D loss: -0.048683, acc: 0.500000, f1: 0.066667] [G loss: 0.734713]\n",
      "[Epoch 0/50] [Batch 136/342] [D loss: -0.048687, acc: 0.500000, f1: 0.066667] [G loss: 0.734716]\n",
      "[Epoch 0/50] [Batch 137/342] [D loss: -0.048693, acc: 0.500000, f1: 0.060606] [G loss: 0.734721]\n",
      "[Epoch 0/50] [Batch 138/342] [D loss: -0.048698, acc: 0.500000, f1: 0.066667] [G loss: 0.734725]\n",
      "[Epoch 0/50] [Batch 139/342] [D loss: -0.048704, acc: 0.500000, f1: 0.060606] [G loss: 0.734731]\n",
      "[Epoch 0/50] [Batch 140/342] [D loss: -0.048710, acc: 0.500000, f1: 0.066667] [G loss: 0.734736]\n",
      "[Epoch 0/50] [Batch 141/342] [D loss: -0.048713, acc: 0.500000, f1: 0.066667] [G loss: 0.734740]\n",
      "[Epoch 0/50] [Batch 142/342] [D loss: -0.048720, acc: 0.500000, f1: 0.060606] [G loss: 0.734745]\n",
      "[Epoch 0/50] [Batch 143/342] [D loss: -0.048725, acc: 0.500000, f1: 0.066667] [G loss: 0.734750]\n",
      "[Epoch 0/50] [Batch 144/342] [D loss: -0.048732, acc: 0.500000, f1: 0.066667] [G loss: 0.734756]\n",
      "[Epoch 0/50] [Batch 145/342] [D loss: -0.048738, acc: 0.500000, f1: 0.066667] [G loss: 0.734761]\n",
      "[Epoch 0/50] [Batch 146/342] [D loss: -0.048744, acc: 0.500000, f1: 0.066667] [G loss: 0.734766]\n",
      "[Epoch 0/50] [Batch 147/342] [D loss: -0.048751, acc: 0.500000, f1: 0.066667] [G loss: 0.734772]\n",
      "[Epoch 0/50] [Batch 148/342] [D loss: -0.048758, acc: 0.500000, f1: 0.066667] [G loss: 0.734778]\n",
      "[Epoch 0/50] [Batch 149/342] [D loss: -0.048766, acc: 0.500000, f1: 0.066667] [G loss: 0.734785]\n",
      "[Epoch 0/50] [Batch 150/342] [D loss: -0.048774, acc: 0.500000, f1: 0.066667] [G loss: 0.734792]\n",
      "[Epoch 0/50] [Batch 151/342] [D loss: -0.048782, acc: 0.500000, f1: 0.066667] [G loss: 0.734798]\n",
      "[Epoch 0/50] [Batch 152/342] [D loss: -0.048792, acc: 0.500000, f1: 0.060606] [G loss: 0.734808]\n",
      "[Epoch 0/50] [Batch 153/342] [D loss: -0.048802, acc: 0.500000, f1: 0.066667] [G loss: 0.734815]\n",
      "[Epoch 0/50] [Batch 154/342] [D loss: -0.048810, acc: 0.500000, f1: 0.060606] [G loss: 0.734825]\n",
      "[Epoch 0/50] [Batch 155/342] [D loss: -0.048822, acc: 0.500000, f1: 0.066667] [G loss: 0.734833]\n",
      "[Epoch 0/50] [Batch 156/342] [D loss: -0.048832, acc: 0.500000, f1: 0.060606] [G loss: 0.734841]\n",
      "[Epoch 0/50] [Batch 157/342] [D loss: -0.048839, acc: 0.500000, f1: 0.060606] [G loss: 0.734847]\n",
      "[Epoch 0/50] [Batch 158/342] [D loss: -0.048846, acc: 0.500000, f1: 0.066667] [G loss: 0.734853]\n",
      "[Epoch 0/50] [Batch 159/342] [D loss: -0.048828, acc: 0.500000, f1: 0.066667] [G loss: 0.734860]\n",
      "[Epoch 0/50] [Batch 160/342] [D loss: -0.048859, acc: 0.500000, f1: 0.066667] [G loss: 0.734866]\n",
      "[Epoch 0/50] [Batch 161/342] [D loss: -0.048866, acc: 0.500000, f1: 0.060606] [G loss: 0.734871]\n",
      "[Epoch 0/50] [Batch 162/342] [D loss: -0.048875, acc: 0.500000, f1: 0.060606] [G loss: 0.734879]\n",
      "[Epoch 0/50] [Batch 163/342] [D loss: -0.048882, acc: 0.500000, f1: 0.066667] [G loss: 0.734885]\n",
      "[Epoch 0/50] [Batch 164/342] [D loss: -0.048890, acc: 0.500000, f1: 0.066667] [G loss: 0.734891]\n",
      "[Epoch 0/50] [Batch 165/342] [D loss: -0.048897, acc: 0.500000, f1: 0.066667] [G loss: 0.734898]\n",
      "[Epoch 0/50] [Batch 166/342] [D loss: -0.048904, acc: 0.500000, f1: 0.066667] [G loss: 0.734905]\n",
      "[Epoch 0/50] [Batch 167/342] [D loss: -0.048911, acc: 0.500000, f1: 0.066667] [G loss: 0.734911]\n",
      "[Epoch 0/50] [Batch 168/342] [D loss: -0.048920, acc: 0.500000, f1: 0.066667] [G loss: 0.734919]\n",
      "[Epoch 0/50] [Batch 169/342] [D loss: -0.048927, acc: 0.500000, f1: 0.060606] [G loss: 0.734924]\n",
      "[Epoch 0/50] [Batch 170/342] [D loss: -0.048936, acc: 0.500000, f1: 0.066667] [G loss: 0.734932]\n",
      "[Epoch 0/50] [Batch 171/342] [D loss: -0.048942, acc: 0.500000, f1: 0.066667] [G loss: 0.734936]\n",
      "[Epoch 0/50] [Batch 172/342] [D loss: -0.048950, acc: 0.500000, f1: 0.066667] [G loss: 0.734944]\n",
      "[Epoch 0/50] [Batch 173/342] [D loss: -0.048959, acc: 0.500000, f1: 0.066667] [G loss: 0.734951]\n",
      "[Epoch 0/50] [Batch 174/342] [D loss: -0.048960, acc: 0.500000, f1: 0.066667] [G loss: 0.734959]\n",
      "[Epoch 0/50] [Batch 175/342] [D loss: -0.048976, acc: 0.500000, f1: 0.066667] [G loss: 0.734966]\n",
      "[Epoch 0/50] [Batch 176/342] [D loss: -0.048985, acc: 0.500000, f1: 0.060606] [G loss: 0.734974]\n",
      "[Epoch 0/50] [Batch 177/342] [D loss: -0.048994, acc: 0.500000, f1: 0.066667] [G loss: 0.734981]\n",
      "[Epoch 0/50] [Batch 178/342] [D loss: -0.049004, acc: 0.500000, f1: 0.066667] [G loss: 0.734990]\n",
      "[Epoch 0/50] [Batch 179/342] [D loss: -0.049015, acc: 0.500000, f1: 0.066667] [G loss: 0.734999]\n",
      "[Epoch 0/50] [Batch 180/342] [D loss: -0.049023, acc: 0.500000, f1: 0.060606] [G loss: 0.735008]\n",
      "[Epoch 0/50] [Batch 181/342] [D loss: -0.049036, acc: 0.500000, f1: 0.066667] [G loss: 0.735017]\n",
      "[Epoch 0/50] [Batch 182/342] [D loss: -0.049050, acc: 0.500000, f1: 0.066667] [G loss: 0.735029]\n",
      "[Epoch 0/50] [Batch 183/342] [D loss: -0.049059, acc: 0.500000, f1: 0.066667] [G loss: 0.735038]\n",
      "[Epoch 0/50] [Batch 184/342] [D loss: -0.049068, acc: 0.500000, f1: 0.060606] [G loss: 0.735046]\n",
      "[Epoch 0/50] [Batch 185/342] [D loss: -0.049078, acc: 0.500000, f1: 0.066667] [G loss: 0.735054]\n",
      "[Epoch 0/50] [Batch 186/342] [D loss: -0.049088, acc: 0.500000, f1: 0.060606] [G loss: 0.735062]\n",
      "[Epoch 0/50] [Batch 187/342] [D loss: -0.049096, acc: 0.500000, f1: 0.066667] [G loss: 0.735069]\n",
      "[Epoch 0/50] [Batch 188/342] [D loss: -0.049106, acc: 0.500000, f1: 0.060606] [G loss: 0.735079]\n",
      "[Epoch 0/50] [Batch 189/342] [D loss: -0.049115, acc: 0.500000, f1: 0.066667] [G loss: 0.735086]\n",
      "[Epoch 0/50] [Batch 190/342] [D loss: -0.049125, acc: 0.500000, f1: 0.066667] [G loss: 0.735095]\n",
      "[Epoch 0/50] [Batch 191/342] [D loss: -0.049133, acc: 0.500000, f1: 0.066667] [G loss: 0.735102]\n",
      "[Epoch 0/50] [Batch 192/342] [D loss: -0.049144, acc: 0.500000, f1: 0.060606] [G loss: 0.735112]\n",
      "[Epoch 0/50] [Batch 193/342] [D loss: -0.049152, acc: 0.500000, f1: 0.066667] [G loss: 0.735119]\n",
      "[Epoch 0/50] [Batch 194/342] [D loss: -0.049162, acc: 0.500000, f1: 0.066667] [G loss: 0.735126]\n",
      "[Epoch 0/50] [Batch 195/342] [D loss: -0.049171, acc: 0.500000, f1: 0.066667] [G loss: 0.735134]\n",
      "[Epoch 0/50] [Batch 196/342] [D loss: -0.049179, acc: 0.500000, f1: 0.066667] [G loss: 0.735141]\n",
      "[Epoch 0/50] [Batch 197/342] [D loss: -0.049188, acc: 0.500000, f1: 0.060606] [G loss: 0.735150]\n",
      "[Epoch 0/50] [Batch 198/342] [D loss: -0.049198, acc: 0.500000, f1: 0.060606] [G loss: 0.735158]\n",
      "[Epoch 0/50] [Batch 199/342] [D loss: -0.049206, acc: 0.500000, f1: 0.066667] [G loss: 0.735164]\n",
      "[Epoch 0/50] [Batch 200/342] [D loss: -0.049215, acc: 0.500000, f1: 0.066667] [G loss: 0.735172]\n",
      "[Epoch 0/50] [Batch 201/342] [D loss: -0.049224, acc: 0.500000, f1: 0.066667] [G loss: 0.735180]\n",
      "[Epoch 0/50] [Batch 202/342] [D loss: -0.049233, acc: 0.500000, f1: 0.066667] [G loss: 0.735188]\n",
      "[Epoch 0/50] [Batch 203/342] [D loss: -0.049242, acc: 0.500000, f1: 0.066667] [G loss: 0.735196]\n",
      "[Epoch 0/50] [Batch 204/342] [D loss: -0.049253, acc: 0.500000, f1: 0.066667] [G loss: 0.735205]\n",
      "[Epoch 0/50] [Batch 205/342] [D loss: -0.049262, acc: 0.500000, f1: 0.066667] [G loss: 0.735213]\n",
      "[Epoch 0/50] [Batch 206/342] [D loss: -0.049273, acc: 0.500000, f1: 0.066667] [G loss: 0.735223]\n",
      "[Epoch 0/50] [Batch 207/342] [D loss: -0.049284, acc: 0.500000, f1: 0.060606] [G loss: 0.735231]\n",
      "[Epoch 0/50] [Batch 208/342] [D loss: -0.049294, acc: 0.500000, f1: 0.060606] [G loss: 0.735241]\n",
      "[Epoch 0/50] [Batch 209/342] [D loss: -0.049304, acc: 0.500000, f1: 0.066667] [G loss: 0.735249]\n",
      "[Epoch 0/50] [Batch 210/342] [D loss: -0.049312, acc: 0.500000, f1: 0.066667] [G loss: 0.735258]\n",
      "[Epoch 0/50] [Batch 211/342] [D loss: -0.049321, acc: 0.500000, f1: 0.066667] [G loss: 0.735265]\n",
      "[Epoch 0/50] [Batch 212/342] [D loss: -0.049331, acc: 0.500000, f1: 0.066667] [G loss: 0.735273]\n",
      "[Epoch 0/50] [Batch 213/342] [D loss: -0.049339, acc: 0.500000, f1: 0.066667] [G loss: 0.735279]\n",
      "[Epoch 0/50] [Batch 214/342] [D loss: -0.049347, acc: 0.500000, f1: 0.066667] [G loss: 0.735287]\n",
      "[Epoch 0/50] [Batch 215/342] [D loss: -0.049354, acc: 0.500000, f1: 0.066667] [G loss: 0.735293]\n",
      "[Epoch 0/50] [Batch 216/342] [D loss: -0.049364, acc: 0.500000, f1: 0.066667] [G loss: 0.735301]\n",
      "[Epoch 0/50] [Batch 217/342] [D loss: -0.049372, acc: 0.500000, f1: 0.066667] [G loss: 0.735308]\n",
      "[Epoch 0/50] [Batch 218/342] [D loss: -0.049379, acc: 0.500000, f1: 0.066667] [G loss: 0.735316]\n",
      "[Epoch 0/50] [Batch 219/342] [D loss: -0.049388, acc: 0.500000, f1: 0.066667] [G loss: 0.735323]\n",
      "[Epoch 0/50] [Batch 220/342] [D loss: -0.049398, acc: 0.500000, f1: 0.060606] [G loss: 0.735331]\n",
      "[Epoch 0/50] [Batch 221/342] [D loss: -0.049407, acc: 0.500000, f1: 0.066667] [G loss: 0.735339]\n",
      "[Epoch 0/50] [Batch 222/342] [D loss: -0.049418, acc: 0.500000, f1: 0.074074] [G loss: 0.735348]\n",
      "[Epoch 0/50] [Batch 223/342] [D loss: -0.049427, acc: 0.500000, f1: 0.060606] [G loss: 0.735356]\n",
      "[Epoch 0/50] [Batch 224/342] [D loss: -0.049438, acc: 0.500000, f1: 0.066667] [G loss: 0.735366]\n",
      "[Epoch 0/50] [Batch 225/342] [D loss: -0.049449, acc: 0.500000, f1: 0.060606] [G loss: 0.735375]\n",
      "[Epoch 0/50] [Batch 226/342] [D loss: -0.049460, acc: 0.500000, f1: 0.066667] [G loss: 0.735385]\n",
      "[Epoch 0/50] [Batch 227/342] [D loss: -0.049472, acc: 0.500000, f1: 0.066667] [G loss: 0.735395]\n",
      "[Epoch 0/50] [Batch 228/342] [D loss: -0.049482, acc: 0.500000, f1: 0.060606] [G loss: 0.735404]\n",
      "[Epoch 0/50] [Batch 229/342] [D loss: -0.049493, acc: 0.500000, f1: 0.066667] [G loss: 0.735414]\n",
      "[Epoch 0/50] [Batch 230/342] [D loss: -0.049505, acc: 0.500000, f1: 0.066667] [G loss: 0.735423]\n",
      "[Epoch 0/50] [Batch 231/342] [D loss: -0.049515, acc: 0.500000, f1: 0.060606] [G loss: 0.735433]\n",
      "[Epoch 0/50] [Batch 232/342] [D loss: -0.049525, acc: 0.500000, f1: 0.066667] [G loss: 0.735442]\n",
      "[Epoch 0/50] [Batch 233/342] [D loss: -0.049537, acc: 0.500000, f1: 0.066667] [G loss: 0.735452]\n",
      "[Epoch 0/50] [Batch 234/342] [D loss: -0.049548, acc: 0.500000, f1: 0.066667] [G loss: 0.735460]\n",
      "[Epoch 0/50] [Batch 235/342] [D loss: -0.049559, acc: 0.500000, f1: 0.060606] [G loss: 0.735470]\n",
      "[Epoch 0/50] [Batch 236/342] [D loss: -0.049570, acc: 0.500000, f1: 0.066667] [G loss: 0.735479]\n",
      "[Epoch 0/50] [Batch 237/342] [D loss: -0.049581, acc: 0.500000, f1: 0.060606] [G loss: 0.735490]\n",
      "[Epoch 0/50] [Batch 238/342] [D loss: -0.049594, acc: 0.500000, f1: 0.060606] [G loss: 0.735501]\n",
      "[Epoch 0/50] [Batch 239/342] [D loss: -0.049608, acc: 0.500000, f1: 0.066667] [G loss: 0.735513]\n",
      "[Epoch 0/50] [Batch 240/342] [D loss: -0.049623, acc: 0.500000, f1: 0.066667] [G loss: 0.735525]\n",
      "[Epoch 0/50] [Batch 241/342] [D loss: -0.049637, acc: 0.500000, f1: 0.060606] [G loss: 0.735539]\n",
      "[Epoch 0/50] [Batch 242/342] [D loss: -0.049654, acc: 0.500000, f1: 0.066667] [G loss: 0.735553]\n",
      "[Epoch 0/50] [Batch 243/342] [D loss: -0.049674, acc: 0.500000, f1: 0.066667] [G loss: 0.735569]\n",
      "[Epoch 0/50] [Batch 244/342] [D loss: -0.049693, acc: 0.500000, f1: 0.060606] [G loss: 0.735585]\n",
      "[Epoch 0/50] [Batch 245/342] [D loss: -0.049709, acc: 0.500000, f1: 0.060606] [G loss: 0.735600]\n",
      "[Epoch 0/50] [Batch 246/342] [D loss: -0.049728, acc: 0.500000, f1: 0.066667] [G loss: 0.735616]\n",
      "[Epoch 0/50] [Batch 247/342] [D loss: -0.049745, acc: 0.500000, f1: 0.060606] [G loss: 0.735631]\n",
      "[Epoch 0/50] [Batch 248/342] [D loss: -0.049760, acc: 0.500000, f1: 0.066667] [G loss: 0.735644]\n",
      "[Epoch 0/50] [Batch 249/342] [D loss: -0.049775, acc: 0.500000, f1: 0.066667] [G loss: 0.735656]\n",
      "[Epoch 0/50] [Batch 250/342] [D loss: -0.049790, acc: 0.500000, f1: 0.066667] [G loss: 0.735669]\n",
      "[Epoch 0/50] [Batch 251/342] [D loss: -0.049803, acc: 0.500000, f1: 0.066667] [G loss: 0.735681]\n",
      "[Epoch 0/50] [Batch 252/342] [D loss: -0.049814, acc: 0.500000, f1: 0.066667] [G loss: 0.735691]\n",
      "[Epoch 0/50] [Batch 253/342] [D loss: -0.049827, acc: 0.500000, f1: 0.066667] [G loss: 0.735701]\n",
      "[Epoch 0/50] [Batch 254/342] [D loss: -0.049838, acc: 0.500000, f1: 0.060606] [G loss: 0.735712]\n",
      "[Epoch 0/50] [Batch 255/342] [D loss: -0.049850, acc: 0.500000, f1: 0.066667] [G loss: 0.735721]\n",
      "[Epoch 0/50] [Batch 256/342] [D loss: -0.049861, acc: 0.500000, f1: 0.060606] [G loss: 0.735731]\n",
      "[Epoch 0/50] [Batch 257/342] [D loss: -0.049873, acc: 0.500000, f1: 0.060606] [G loss: 0.735741]\n",
      "[Epoch 0/50] [Batch 258/342] [D loss: -0.049885, acc: 0.500000, f1: 0.066667] [G loss: 0.735751]\n",
      "[Epoch 0/50] [Batch 259/342] [D loss: -0.049896, acc: 0.500000, f1: 0.066667] [G loss: 0.735762]\n",
      "[Epoch 0/50] [Batch 260/342] [D loss: -0.049908, acc: 0.500000, f1: 0.066667] [G loss: 0.735771]\n",
      "[Epoch 0/50] [Batch 261/342] [D loss: -0.049919, acc: 0.500000, f1: 0.066667] [G loss: 0.735781]\n",
      "[Epoch 0/50] [Batch 262/342] [D loss: -0.049931, acc: 0.500000, f1: 0.066667] [G loss: 0.735792]\n",
      "[Epoch 0/50] [Batch 263/342] [D loss: -0.049944, acc: 0.500000, f1: 0.066667] [G loss: 0.735802]\n",
      "[Epoch 0/50] [Batch 264/342] [D loss: -0.049956, acc: 0.500000, f1: 0.060606] [G loss: 0.735813]\n",
      "[Epoch 0/50] [Batch 265/342] [D loss: -0.049967, acc: 0.500000, f1: 0.074074] [G loss: 0.735823]\n",
      "[Epoch 0/50] [Batch 266/342] [D loss: -0.049979, acc: 0.500000, f1: 0.066667] [G loss: 0.735833]\n",
      "[Epoch 0/50] [Batch 267/342] [D loss: -0.049990, acc: 0.500000, f1: 0.066667] [G loss: 0.735842]\n",
      "[Epoch 0/50] [Batch 268/342] [D loss: -0.050000, acc: 0.500000, f1: 0.066667] [G loss: 0.735852]\n",
      "[Epoch 0/50] [Batch 269/342] [D loss: -0.050012, acc: 0.500000, f1: 0.066667] [G loss: 0.735860]\n",
      "[Epoch 0/50] [Batch 270/342] [D loss: -0.050019, acc: 0.500000, f1: 0.066667] [G loss: 0.735868]\n",
      "[Epoch 0/50] [Batch 271/342] [D loss: -0.050028, acc: 0.500000, f1: 0.066667] [G loss: 0.735875]\n",
      "[Epoch 0/50] [Batch 272/342] [D loss: -0.050038, acc: 0.500000, f1: 0.066667] [G loss: 0.735884]\n",
      "[Epoch 0/50] [Batch 273/342] [D loss: -0.050047, acc: 0.500000, f1: 0.060606] [G loss: 0.735890]\n",
      "[Epoch 0/50] [Batch 274/342] [D loss: -0.050056, acc: 0.500000, f1: 0.066667] [G loss: 0.735898]\n",
      "[Epoch 0/50] [Batch 275/342] [D loss: -0.050064, acc: 0.500000, f1: 0.060606] [G loss: 0.735906]\n",
      "[Epoch 0/50] [Batch 276/342] [D loss: -0.050072, acc: 0.500000, f1: 0.060606] [G loss: 0.735914]\n",
      "[Epoch 0/50] [Batch 277/342] [D loss: -0.050081, acc: 0.500000, f1: 0.060606] [G loss: 0.735921]\n",
      "[Epoch 0/50] [Batch 278/342] [D loss: -0.050068, acc: 0.500000, f1: 0.066667] [G loss: 0.735928]\n",
      "[Epoch 0/50] [Batch 279/342] [D loss: -0.050099, acc: 0.500000, f1: 0.060606] [G loss: 0.735937]\n",
      "[Epoch 0/50] [Batch 280/342] [D loss: -0.050109, acc: 0.500000, f1: 0.066667] [G loss: 0.735945]\n",
      "[Epoch 0/50] [Batch 281/342] [D loss: -0.050118, acc: 0.500000, f1: 0.066667] [G loss: 0.735953]\n",
      "[Epoch 0/50] [Batch 282/342] [D loss: -0.050127, acc: 0.500000, f1: 0.066667] [G loss: 0.735960]\n",
      "[Epoch 0/50] [Batch 283/342] [D loss: -0.050134, acc: 0.500000, f1: 0.060606] [G loss: 0.735967]\n",
      "[Epoch 0/50] [Batch 284/342] [D loss: -0.050143, acc: 0.500000, f1: 0.060606] [G loss: 0.735974]\n",
      "[Epoch 0/50] [Batch 285/342] [D loss: -0.050150, acc: 0.500000, f1: 0.060606] [G loss: 0.735980]\n",
      "[Epoch 0/50] [Batch 286/342] [D loss: -0.050159, acc: 0.500000, f1: 0.066667] [G loss: 0.735988]\n",
      "[Epoch 0/50] [Batch 287/342] [D loss: -0.050166, acc: 0.500000, f1: 0.066667] [G loss: 0.735994]\n",
      "[Epoch 0/50] [Batch 288/342] [D loss: -0.050171, acc: 0.500000, f1: 0.066667] [G loss: 0.735998]\n",
      "[Epoch 0/50] [Batch 289/342] [D loss: -0.050177, acc: 0.500000, f1: 0.066667] [G loss: 0.736004]\n",
      "[Epoch 0/50] [Batch 290/342] [D loss: -0.050184, acc: 0.500000, f1: 0.060606] [G loss: 0.736009]\n",
      "[Epoch 0/50] [Batch 291/342] [D loss: -0.050191, acc: 0.500000, f1: 0.066667] [G loss: 0.736014]\n",
      "[Epoch 0/50] [Batch 292/342] [D loss: -0.050194, acc: 0.500000, f1: 0.066667] [G loss: 0.736018]\n",
      "[Epoch 0/50] [Batch 293/342] [D loss: -0.050200, acc: 0.500000, f1: 0.060606] [G loss: 0.736023]\n",
      "[Epoch 0/50] [Batch 294/342] [D loss: -0.050206, acc: 0.500000, f1: 0.060606] [G loss: 0.736028]\n",
      "[Epoch 0/50] [Batch 295/342] [D loss: -0.050211, acc: 0.500000, f1: 0.060606] [G loss: 0.736033]\n",
      "[Epoch 0/50] [Batch 296/342] [D loss: -0.050216, acc: 0.500000, f1: 0.060606] [G loss: 0.736037]\n",
      "[Epoch 0/50] [Batch 297/342] [D loss: -0.050221, acc: 0.500000, f1: 0.060606] [G loss: 0.736041]\n",
      "[Epoch 0/50] [Batch 298/342] [D loss: -0.050226, acc: 0.500000, f1: 0.060606] [G loss: 0.736046]\n",
      "[Epoch 0/50] [Batch 299/342] [D loss: -0.050233, acc: 0.500000, f1: 0.060606] [G loss: 0.736051]\n",
      "[Epoch 0/50] [Batch 300/342] [D loss: -0.050238, acc: 0.500000, f1: 0.060606] [G loss: 0.736056]\n",
      "[Epoch 0/50] [Batch 301/342] [D loss: -0.050244, acc: 0.500000, f1: 0.066667] [G loss: 0.736060]\n",
      "[Epoch 0/50] [Batch 302/342] [D loss: -0.050249, acc: 0.500000, f1: 0.066667] [G loss: 0.736065]\n",
      "[Epoch 0/50] [Batch 303/342] [D loss: -0.050256, acc: 0.500000, f1: 0.066667] [G loss: 0.736070]\n",
      "[Epoch 0/50] [Batch 304/342] [D loss: -0.050260, acc: 0.500000, f1: 0.060606] [G loss: 0.736075]\n",
      "[Epoch 0/50] [Batch 305/342] [D loss: -0.050267, acc: 0.500000, f1: 0.066667] [G loss: 0.736080]\n",
      "[Epoch 0/50] [Batch 306/342] [D loss: -0.050272, acc: 0.500000, f1: 0.060606] [G loss: 0.736085]\n",
      "[Epoch 0/50] [Batch 307/342] [D loss: -0.050277, acc: 0.500000, f1: 0.060606] [G loss: 0.736090]\n",
      "[Epoch 0/50] [Batch 308/342] [D loss: -0.050284, acc: 0.500000, f1: 0.066667] [G loss: 0.736094]\n",
      "[Epoch 0/50] [Batch 309/342] [D loss: -0.050290, acc: 0.500000, f1: 0.066667] [G loss: 0.736100]\n",
      "[Epoch 0/50] [Batch 310/342] [D loss: -0.050295, acc: 0.500000, f1: 0.066667] [G loss: 0.736105]\n",
      "[Epoch 0/50] [Batch 311/342] [D loss: -0.050300, acc: 0.500000, f1: 0.066667] [G loss: 0.736110]\n",
      "[Epoch 0/50] [Batch 312/342] [D loss: -0.050307, acc: 0.500000, f1: 0.066667] [G loss: 0.736115]\n",
      "[Epoch 0/50] [Batch 313/342] [D loss: -0.050312, acc: 0.500000, f1: 0.066667] [G loss: 0.736120]\n",
      "[Epoch 0/50] [Batch 314/342] [D loss: -0.050318, acc: 0.500000, f1: 0.060606] [G loss: 0.736125]\n",
      "[Epoch 0/50] [Batch 315/342] [D loss: -0.050325, acc: 0.500000, f1: 0.066667] [G loss: 0.736130]\n",
      "[Epoch 0/50] [Batch 316/342] [D loss: -0.050331, acc: 0.500000, f1: 0.066667] [G loss: 0.736135]\n",
      "[Epoch 0/50] [Batch 317/342] [D loss: -0.050337, acc: 0.500000, f1: 0.060606] [G loss: 0.736140]\n",
      "[Epoch 0/50] [Batch 318/342] [D loss: -0.050342, acc: 0.500000, f1: 0.066667] [G loss: 0.736146]\n",
      "[Epoch 0/50] [Batch 319/342] [D loss: -0.050347, acc: 0.500000, f1: 0.060606] [G loss: 0.736151]\n",
      "[Epoch 0/50] [Batch 320/342] [D loss: -0.050353, acc: 0.500000, f1: 0.074074] [G loss: 0.736155]\n",
      "[Epoch 0/50] [Batch 321/342] [D loss: -0.050360, acc: 0.500000, f1: 0.066667] [G loss: 0.736161]\n",
      "[Epoch 0/50] [Batch 322/342] [D loss: -0.050365, acc: 0.500000, f1: 0.066667] [G loss: 0.736165]\n",
      "[Epoch 0/50] [Batch 323/342] [D loss: -0.050370, acc: 0.500000, f1: 0.060606] [G loss: 0.736170]\n",
      "[Epoch 0/50] [Batch 324/342] [D loss: -0.050375, acc: 0.500000, f1: 0.060606] [G loss: 0.736173]\n",
      "[Epoch 0/50] [Batch 325/342] [D loss: -0.050379, acc: 0.500000, f1: 0.066667] [G loss: 0.736178]\n",
      "[Epoch 0/50] [Batch 326/342] [D loss: -0.050385, acc: 0.500000, f1: 0.066667] [G loss: 0.736181]\n",
      "[Epoch 0/50] [Batch 327/342] [D loss: -0.050389, acc: 0.500000, f1: 0.066667] [G loss: 0.736186]\n",
      "[Epoch 0/50] [Batch 328/342] [D loss: -0.050394, acc: 0.500000, f1: 0.066667] [G loss: 0.736190]\n",
      "[Epoch 0/50] [Batch 329/342] [D loss: -0.050398, acc: 0.500000, f1: 0.060606] [G loss: 0.736193]\n",
      "[Epoch 0/50] [Batch 330/342] [D loss: -0.050404, acc: 0.500000, f1: 0.066667] [G loss: 0.736199]\n",
      "[Epoch 0/50] [Batch 331/342] [D loss: -0.050409, acc: 0.500000, f1: 0.066667] [G loss: 0.736204]\n",
      "[Epoch 0/50] [Batch 332/342] [D loss: -0.050415, acc: 0.500000, f1: 0.066667] [G loss: 0.736208]\n",
      "[Epoch 0/50] [Batch 333/342] [D loss: -0.050422, acc: 0.500000, f1: 0.060606] [G loss: 0.736214]\n",
      "[Epoch 0/50] [Batch 334/342] [D loss: -0.050429, acc: 0.500000, f1: 0.060606] [G loss: 0.736220]\n",
      "[Epoch 0/50] [Batch 335/342] [D loss: -0.050437, acc: 0.500000, f1: 0.066667] [G loss: 0.736227]\n",
      "[Epoch 0/50] [Batch 336/342] [D loss: -0.050446, acc: 0.500000, f1: 0.060606] [G loss: 0.736234]\n",
      "[Epoch 0/50] [Batch 337/342] [D loss: -0.050453, acc: 0.500000, f1: 0.060606] [G loss: 0.736241]\n",
      "[Epoch 0/50] [Batch 338/342] [D loss: -0.050461, acc: 0.500000, f1: 0.074074] [G loss: 0.736248]\n",
      "[Epoch 0/50] [Batch 339/342] [D loss: -0.050470, acc: 0.500000, f1: 0.060606] [G loss: 0.736255]\n",
      "[Epoch 0/50] [Batch 340/342] [D loss: -0.050477, acc: 0.500000, f1: 0.066667] [G loss: 0.736261]\n",
      "[Epoch 0/50] [Batch 341/342] [D loss: -0.050482, acc: 0.500000, f1: 0.074074] [G loss: 0.736266]\n",
      "[Epoch 1/50] [Batch 0/342] [D loss: -0.050487, acc: 0.500000, f1: 0.060606] [G loss: 0.736270]\n",
      "[Epoch 1/50] [Batch 1/342] [D loss: -0.050494, acc: 0.500000, f1: 0.066667] [G loss: 0.736276]\n",
      "[Epoch 1/50] [Batch 2/342] [D loss: -0.050498, acc: 0.500000, f1: 0.074074] [G loss: 0.736280]\n",
      "[Epoch 1/50] [Batch 3/342] [D loss: -0.050504, acc: 0.500000, f1: 0.060606] [G loss: 0.736285]\n",
      "[Epoch 1/50] [Batch 4/342] [D loss: -0.050508, acc: 0.500000, f1: 0.066667] [G loss: 0.736288]\n",
      "[Epoch 1/50] [Batch 5/342] [D loss: -0.050501, acc: 0.500000, f1: 0.066667] [G loss: 0.736293]\n",
      "[Epoch 1/50] [Batch 6/342] [D loss: -0.050519, acc: 0.500000, f1: 0.066667] [G loss: 0.736297]\n",
      "[Epoch 1/50] [Batch 7/342] [D loss: -0.050524, acc: 0.500000, f1: 0.066667] [G loss: 0.736302]\n",
      "[Epoch 1/50] [Batch 8/342] [D loss: -0.050528, acc: 0.500000, f1: 0.060606] [G loss: 0.736307]\n",
      "[Epoch 1/50] [Batch 9/342] [D loss: -0.050534, acc: 0.500000, f1: 0.066667] [G loss: 0.736311]\n",
      "[Epoch 1/50] [Batch 10/342] [D loss: -0.050539, acc: 0.500000, f1: 0.066667] [G loss: 0.736315]\n",
      "[Epoch 1/50] [Batch 11/342] [D loss: -0.050543, acc: 0.500000, f1: 0.066667] [G loss: 0.736320]\n",
      "[Epoch 1/50] [Batch 12/342] [D loss: -0.050549, acc: 0.500000, f1: 0.066667] [G loss: 0.736323]\n",
      "[Epoch 1/50] [Batch 13/342] [D loss: -0.050553, acc: 0.500000, f1: 0.060606] [G loss: 0.736327]\n",
      "[Epoch 1/50] [Batch 14/342] [D loss: -0.050559, acc: 0.500000, f1: 0.066667] [G loss: 0.736332]\n",
      "[Epoch 1/50] [Batch 15/342] [D loss: -0.050562, acc: 0.500000, f1: 0.066667] [G loss: 0.736336]\n",
      "[Epoch 1/50] [Batch 16/342] [D loss: -0.050569, acc: 0.500000, f1: 0.060606] [G loss: 0.736341]\n",
      "[Epoch 1/50] [Batch 17/342] [D loss: -0.050573, acc: 0.500000, f1: 0.066667] [G loss: 0.736345]\n",
      "[Epoch 1/50] [Batch 18/342] [D loss: -0.050578, acc: 0.500000, f1: 0.060606] [G loss: 0.736350]\n",
      "[Epoch 1/50] [Batch 19/342] [D loss: -0.050583, acc: 0.500000, f1: 0.066667] [G loss: 0.736354]\n",
      "[Epoch 1/50] [Batch 20/342] [D loss: -0.050586, acc: 0.500000, f1: 0.066667] [G loss: 0.736356]\n",
      "[Epoch 1/50] [Batch 21/342] [D loss: -0.050591, acc: 0.500000, f1: 0.066667] [G loss: 0.736359]\n",
      "[Epoch 1/50] [Batch 22/342] [D loss: -0.050595, acc: 0.500000, f1: 0.066667] [G loss: 0.736363]\n",
      "[Epoch 1/50] [Batch 23/342] [D loss: -0.050599, acc: 0.500000, f1: 0.066667] [G loss: 0.736366]\n",
      "[Epoch 1/50] [Batch 24/342] [D loss: -0.050603, acc: 0.500000, f1: 0.066667] [G loss: 0.736370]\n",
      "[Epoch 1/50] [Batch 25/342] [D loss: -0.050606, acc: 0.500000, f1: 0.066667] [G loss: 0.736373]\n",
      "[Epoch 1/50] [Batch 26/342] [D loss: -0.050611, acc: 0.500000, f1: 0.066667] [G loss: 0.736377]\n",
      "[Epoch 1/50] [Batch 27/342] [D loss: -0.050615, acc: 0.500000, f1: 0.066667] [G loss: 0.736380]\n",
      "[Epoch 1/50] [Batch 28/342] [D loss: -0.050620, acc: 0.500000, f1: 0.060606] [G loss: 0.736384]\n",
      "[Epoch 1/50] [Batch 29/342] [D loss: -0.050624, acc: 0.500000, f1: 0.066667] [G loss: 0.736388]\n",
      "[Epoch 1/50] [Batch 30/342] [D loss: -0.050630, acc: 0.500000, f1: 0.066667] [G loss: 0.736393]\n",
      "[Epoch 1/50] [Batch 31/342] [D loss: -0.050633, acc: 0.500000, f1: 0.066667] [G loss: 0.736397]\n",
      "[Epoch 1/50] [Batch 32/342] [D loss: -0.050638, acc: 0.500000, f1: 0.066667] [G loss: 0.736400]\n",
      "[Epoch 1/50] [Batch 33/342] [D loss: -0.050642, acc: 0.500000, f1: 0.066667] [G loss: 0.736403]\n",
      "[Epoch 1/50] [Batch 34/342] [D loss: -0.050645, acc: 0.500000, f1: 0.074074] [G loss: 0.736406]\n",
      "[Epoch 1/50] [Batch 35/342] [D loss: -0.050648, acc: 0.500000, f1: 0.060606] [G loss: 0.736408]\n",
      "[Epoch 1/50] [Batch 36/342] [D loss: -0.050651, acc: 0.500000, f1: 0.066667] [G loss: 0.736411]\n",
      "[Epoch 1/50] [Batch 37/342] [D loss: -0.050655, acc: 0.500000, f1: 0.060606] [G loss: 0.736415]\n",
      "[Epoch 1/50] [Batch 38/342] [D loss: -0.050658, acc: 0.500000, f1: 0.066667] [G loss: 0.736417]\n",
      "[Epoch 1/50] [Batch 39/342] [D loss: -0.050662, acc: 0.500000, f1: 0.066667] [G loss: 0.736420]\n",
      "[Epoch 1/50] [Batch 40/342] [D loss: -0.050663, acc: 0.500000, f1: 0.060606] [G loss: 0.736421]\n",
      "[Epoch 1/50] [Batch 41/342] [D loss: -0.050665, acc: 0.500000, f1: 0.060606] [G loss: 0.736424]\n",
      "[Epoch 1/50] [Batch 42/342] [D loss: -0.050668, acc: 0.500000, f1: 0.066667] [G loss: 0.736425]\n",
      "[Epoch 1/50] [Batch 43/342] [D loss: -0.050671, acc: 0.500000, f1: 0.066667] [G loss: 0.736428]\n",
      "[Epoch 1/50] [Batch 44/342] [D loss: -0.050673, acc: 0.500000, f1: 0.060606] [G loss: 0.736430]\n",
      "[Epoch 1/50] [Batch 45/342] [D loss: -0.050675, acc: 0.500000, f1: 0.066667] [G loss: 0.736432]\n",
      "[Epoch 1/50] [Batch 46/342] [D loss: -0.050677, acc: 0.500000, f1: 0.066667] [G loss: 0.736433]\n",
      "[Epoch 1/50] [Batch 47/342] [D loss: -0.050679, acc: 0.500000, f1: 0.066667] [G loss: 0.736435]\n",
      "[Epoch 1/50] [Batch 48/342] [D loss: -0.050681, acc: 0.500000, f1: 0.066667] [G loss: 0.736437]\n",
      "[Epoch 1/50] [Batch 49/342] [D loss: -0.050683, acc: 0.500000, f1: 0.060606] [G loss: 0.736438]\n",
      "[Epoch 1/50] [Batch 50/342] [D loss: -0.050686, acc: 0.500000, f1: 0.074074] [G loss: 0.736441]\n",
      "[Epoch 1/50] [Batch 51/342] [D loss: -0.050687, acc: 0.500000, f1: 0.066667] [G loss: 0.736443]\n",
      "[Epoch 1/50] [Batch 52/342] [D loss: -0.050690, acc: 0.500000, f1: 0.066667] [G loss: 0.736444]\n",
      "[Epoch 1/50] [Batch 53/342] [D loss: -0.050692, acc: 0.500000, f1: 0.060606] [G loss: 0.736446]\n",
      "[Epoch 1/50] [Batch 54/342] [D loss: -0.050694, acc: 0.500000, f1: 0.060606] [G loss: 0.736447]\n",
      "[Epoch 1/50] [Batch 55/342] [D loss: -0.050696, acc: 0.500000, f1: 0.066667] [G loss: 0.736450]\n",
      "[Epoch 1/50] [Batch 56/342] [D loss: -0.050699, acc: 0.500000, f1: 0.060606] [G loss: 0.736452]\n",
      "[Epoch 1/50] [Batch 57/342] [D loss: -0.050700, acc: 0.500000, f1: 0.066667] [G loss: 0.736454]\n",
      "[Epoch 1/50] [Batch 58/342] [D loss: -0.050702, acc: 0.500000, f1: 0.066667] [G loss: 0.736455]\n",
      "[Epoch 1/50] [Batch 59/342] [D loss: -0.050704, acc: 0.500000, f1: 0.066667] [G loss: 0.736457]\n",
      "[Epoch 1/50] [Batch 60/342] [D loss: -0.050706, acc: 0.500000, f1: 0.066667] [G loss: 0.736458]\n",
      "[Epoch 1/50] [Batch 61/342] [D loss: -0.050709, acc: 0.500000, f1: 0.066667] [G loss: 0.736460]\n",
      "[Epoch 1/50] [Batch 62/342] [D loss: -0.050710, acc: 0.500000, f1: 0.066667] [G loss: 0.736462]\n",
      "[Epoch 1/50] [Batch 63/342] [D loss: -0.050713, acc: 0.500000, f1: 0.066667] [G loss: 0.736464]\n",
      "[Epoch 1/50] [Batch 64/342] [D loss: -0.050710, acc: 0.500000, f1: 0.066667] [G loss: 0.736466]\n",
      "[Epoch 1/50] [Batch 65/342] [D loss: -0.050717, acc: 0.500000, f1: 0.066667] [G loss: 0.736468]\n",
      "[Epoch 1/50] [Batch 66/342] [D loss: -0.050719, acc: 0.500000, f1: 0.060606] [G loss: 0.736468]\n",
      "[Epoch 1/50] [Batch 67/342] [D loss: -0.050720, acc: 0.500000, f1: 0.066667] [G loss: 0.736470]\n",
      "[Epoch 1/50] [Batch 68/342] [D loss: -0.050722, acc: 0.500000, f1: 0.066667] [G loss: 0.736472]\n",
      "[Epoch 1/50] [Batch 69/342] [D loss: -0.050723, acc: 0.500000, f1: 0.066667] [G loss: 0.736474]\n",
      "[Epoch 1/50] [Batch 70/342] [D loss: -0.050726, acc: 0.500000, f1: 0.060606] [G loss: 0.736475]\n",
      "[Epoch 1/50] [Batch 71/342] [D loss: -0.050727, acc: 0.500000, f1: 0.066667] [G loss: 0.736477]\n",
      "[Epoch 1/50] [Batch 72/342] [D loss: -0.050730, acc: 0.500000, f1: 0.066667] [G loss: 0.736479]\n",
      "[Epoch 1/50] [Batch 73/342] [D loss: -0.050732, acc: 0.500000, f1: 0.066667] [G loss: 0.736481]\n",
      "[Epoch 1/50] [Batch 74/342] [D loss: -0.050733, acc: 0.500000, f1: 0.066667] [G loss: 0.736483]\n",
      "[Epoch 1/50] [Batch 75/342] [D loss: -0.050736, acc: 0.500000, f1: 0.066667] [G loss: 0.736485]\n",
      "[Epoch 1/50] [Batch 76/342] [D loss: -0.050739, acc: 0.500000, f1: 0.066667] [G loss: 0.736486]\n",
      "[Epoch 1/50] [Batch 77/342] [D loss: -0.050742, acc: 0.500000, f1: 0.060606] [G loss: 0.736489]\n",
      "[Epoch 1/50] [Batch 78/342] [D loss: -0.050743, acc: 0.500000, f1: 0.066667] [G loss: 0.736490]\n",
      "[Epoch 1/50] [Batch 79/342] [D loss: -0.050746, acc: 0.500000, f1: 0.066667] [G loss: 0.736492]\n",
      "[Epoch 1/50] [Batch 80/342] [D loss: -0.050749, acc: 0.500000, f1: 0.060606] [G loss: 0.736495]\n",
      "[Epoch 1/50] [Batch 81/342] [D loss: -0.050751, acc: 0.500000, f1: 0.066667] [G loss: 0.736496]\n",
      "[Epoch 1/50] [Batch 82/342] [D loss: -0.050745, acc: 0.500000, f1: 0.066667] [G loss: 0.736498]\n",
      "[Epoch 1/50] [Batch 83/342] [D loss: -0.050755, acc: 0.500000, f1: 0.066667] [G loss: 0.736501]\n",
      "[Epoch 1/50] [Batch 84/342] [D loss: -0.050758, acc: 0.500000, f1: 0.066667] [G loss: 0.736502]\n",
      "[Epoch 1/50] [Batch 85/342] [D loss: -0.050759, acc: 0.500000, f1: 0.066667] [G loss: 0.736504]\n",
      "[Epoch 1/50] [Batch 86/342] [D loss: -0.050762, acc: 0.500000, f1: 0.066667] [G loss: 0.736506]\n",
      "[Epoch 1/50] [Batch 87/342] [D loss: -0.050762, acc: 0.500000, f1: 0.060606] [G loss: 0.736507]\n",
      "[Epoch 1/50] [Batch 88/342] [D loss: -0.050763, acc: 0.500000, f1: 0.066667] [G loss: 0.736507]\n",
      "[Epoch 1/50] [Batch 89/342] [D loss: -0.050764, acc: 0.500000, f1: 0.066667] [G loss: 0.736508]\n",
      "[Epoch 1/50] [Batch 90/342] [D loss: -0.050765, acc: 0.500000, f1: 0.060606] [G loss: 0.736509]\n",
      "[Epoch 1/50] [Batch 91/342] [D loss: -0.050766, acc: 0.500000, f1: 0.066667] [G loss: 0.736510]\n",
      "[Epoch 1/50] [Batch 92/342] [D loss: -0.050766, acc: 0.500000, f1: 0.060606] [G loss: 0.736509]\n",
      "[Epoch 1/50] [Batch 93/342] [D loss: -0.050768, acc: 0.500000, f1: 0.060606] [G loss: 0.736511]\n",
      "[Epoch 1/50] [Batch 94/342] [D loss: -0.050769, acc: 0.500000, f1: 0.060606] [G loss: 0.736512]\n",
      "[Epoch 1/50] [Batch 95/342] [D loss: -0.050768, acc: 0.500000, f1: 0.066667] [G loss: 0.736512]\n",
      "[Epoch 1/50] [Batch 96/342] [D loss: -0.050771, acc: 0.500000, f1: 0.066667] [G loss: 0.736513]\n",
      "[Epoch 1/50] [Batch 97/342] [D loss: -0.050769, acc: 0.500000, f1: 0.060606] [G loss: 0.736513]\n",
      "[Epoch 1/50] [Batch 98/342] [D loss: -0.050770, acc: 0.500000, f1: 0.066667] [G loss: 0.736514]\n",
      "[Epoch 1/50] [Batch 99/342] [D loss: -0.050772, acc: 0.500000, f1: 0.066667] [G loss: 0.736514]\n",
      "[Epoch 1/50] [Batch 100/342] [D loss: -0.050771, acc: 0.500000, f1: 0.066667] [G loss: 0.736514]\n",
      "[Epoch 1/50] [Batch 101/342] [D loss: -0.050772, acc: 0.500000, f1: 0.066667] [G loss: 0.736515]\n",
      "[Epoch 1/50] [Batch 102/342] [D loss: -0.050774, acc: 0.500000, f1: 0.066667] [G loss: 0.736516]\n",
      "[Epoch 1/50] [Batch 103/342] [D loss: -0.050774, acc: 0.500000, f1: 0.066667] [G loss: 0.736517]\n",
      "[Epoch 1/50] [Batch 104/342] [D loss: -0.050773, acc: 0.500000, f1: 0.066667] [G loss: 0.736517]\n",
      "[Epoch 1/50] [Batch 105/342] [D loss: -0.050775, acc: 0.500000, f1: 0.066667] [G loss: 0.736517]\n",
      "[Epoch 1/50] [Batch 106/342] [D loss: -0.050775, acc: 0.500000, f1: 0.066667] [G loss: 0.736517]\n",
      "[Epoch 1/50] [Batch 107/342] [D loss: -0.050776, acc: 0.500000, f1: 0.060606] [G loss: 0.736519]\n",
      "[Epoch 1/50] [Batch 108/342] [D loss: -0.050750, acc: 0.500000, f1: 0.066667] [G loss: 0.736519]\n",
      "[Epoch 1/50] [Batch 109/342] [D loss: -0.050778, acc: 0.500000, f1: 0.066667] [G loss: 0.736519]\n",
      "[Epoch 1/50] [Batch 110/342] [D loss: -0.050777, acc: 0.500000, f1: 0.066667] [G loss: 0.736519]\n",
      "[Epoch 1/50] [Batch 111/342] [D loss: -0.050777, acc: 0.500000, f1: 0.066667] [G loss: 0.736520]\n",
      "[Epoch 1/50] [Batch 112/342] [D loss: -0.050778, acc: 0.500000, f1: 0.066667] [G loss: 0.736520]\n",
      "[Epoch 1/50] [Batch 113/342] [D loss: -0.050779, acc: 0.500000, f1: 0.066667] [G loss: 0.736521]\n",
      "[Epoch 1/50] [Batch 114/342] [D loss: -0.050779, acc: 0.500000, f1: 0.066667] [G loss: 0.736521]\n",
      "[Epoch 1/50] [Batch 115/342] [D loss: -0.050780, acc: 0.500000, f1: 0.066667] [G loss: 0.736521]\n",
      "[Epoch 1/50] [Batch 116/342] [D loss: -0.050781, acc: 0.500000, f1: 0.074074] [G loss: 0.736522]\n",
      "[Epoch 1/50] [Batch 117/342] [D loss: -0.050781, acc: 0.500000, f1: 0.060606] [G loss: 0.736522]\n",
      "[Epoch 1/50] [Batch 118/342] [D loss: -0.050782, acc: 0.500000, f1: 0.060606] [G loss: 0.736523]\n",
      "[Epoch 1/50] [Batch 119/342] [D loss: -0.050781, acc: 0.500000, f1: 0.066667] [G loss: 0.736523]\n",
      "[Epoch 1/50] [Batch 120/342] [D loss: -0.050781, acc: 0.500000, f1: 0.066667] [G loss: 0.736523]\n",
      "[Epoch 1/50] [Batch 121/342] [D loss: -0.050783, acc: 0.500000, f1: 0.060606] [G loss: 0.736524]\n",
      "[Epoch 1/50] [Batch 122/342] [D loss: -0.050783, acc: 0.500000, f1: 0.060606] [G loss: 0.736524]\n",
      "[Epoch 1/50] [Batch 123/342] [D loss: -0.050781, acc: 0.500000, f1: 0.066667] [G loss: 0.736524]\n",
      "[Epoch 1/50] [Batch 124/342] [D loss: -0.050783, acc: 0.500000, f1: 0.066667] [G loss: 0.736524]\n",
      "[Epoch 1/50] [Batch 125/342] [D loss: -0.050784, acc: 0.500000, f1: 0.066667] [G loss: 0.736525]\n",
      "[Epoch 1/50] [Batch 126/342] [D loss: -0.050784, acc: 0.500000, f1: 0.060606] [G loss: 0.736524]\n",
      "[Epoch 1/50] [Batch 127/342] [D loss: -0.050785, acc: 0.500000, f1: 0.066667] [G loss: 0.736525]\n",
      "[Epoch 1/50] [Batch 128/342] [D loss: -0.050784, acc: 0.500000, f1: 0.066667] [G loss: 0.736525]\n",
      "[Epoch 1/50] [Batch 129/342] [D loss: -0.050783, acc: 0.500000, f1: 0.066667] [G loss: 0.736526]\n",
      "[Epoch 1/50] [Batch 130/342] [D loss: -0.050785, acc: 0.500000, f1: 0.066667] [G loss: 0.736526]\n",
      "[Epoch 1/50] [Batch 131/342] [D loss: -0.050784, acc: 0.500000, f1: 0.066667] [G loss: 0.736526]\n",
      "[Epoch 1/50] [Batch 132/342] [D loss: -0.050785, acc: 0.500000, f1: 0.060606] [G loss: 0.736526]\n",
      "[Epoch 1/50] [Batch 133/342] [D loss: -0.050786, acc: 0.500000, f1: 0.060606] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 134/342] [D loss: -0.050786, acc: 0.500000, f1: 0.060606] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 135/342] [D loss: -0.050786, acc: 0.500000, f1: 0.066667] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 136/342] [D loss: -0.050787, acc: 0.500000, f1: 0.066667] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 137/342] [D loss: -0.050786, acc: 0.500000, f1: 0.066667] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 138/342] [D loss: -0.050786, acc: 0.500000, f1: 0.066667] [G loss: 0.736527]\n",
      "[Epoch 1/50] [Batch 139/342] [D loss: -0.050787, acc: 0.500000, f1: 0.066667] [G loss: 0.736528]\n",
      "[Epoch 1/50] [Batch 140/342] [D loss: -0.050787, acc: 0.500000, f1: 0.060606] [G loss: 0.736528]\n",
      "[Epoch 1/50] [Batch 141/342] [D loss: -0.050788, acc: 0.500000, f1: 0.066667] [G loss: 0.736528]\n",
      "[Epoch 1/50] [Batch 142/342] [D loss: -0.050787, acc: 0.500000, f1: 0.060606] [G loss: 0.736528]\n",
      "[Epoch 1/50] [Batch 143/342] [D loss: -0.050788, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 144/342] [D loss: -0.050788, acc: 0.500000, f1: 0.060606] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 145/342] [D loss: -0.050788, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 146/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 147/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 148/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 149/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 150/342] [D loss: -0.050788, acc: 0.500000, f1: 0.066667] [G loss: 0.736529]\n",
      "[Epoch 1/50] [Batch 151/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 152/342] [D loss: -0.050790, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 153/342] [D loss: -0.050789, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 154/342] [D loss: -0.050790, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 155/342] [D loss: -0.050791, acc: 0.500000, f1: 0.066667] [G loss: 0.736530]\n",
      "[Epoch 1/50] [Batch 156/342] [D loss: -0.050790, acc: 0.500000, f1: 0.060606] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 157/342] [D loss: -0.050790, acc: 0.500000, f1: 0.066667] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 158/342] [D loss: -0.050791, acc: 0.500000, f1: 0.060606] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 159/342] [D loss: -0.050791, acc: 0.500000, f1: 0.060606] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 160/342] [D loss: -0.050791, acc: 0.500000, f1: 0.060606] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 161/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 162/342] [D loss: -0.050791, acc: 0.500000, f1: 0.066667] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 163/342] [D loss: -0.050791, acc: 0.500000, f1: 0.066667] [G loss: 0.736531]\n",
      "[Epoch 1/50] [Batch 164/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736532]\n",
      "[Epoch 1/50] [Batch 165/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736532]\n",
      "[Epoch 1/50] [Batch 166/342] [D loss: -0.050790, acc: 0.500000, f1: 0.066667] [G loss: 0.736532]\n",
      "[Epoch 1/50] [Batch 167/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736532]\n",
      "[Epoch 1/50] [Batch 168/342] [D loss: -0.050791, acc: 0.500000, f1: 0.060606] [G loss: 0.736532]\n",
      "[Epoch 1/50] [Batch 169/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 170/342] [D loss: -0.050793, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 171/342] [D loss: -0.050793, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 172/342] [D loss: -0.050793, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 173/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 174/342] [D loss: -0.050793, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 175/342] [D loss: -0.050793, acc: 0.500000, f1: 0.060606] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 176/342] [D loss: -0.050793, acc: 0.500000, f1: 0.060606] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 177/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736533]\n",
      "[Epoch 1/50] [Batch 178/342] [D loss: -0.050793, acc: 0.500000, f1: 0.060606] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 179/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 180/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 181/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 182/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 183/342] [D loss: -0.050793, acc: 0.500000, f1: 0.060606] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 184/342] [D loss: -0.050795, acc: 0.500000, f1: 0.060606] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 185/342] [D loss: -0.050795, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 186/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 187/342] [D loss: -0.050795, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 188/342] [D loss: -0.050794, acc: 0.500000, f1: 0.060606] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 189/342] [D loss: -0.050795, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 190/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 191/342] [D loss: -0.050795, acc: 0.500000, f1: 0.066667] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 192/342] [D loss: -0.050796, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 193/342] [D loss: -0.050793, acc: 0.500000, f1: 0.066667] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 194/342] [D loss: -0.050795, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 195/342] [D loss: -0.050794, acc: 0.500000, f1: 0.066667] [G loss: 0.736534]\n",
      "[Epoch 1/50] [Batch 196/342] [D loss: -0.050786, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 197/342] [D loss: -0.050795, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 198/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 199/342] [D loss: -0.050796, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 200/342] [D loss: -0.050796, acc: 0.500000, f1: 0.060606] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 201/342] [D loss: -0.050796, acc: 0.500000, f1: 0.066667] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 202/342] [D loss: -0.050795, acc: 0.500000, f1: 0.060606] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 203/342] [D loss: -0.050796, acc: 0.500000, f1: 0.066667] [G loss: 0.736535]\n",
      "[Epoch 1/50] [Batch 204/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 205/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 206/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 207/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 208/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 209/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 210/342] [D loss: -0.050796, acc: 0.500000, f1: 0.066667] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 211/342] [D loss: -0.050774, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 212/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 213/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736536]\n",
      "[Epoch 1/50] [Batch 214/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 215/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 216/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 217/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 218/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 219/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 220/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 221/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 222/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 223/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 224/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 225/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 226/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 227/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 228/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 229/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 230/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 231/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 232/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 233/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 234/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 235/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 236/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 237/342] [D loss: -0.050797, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 238/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 239/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 240/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 241/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 242/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736537]\n",
      "[Epoch 1/50] [Batch 243/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 244/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 245/342] [D loss: -0.050798, acc: 0.500000, f1: 0.060606] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 246/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 247/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 248/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 249/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 250/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 251/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 252/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 253/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 254/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 255/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 256/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 257/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 258/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 259/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 260/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 261/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 262/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 263/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 264/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 265/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 266/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 267/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 268/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 269/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 270/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 271/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 272/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 273/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 274/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 275/342] [D loss: -0.050801, acc: 0.500000, f1: 0.074074] [G loss: 0.736538]\n",
      "[Epoch 1/50] [Batch 276/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 277/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 278/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 279/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 280/342] [D loss: -0.050799, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 281/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 282/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 283/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 284/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 285/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 286/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 287/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 288/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 289/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 290/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 291/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 292/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 293/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 294/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 295/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 296/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 297/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 298/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 299/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 300/342] [D loss: -0.050793, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 301/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 302/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 303/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 304/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 305/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 306/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 307/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 308/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 309/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 310/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 311/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 312/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 313/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 314/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 315/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 316/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 317/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 318/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 319/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 1/50] [Batch 320/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 321/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 322/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 323/342] [D loss: -0.050799, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 324/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 325/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 326/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 327/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 328/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 329/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 330/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 331/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 332/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 333/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 1/50] [Batch 334/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 335/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 1/50] [Batch 336/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 1/50] [Batch 337/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 1/50] [Batch 338/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 1/50] [Batch 339/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 1/50] [Batch 340/342] [D loss: -0.050801, acc: 0.500000, f1: 0.074074] [G loss: 0.736541]\n",
      "[Epoch 1/50] [Batch 341/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 0/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 1/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 2/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 3/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 4/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 5/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 6/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 7/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 8/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 9/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 10/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 11/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 12/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 13/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 14/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 15/342] [D loss: -0.050802, acc: 0.500000, f1: 0.074074] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 16/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 17/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 18/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 19/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 20/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 21/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 22/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 23/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 24/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 25/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 26/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 27/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 28/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 29/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 2/50] [Batch 30/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 31/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 2/50] [Batch 32/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 33/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 34/342] [D loss: -0.050798, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 35/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 36/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 37/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 38/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 39/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 40/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 41/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 42/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 43/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 44/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736539]\n",
      "[Epoch 2/50] [Batch 45/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 46/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 47/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 48/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 49/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 50/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 51/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 52/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 53/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 54/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 55/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 56/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 57/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 58/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 59/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 60/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 61/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 62/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 63/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 64/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 65/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 66/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 67/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 68/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 69/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 70/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 71/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 72/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 73/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 74/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 75/342] [D loss: -0.050802, acc: 0.500000, f1: 0.074074] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 76/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 77/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 78/342] [D loss: -0.050781, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 79/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 80/342] [D loss: -0.050796, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 81/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 82/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 83/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 84/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 85/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 86/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 87/342] [D loss: -0.050796, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 88/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 89/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 90/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 91/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 92/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 93/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 94/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 95/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 96/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 97/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 98/342] [D loss: -0.050783, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 99/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 100/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 101/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 102/342] [D loss: -0.050802, acc: 0.500000, f1: 0.074074] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 103/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 104/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 105/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 106/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 107/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 108/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 109/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 110/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 111/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 112/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 113/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 114/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 115/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 116/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 117/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 118/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 119/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 120/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 121/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 122/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 123/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 124/342] [D loss: -0.050797, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 125/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 126/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 127/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 128/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 129/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 130/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 131/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 132/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 133/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 134/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 135/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 136/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 137/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 138/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 139/342] [D loss: -0.050792, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 140/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 141/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 142/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 143/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 144/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 145/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 146/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 147/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 148/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 149/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 150/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 151/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 152/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 153/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 154/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 155/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 156/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 157/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 158/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 159/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 160/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 161/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 162/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 163/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 164/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 165/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 166/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 167/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 168/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 169/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 170/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 171/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 172/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 173/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 174/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 175/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 176/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 177/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 178/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 179/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 180/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 181/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 182/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 183/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 184/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 185/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 186/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 187/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 188/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 189/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 190/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 191/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 192/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 193/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 194/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 195/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 196/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 197/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 198/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 199/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 200/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 201/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 202/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 203/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 204/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 205/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 206/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 207/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 208/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 209/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 210/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 211/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 212/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 213/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 214/342] [D loss: -0.050802, acc: 0.500000, f1: 0.074074] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 215/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 216/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 217/342] [D loss: -0.050803, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 218/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 219/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 220/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 221/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 222/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 223/342] [D loss: -0.050800, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 224/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 225/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 226/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 227/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 228/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 229/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 230/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 231/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 232/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 233/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 234/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 235/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 236/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 237/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 238/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 239/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 240/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 241/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 242/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 243/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 244/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 245/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 246/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 247/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 248/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 249/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 250/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 251/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 252/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 253/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 254/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 255/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 256/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 257/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 258/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 259/342] [D loss: -0.050803, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 260/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 261/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 262/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 263/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 264/342] [D loss: -0.050792, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 265/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 266/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 267/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 268/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 269/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 270/342] [D loss: -0.050801, acc: 0.500000, f1: 0.060606] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 271/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 272/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 273/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736542]\n",
      "[Epoch 2/50] [Batch 274/342] [D loss: -0.050802, acc: 0.500000, f1: 0.060606] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 275/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 276/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 277/342] [D loss: -0.050801, acc: 0.500000, f1: 0.066667] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 278/342] [D loss: -0.050802, acc: 0.500000, f1: 0.066667] [G loss: 0.736541]\n",
      "[Epoch 2/50] [Batch 279/342] [D loss: -0.050800, acc: 0.500000, f1: 0.060606] [G loss: 0.736540]\n",
      "[Epoch 2/50] [Batch 280/342] [D loss: -0.050804, acc: 0.500000, f1: 0.066667] [G loss: 0.736543]\n",
      "[Epoch 2/50] [Batch 281/342] [D loss: -0.050809, acc: 0.500000, f1: 0.060606] [G loss: 0.736547]\n",
      "[Epoch 2/50] [Batch 282/342] [D loss: -0.050811, acc: 0.500000, f1: 0.066667] [G loss: 0.736549]\n",
      "[Epoch 2/50] [Batch 283/342] [D loss: -0.050814, acc: 0.500000, f1: 0.060606] [G loss: 0.736551]\n",
      "[Epoch 2/50] [Batch 284/342] [D loss: -0.050816, acc: 0.500000, f1: 0.066667] [G loss: 0.736553]\n",
      "[Epoch 2/50] [Batch 285/342] [D loss: -0.050817, acc: 0.500000, f1: 0.060606] [G loss: 0.736555]\n",
      "[Epoch 2/50] [Batch 286/342] [D loss: -0.050819, acc: 0.500000, f1: 0.066667] [G loss: 0.736556]\n",
      "[Epoch 2/50] [Batch 287/342] [D loss: -0.050822, acc: 0.500000, f1: 0.066667] [G loss: 0.736557]\n",
      "[Epoch 2/50] [Batch 288/342] [D loss: -0.050823, acc: 0.500000, f1: 0.066667] [G loss: 0.736558]\n",
      "[Epoch 2/50] [Batch 289/342] [D loss: -0.050823, acc: 0.500000, f1: 0.066667] [G loss: 0.736559]\n",
      "[Epoch 2/50] [Batch 290/342] [D loss: -0.050823, acc: 0.500000, f1: 0.060606] [G loss: 0.736560]\n",
      "[Epoch 2/50] [Batch 291/342] [D loss: -0.050824, acc: 0.500000, f1: 0.060606] [G loss: 0.736560]\n",
      "[Epoch 2/50] [Batch 292/342] [D loss: -0.050824, acc: 0.500000, f1: 0.066667] [G loss: 0.736561]\n",
      "[Epoch 2/50] [Batch 293/342] [D loss: -0.050824, acc: 0.500000, f1: 0.066667] [G loss: 0.736561]\n",
      "[Epoch 2/50] [Batch 294/342] [D loss: -0.050825, acc: 0.500000, f1: 0.066667] [G loss: 0.736561]\n",
      "[Epoch 2/50] [Batch 295/342] [D loss: -0.050827, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 296/342] [D loss: -0.050826, acc: 0.500000, f1: 0.060606] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 297/342] [D loss: -0.050825, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 298/342] [D loss: -0.050826, acc: 0.500000, f1: 0.060606] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 299/342] [D loss: -0.050826, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 300/342] [D loss: -0.050827, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 301/342] [D loss: -0.050826, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 302/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 303/342] [D loss: -0.050827, acc: 0.500000, f1: 0.066667] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 304/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 305/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 306/342] [D loss: -0.050828, acc: 0.500000, f1: 0.060606] [G loss: 0.736562]\n",
      "[Epoch 2/50] [Batch 307/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 308/342] [D loss: -0.050828, acc: 0.500000, f1: 0.060606] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 309/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 310/342] [D loss: -0.050828, acc: 0.500000, f1: 0.074074] [G loss: 0.736563]\n",
      "[Epoch 2/50] [Batch 311/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736564]\n",
      "[Epoch 2/50] [Batch 312/342] [D loss: -0.050831, acc: 0.500000, f1: 0.066667] [G loss: 0.736564]\n",
      "[Epoch 2/50] [Batch 313/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 314/342] [D loss: -0.050829, acc: 0.500000, f1: 0.060606] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 315/342] [D loss: -0.050829, acc: 0.500000, f1: 0.060606] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 316/342] [D loss: -0.050830, acc: 0.500000, f1: 0.060606] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 317/342] [D loss: -0.050829, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 318/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 319/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 320/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 321/342] [D loss: -0.050830, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 322/342] [D loss: -0.050830, acc: 0.500000, f1: 0.060606] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 323/342] [D loss: -0.050830, acc: 0.500000, f1: 0.060606] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 324/342] [D loss: -0.050832, acc: 0.500000, f1: 0.060606] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 325/342] [D loss: -0.050831, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 326/342] [D loss: -0.050831, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 327/342] [D loss: -0.050832, acc: 0.500000, f1: 0.060606] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 328/342] [D loss: -0.050831, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 329/342] [D loss: -0.050832, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 330/342] [D loss: -0.050832, acc: 0.500000, f1: 0.066667] [G loss: 0.736565]\n",
      "[Epoch 2/50] [Batch 331/342] [D loss: -0.050831, acc: 0.500000, f1: 0.060606] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 332/342] [D loss: -0.050831, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 333/342] [D loss: -0.050832, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 334/342] [D loss: -0.050832, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 2/50] [Batch 335/342] [D loss: -0.050832, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 336/342] [D loss: -0.050833, acc: 0.500000, f1: 0.060606] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 337/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 338/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 2/50] [Batch 339/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 2/50] [Batch 340/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 2/50] [Batch 341/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 0/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 1/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736566]\n",
      "[Epoch 3/50] [Batch 2/342] [D loss: -0.050823, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 3/342] [D loss: -0.050833, acc: 0.500000, f1: 0.060606] [G loss: 0.736568]\n",
      "[Epoch 3/50] [Batch 4/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 5/342] [D loss: -0.050833, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 6/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 7/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736567]\n",
      "[Epoch 3/50] [Batch 8/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736568]\n",
      "[Epoch 3/50] [Batch 9/342] [D loss: -0.050834, acc: 0.500000, f1: 0.060606] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 10/342] [D loss: -0.050834, acc: 0.500000, f1: 0.074074] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 11/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 12/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 13/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 14/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 15/342] [D loss: -0.050834, acc: 0.500000, f1: 0.060606] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 16/342] [D loss: -0.050834, acc: 0.500000, f1: 0.060606] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 17/342] [D loss: -0.050833, acc: 0.500000, f1: 0.060606] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 18/342] [D loss: -0.050833, acc: 0.500000, f1: 0.060606] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 19/342] [D loss: -0.050834, acc: 0.500000, f1: 0.060606] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 20/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 21/342] [D loss: -0.050834, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 22/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 23/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 24/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 25/342] [D loss: -0.050835, acc: 0.500000, f1: 0.060606] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 26/342] [D loss: -0.050835, acc: 0.500000, f1: 0.074074] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 27/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 28/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 29/342] [D loss: -0.050836, acc: 0.500000, f1: 0.060606] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 30/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736569]\n",
      "[Epoch 3/50] [Batch 31/342] [D loss: -0.050837, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 32/342] [D loss: -0.050835, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 33/342] [D loss: -0.050836, acc: 0.500000, f1: 0.060606] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 34/342] [D loss: -0.050837, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 35/342] [D loss: -0.050836, acc: 0.500000, f1: 0.060606] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 36/342] [D loss: -0.050828, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 37/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 38/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 39/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 40/342] [D loss: -0.050837, acc: 0.500000, f1: 0.074074] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 41/342] [D loss: -0.050837, acc: 0.500000, f1: 0.060606] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 42/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 43/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 44/342] [D loss: -0.050838, acc: 0.500000, f1: 0.060606] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 45/342] [D loss: -0.050836, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 46/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 47/342] [D loss: -0.050837, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 48/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 49/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736570]\n",
      "[Epoch 3/50] [Batch 50/342] [D loss: -0.050837, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 51/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736571]\n",
      "[Epoch 3/50] [Batch 52/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 53/342] [D loss: -0.050838, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 54/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 55/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 56/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 57/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 58/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 59/342] [D loss: -0.050838, acc: 0.500000, f1: 0.074074] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 60/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 61/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 62/342] [D loss: -0.050838, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 63/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 64/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 65/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 66/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 67/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 68/342] [D loss: -0.050838, acc: 0.500000, f1: 0.074074] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 69/342] [D loss: -0.050838, acc: 0.500000, f1: 0.066667] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 70/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 71/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 72/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 73/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736572]\n",
      "[Epoch 3/50] [Batch 74/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 75/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 76/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 77/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 78/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 79/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 80/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 81/342] [D loss: -0.050840, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 82/342] [D loss: -0.050839, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 83/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 84/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 85/342] [D loss: -0.050839, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 86/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 87/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 88/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 89/342] [D loss: -0.050840, acc: 0.500000, f1: 0.066667] [G loss: 0.736573]\n",
      "[Epoch 3/50] [Batch 90/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 91/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 92/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 93/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 94/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736574]\n",
      "[Epoch 3/50] [Batch 95/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 96/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 97/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 98/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 99/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 100/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 101/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 102/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 103/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 104/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 105/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 106/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 107/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 108/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 109/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 110/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 111/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 112/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 113/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 114/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 115/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 116/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 117/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 118/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 119/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 120/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 121/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 122/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 123/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 124/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 125/342] [D loss: -0.050843, acc: 0.500000, f1: 0.074074] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 126/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 127/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 128/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 129/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 130/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 131/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 132/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 133/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 134/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 135/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 136/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 137/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 138/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 139/342] [D loss: -0.050843, acc: 0.500000, f1: 0.074074] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 140/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 141/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 142/342] [D loss: -0.050843, acc: 0.500000, f1: 0.074074] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 143/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 144/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 145/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 146/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 147/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 148/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 149/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 150/342] [D loss: -0.050844, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 151/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 152/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 153/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 154/342] [D loss: -0.050843, acc: 0.500000, f1: 0.074074] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 155/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 156/342] [D loss: -0.050843, acc: 0.500000, f1: 0.074074] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 157/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 158/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 159/342] [D loss: -0.050844, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 160/342] [D loss: -0.050844, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 161/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 162/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 163/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 164/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 165/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 166/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 167/342] [D loss: -0.050842, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 168/342] [D loss: -0.050841, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 169/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 170/342] [D loss: -0.050823, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 171/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 172/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 173/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 174/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 175/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 176/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 177/342] [D loss: -0.050825, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 178/342] [D loss: -0.050842, acc: 0.500000, f1: 0.074074] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 179/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 180/342] [D loss: -0.050841, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 181/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 182/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 183/342] [D loss: -0.050837, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 184/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 185/342] [D loss: -0.050843, acc: 0.500000, f1: 0.060606] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 186/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 187/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 188/342] [D loss: -0.050842, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 189/342] [D loss: -0.050843, acc: 0.500000, f1: 0.066667] [G loss: 0.736575]\n",
      "[Epoch 3/50] [Batch 190/342] [D loss: -0.050844, acc: 0.500000, f1: 0.060606] [G loss: 0.736576]\n",
      "[Epoch 3/50] [Batch 191/342] [D loss: -0.050845, acc: 0.500000, f1: 0.066667] [G loss: 0.736577]\n",
      "[Epoch 3/50] [Batch 192/342] [D loss: -0.050849, acc: 0.500000, f1: 0.066667] [G loss: 0.736581]\n",
      "[Epoch 3/50] [Batch 193/342] [D loss: -0.050852, acc: 0.500000, f1: 0.060606] [G loss: 0.736583]\n",
      "[Epoch 3/50] [Batch 194/342] [D loss: -0.050853, acc: 0.500000, f1: 0.066667] [G loss: 0.736585]\n",
      "[Epoch 3/50] [Batch 195/342] [D loss: -0.050855, acc: 0.500000, f1: 0.066667] [G loss: 0.736587]\n",
      "[Epoch 3/50] [Batch 196/342] [D loss: -0.050856, acc: 0.500000, f1: 0.060606] [G loss: 0.736587]\n",
      "[Epoch 3/50] [Batch 197/342] [D loss: -0.050857, acc: 0.500000, f1: 0.060606] [G loss: 0.736588]\n",
      "[Epoch 3/50] [Batch 198/342] [D loss: -0.050856, acc: 0.500000, f1: 0.066667] [G loss: 0.736589]\n",
      "[Epoch 3/50] [Batch 199/342] [D loss: -0.050858, acc: 0.500000, f1: 0.066667] [G loss: 0.736589]\n",
      "[Epoch 3/50] [Batch 200/342] [D loss: -0.050859, acc: 0.500000, f1: 0.066667] [G loss: 0.736589]\n",
      "[Epoch 3/50] [Batch 201/342] [D loss: -0.050859, acc: 0.500000, f1: 0.060606] [G loss: 0.736590]\n",
      "[Epoch 3/50] [Batch 202/342] [D loss: -0.050861, acc: 0.500000, f1: 0.066667] [G loss: 0.736592]\n",
      "[Epoch 3/50] [Batch 203/342] [D loss: -0.050867, acc: 0.500000, f1: 0.066667] [G loss: 0.736596]\n",
      "[Epoch 3/50] [Batch 204/342] [D loss: -0.050870, acc: 0.500000, f1: 0.074074] [G loss: 0.736598]\n",
      "[Epoch 3/50] [Batch 205/342] [D loss: -0.050873, acc: 0.500000, f1: 0.066667] [G loss: 0.736600]\n",
      "[Epoch 3/50] [Batch 206/342] [D loss: -0.050874, acc: 0.500000, f1: 0.066667] [G loss: 0.736602]\n",
      "[Epoch 3/50] [Batch 207/342] [D loss: -0.050876, acc: 0.500000, f1: 0.060606] [G loss: 0.736603]\n",
      "[Epoch 3/50] [Batch 208/342] [D loss: -0.050877, acc: 0.500000, f1: 0.066667] [G loss: 0.736604]\n",
      "[Epoch 3/50] [Batch 209/342] [D loss: -0.050873, acc: 0.500000, f1: 0.066667] [G loss: 0.736605]\n",
      "[Epoch 3/50] [Batch 210/342] [D loss: -0.050880, acc: 0.500000, f1: 0.066667] [G loss: 0.736607]\n",
      "[Epoch 3/50] [Batch 211/342] [D loss: -0.050879, acc: 0.500000, f1: 0.066667] [G loss: 0.736607]\n",
      "[Epoch 3/50] [Batch 212/342] [D loss: -0.050882, acc: 0.500000, f1: 0.066667] [G loss: 0.736608]\n",
      "[Epoch 3/50] [Batch 213/342] [D loss: -0.050882, acc: 0.500000, f1: 0.066667] [G loss: 0.736609]\n",
      "[Epoch 3/50] [Batch 214/342] [D loss: -0.050882, acc: 0.500000, f1: 0.066667] [G loss: 0.736609]\n",
      "[Epoch 3/50] [Batch 215/342] [D loss: -0.050883, acc: 0.500000, f1: 0.060606] [G loss: 0.736610]\n",
      "[Epoch 3/50] [Batch 216/342] [D loss: -0.050885, acc: 0.500000, f1: 0.060606] [G loss: 0.736611]\n",
      "[Epoch 3/50] [Batch 217/342] [D loss: -0.050885, acc: 0.500000, f1: 0.066667] [G loss: 0.736612]\n",
      "[Epoch 3/50] [Batch 218/342] [D loss: -0.050885, acc: 0.500000, f1: 0.066667] [G loss: 0.736613]\n",
      "[Epoch 3/50] [Batch 219/342] [D loss: -0.050886, acc: 0.500000, f1: 0.060606] [G loss: 0.736613]\n",
      "[Epoch 3/50] [Batch 220/342] [D loss: -0.050887, acc: 0.500000, f1: 0.066667] [G loss: 0.736614]\n",
      "[Epoch 3/50] [Batch 221/342] [D loss: -0.050891, acc: 0.500000, f1: 0.066667] [G loss: 0.736618]\n",
      "[Epoch 3/50] [Batch 222/342] [D loss: -0.050894, acc: 0.500000, f1: 0.066667] [G loss: 0.736621]\n",
      "[Epoch 3/50] [Batch 223/342] [D loss: -0.050897, acc: 0.500000, f1: 0.066667] [G loss: 0.736623]\n",
      "[Epoch 3/50] [Batch 224/342] [D loss: -0.050900, acc: 0.500000, f1: 0.066667] [G loss: 0.736625]\n",
      "[Epoch 3/50] [Batch 225/342] [D loss: -0.050902, acc: 0.500000, f1: 0.066667] [G loss: 0.736626]\n",
      "[Epoch 3/50] [Batch 226/342] [D loss: -0.050902, acc: 0.500000, f1: 0.066667] [G loss: 0.736627]\n",
      "[Epoch 3/50] [Batch 227/342] [D loss: -0.050905, acc: 0.500000, f1: 0.060606] [G loss: 0.736629]\n",
      "[Epoch 3/50] [Batch 228/342] [D loss: -0.050907, acc: 0.500000, f1: 0.066667] [G loss: 0.736630]\n",
      "[Epoch 3/50] [Batch 229/342] [D loss: -0.050907, acc: 0.500000, f1: 0.074074] [G loss: 0.736630]\n",
      "[Epoch 3/50] [Batch 230/342] [D loss: -0.050908, acc: 0.500000, f1: 0.066667] [G loss: 0.736631]\n",
      "[Epoch 3/50] [Batch 231/342] [D loss: -0.050908, acc: 0.500000, f1: 0.066667] [G loss: 0.736632]\n",
      "[Epoch 3/50] [Batch 232/342] [D loss: -0.050908, acc: 0.500000, f1: 0.066667] [G loss: 0.736633]\n",
      "[Epoch 3/50] [Batch 233/342] [D loss: -0.050911, acc: 0.500000, f1: 0.066667] [G loss: 0.736634]\n",
      "[Epoch 3/50] [Batch 234/342] [D loss: -0.050911, acc: 0.500000, f1: 0.066667] [G loss: 0.736634]\n",
      "[Epoch 3/50] [Batch 235/342] [D loss: -0.050911, acc: 0.500000, f1: 0.060606] [G loss: 0.736635]\n",
      "[Epoch 3/50] [Batch 236/342] [D loss: -0.050912, acc: 0.500000, f1: 0.060606] [G loss: 0.736635]\n",
      "[Epoch 3/50] [Batch 237/342] [D loss: -0.050914, acc: 0.500000, f1: 0.060606] [G loss: 0.736636]\n",
      "[Epoch 3/50] [Batch 238/342] [D loss: -0.050914, acc: 0.500000, f1: 0.074074] [G loss: 0.736636]\n",
      "[Epoch 3/50] [Batch 239/342] [D loss: -0.050914, acc: 0.500000, f1: 0.066667] [G loss: 0.736636]\n",
      "[Epoch 3/50] [Batch 240/342] [D loss: -0.050915, acc: 0.500000, f1: 0.060606] [G loss: 0.736637]\n",
      "[Epoch 3/50] [Batch 241/342] [D loss: -0.050916, acc: 0.500000, f1: 0.066667] [G loss: 0.736637]\n",
      "[Epoch 3/50] [Batch 242/342] [D loss: -0.050916, acc: 0.500000, f1: 0.060606] [G loss: 0.736638]\n",
      "[Epoch 3/50] [Batch 243/342] [D loss: -0.050919, acc: 0.500000, f1: 0.066667] [G loss: 0.736639]\n",
      "[Epoch 3/50] [Batch 244/342] [D loss: -0.050918, acc: 0.500000, f1: 0.066667] [G loss: 0.736639]\n",
      "[Epoch 3/50] [Batch 245/342] [D loss: -0.050917, acc: 0.500000, f1: 0.066667] [G loss: 0.736639]\n",
      "[Epoch 3/50] [Batch 246/342] [D loss: -0.050919, acc: 0.500000, f1: 0.060606] [G loss: 0.736640]\n",
      "[Epoch 3/50] [Batch 247/342] [D loss: -0.050920, acc: 0.500000, f1: 0.066667] [G loss: 0.736641]\n",
      "[Epoch 3/50] [Batch 248/342] [D loss: -0.050918, acc: 0.500000, f1: 0.060606] [G loss: 0.736641]\n",
      "[Epoch 3/50] [Batch 249/342] [D loss: -0.050921, acc: 0.500000, f1: 0.066667] [G loss: 0.736643]\n",
      "[Epoch 3/50] [Batch 250/342] [D loss: -0.050920, acc: 0.500000, f1: 0.066667] [G loss: 0.736643]\n",
      "[Epoch 3/50] [Batch 251/342] [D loss: -0.050922, acc: 0.500000, f1: 0.060606] [G loss: 0.736644]\n",
      "[Epoch 3/50] [Batch 252/342] [D loss: -0.050921, acc: 0.500000, f1: 0.060606] [G loss: 0.736643]\n",
      "[Epoch 3/50] [Batch 253/342] [D loss: -0.050921, acc: 0.500000, f1: 0.066667] [G loss: 0.736644]\n",
      "[Epoch 3/50] [Batch 254/342] [D loss: -0.050922, acc: 0.500000, f1: 0.060606] [G loss: 0.736644]\n",
      "[Epoch 3/50] [Batch 255/342] [D loss: -0.050921, acc: 0.500000, f1: 0.066667] [G loss: 0.736644]\n",
      "[Epoch 3/50] [Batch 256/342] [D loss: -0.050922, acc: 0.500000, f1: 0.066667] [G loss: 0.736644]\n",
      "[Epoch 3/50] [Batch 257/342] [D loss: -0.050924, acc: 0.500000, f1: 0.074074] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 258/342] [D loss: -0.050923, acc: 0.500000, f1: 0.066667] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 259/342] [D loss: -0.050924, acc: 0.500000, f1: 0.060606] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 260/342] [D loss: -0.050924, acc: 0.500000, f1: 0.066667] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 261/342] [D loss: -0.050925, acc: 0.500000, f1: 0.060606] [G loss: 0.736646]\n",
      "[Epoch 3/50] [Batch 262/342] [D loss: -0.050925, acc: 0.500000, f1: 0.060606] [G loss: 0.736646]\n",
      "[Epoch 3/50] [Batch 263/342] [D loss: -0.050925, acc: 0.500000, f1: 0.060606] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 264/342] [D loss: -0.050924, acc: 0.500000, f1: 0.066667] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 265/342] [D loss: -0.050925, acc: 0.500000, f1: 0.066667] [G loss: 0.736645]\n",
      "[Epoch 3/50] [Batch 266/342] [D loss: -0.050926, acc: 0.500000, f1: 0.060606] [G loss: 0.736646]\n",
      "[Epoch 3/50] [Batch 267/342] [D loss: -0.050926, acc: 0.500000, f1: 0.066667] [G loss: 0.736646]\n",
      "[Epoch 3/50] [Batch 268/342] [D loss: -0.050926, acc: 0.500000, f1: 0.066667] [G loss: 0.736647]\n",
      "[Epoch 3/50] [Batch 269/342] [D loss: -0.050926, acc: 0.500000, f1: 0.066667] [G loss: 0.736647]\n",
      "[Epoch 3/50] [Batch 270/342] [D loss: -0.050928, acc: 0.500000, f1: 0.066667] [G loss: 0.736647]\n",
      "[Epoch 3/50] [Batch 271/342] [D loss: -0.050927, acc: 0.500000, f1: 0.060606] [G loss: 0.736648]\n",
      "[Epoch 3/50] [Batch 272/342] [D loss: -0.050927, acc: 0.500000, f1: 0.060606] [G loss: 0.736648]\n",
      "[Epoch 3/50] [Batch 273/342] [D loss: -0.050928, acc: 0.500000, f1: 0.066667] [G loss: 0.736648]\n",
      "[Epoch 3/50] [Batch 274/342] [D loss: -0.050927, acc: 0.500000, f1: 0.066667] [G loss: 0.736648]\n",
      "[Epoch 3/50] [Batch 275/342] [D loss: -0.050928, acc: 0.500000, f1: 0.066667] [G loss: 0.736649]\n",
      "[Epoch 3/50] [Batch 276/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736649]\n",
      "[Epoch 3/50] [Batch 277/342] [D loss: -0.050928, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 278/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 279/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 280/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 281/342] [D loss: -0.050931, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 282/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 283/342] [D loss: -0.050930, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 284/342] [D loss: -0.050929, acc: 0.500000, f1: 0.060606] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 285/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 286/342] [D loss: -0.050929, acc: 0.500000, f1: 0.060606] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 287/342] [D loss: -0.050929, acc: 0.500000, f1: 0.066667] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 288/342] [D loss: -0.050930, acc: 0.500000, f1: 0.060606] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 289/342] [D loss: -0.050930, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 290/342] [D loss: -0.050931, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 291/342] [D loss: -0.050930, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 292/342] [D loss: -0.050931, acc: 0.500000, f1: 0.060606] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 293/342] [D loss: -0.050931, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 294/342] [D loss: -0.050931, acc: 0.500000, f1: 0.060606] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 295/342] [D loss: -0.050931, acc: 0.500000, f1: 0.060606] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 296/342] [D loss: -0.050931, acc: 0.500000, f1: 0.060606] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 297/342] [D loss: -0.050931, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 298/342] [D loss: -0.050931, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 299/342] [D loss: -0.050932, acc: 0.500000, f1: 0.060606] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 300/342] [D loss: -0.050932, acc: 0.500000, f1: 0.060606] [G loss: 0.736650]\n",
      "[Epoch 3/50] [Batch 301/342] [D loss: -0.050933, acc: 0.500000, f1: 0.074074] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 302/342] [D loss: -0.050932, acc: 0.500000, f1: 0.066667] [G loss: 0.736651]\n",
      "[Epoch 3/50] [Batch 303/342] [D loss: -0.050933, acc: 0.500000, f1: 0.060606] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 304/342] [D loss: -0.050933, acc: 0.500000, f1: 0.060606] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 305/342] [D loss: -0.050933, acc: 0.500000, f1: 0.060606] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 306/342] [D loss: -0.050932, acc: 0.500000, f1: 0.066667] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 307/342] [D loss: -0.050932, acc: 0.500000, f1: 0.066667] [G loss: 0.736652]\n",
      "[Epoch 3/50] [Batch 308/342] [D loss: -0.050933, acc: 0.500000, f1: 0.074074] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 309/342] [D loss: -0.050933, acc: 0.500000, f1: 0.060606] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 310/342] [D loss: -0.050932, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 311/342] [D loss: -0.050933, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 312/342] [D loss: -0.050934, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 313/342] [D loss: -0.050934, acc: 0.500000, f1: 0.060606] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 314/342] [D loss: -0.050933, acc: 0.500000, f1: 0.066667] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 315/342] [D loss: -0.050935, acc: 0.500000, f1: 0.060606] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 316/342] [D loss: -0.050933, acc: 0.500000, f1: 0.066667] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 317/342] [D loss: -0.050934, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 318/342] [D loss: -0.050924, acc: 0.500000, f1: 0.066667] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 319/342] [D loss: -0.050934, acc: 0.500000, f1: 0.060606] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 320/342] [D loss: -0.050933, acc: 0.500000, f1: 0.060606] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 321/342] [D loss: -0.050933, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 322/342] [D loss: -0.050935, acc: 0.500000, f1: 0.060606] [G loss: 0.736653]\n",
      "[Epoch 3/50] [Batch 323/342] [D loss: -0.050935, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 324/342] [D loss: -0.050935, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 325/342] [D loss: -0.050935, acc: 0.500000, f1: 0.060606] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 326/342] [D loss: -0.050936, acc: 0.500000, f1: 0.060606] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 327/342] [D loss: -0.050936, acc: 0.500000, f1: 0.060606] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 328/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 329/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736654]\n",
      "[Epoch 3/50] [Batch 330/342] [D loss: -0.050934, acc: 0.500000, f1: 0.060606] [G loss: 0.736655]\n",
      "[Epoch 3/50] [Batch 331/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736655]\n",
      "[Epoch 3/50] [Batch 332/342] [D loss: -0.050935, acc: 0.500000, f1: 0.066667] [G loss: 0.736655]\n",
      "[Epoch 3/50] [Batch 333/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736657]\n",
      "[Epoch 3/50] [Batch 334/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 335/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 336/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 337/342] [D loss: -0.050936, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 338/342] [D loss: -0.050936, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 339/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 340/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736656]\n",
      "[Epoch 3/50] [Batch 341/342] [D loss: -0.050936, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 0/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 1/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 2/342] [D loss: -0.050938, acc: 0.500000, f1: 0.060606] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 3/342] [D loss: -0.050921, acc: 0.500000, f1: 0.066667] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 4/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 5/342] [D loss: -0.050938, acc: 0.500000, f1: 0.066667] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 6/342] [D loss: -0.050936, acc: 0.500000, f1: 0.066667] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 7/342] [D loss: -0.050937, acc: 0.500000, f1: 0.060606] [G loss: 0.736656]\n",
      "[Epoch 4/50] [Batch 8/342] [D loss: -0.050938, acc: 0.500000, f1: 0.060606] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 9/342] [D loss: -0.050938, acc: 0.500000, f1: 0.060606] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 10/342] [D loss: -0.050938, acc: 0.500000, f1: 0.060606] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 11/342] [D loss: -0.050938, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 12/342] [D loss: -0.050938, acc: 0.500000, f1: 0.060606] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 13/342] [D loss: -0.050939, acc: 0.500000, f1: 0.060606] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 14/342] [D loss: -0.050939, acc: 0.500000, f1: 0.066667] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 15/342] [D loss: -0.050939, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 16/342] [D loss: -0.050938, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 17/342] [D loss: -0.050939, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 18/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 19/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 20/342] [D loss: -0.050939, acc: 0.500000, f1: 0.066667] [G loss: 0.736657]\n",
      "[Epoch 4/50] [Batch 21/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 22/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 23/342] [D loss: -0.050941, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 24/342] [D loss: -0.050940, acc: 0.500000, f1: 0.060606] [G loss: 0.736658]\n",
      "[Epoch 4/50] [Batch 25/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 26/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 27/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 28/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 29/342] [D loss: -0.050940, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 30/342] [D loss: -0.050942, acc: 0.500000, f1: 0.060606] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 31/342] [D loss: -0.050941, acc: 0.500000, f1: 0.060606] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 32/342] [D loss: -0.050941, acc: 0.500000, f1: 0.060606] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 33/342] [D loss: -0.050941, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 34/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 35/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736659]\n",
      "[Epoch 4/50] [Batch 36/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 37/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 38/342] [D loss: -0.050941, acc: 0.500000, f1: 0.060606] [G loss: 0.736661]\n",
      "[Epoch 4/50] [Batch 39/342] [D loss: -0.050941, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 40/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 41/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 42/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 43/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 44/342] [D loss: -0.050942, acc: 0.500000, f1: 0.060606] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 45/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 46/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736661]\n",
      "[Epoch 4/50] [Batch 47/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736660]\n",
      "[Epoch 4/50] [Batch 48/342] [D loss: -0.050943, acc: 0.500000, f1: 0.060606] [G loss: 0.736661]\n",
      "[Epoch 4/50] [Batch 49/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736661]\n",
      "[Epoch 4/50] [Batch 50/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 51/342] [D loss: -0.050943, acc: 0.500000, f1: 0.066667] [G loss: 0.736662]\n",
      "[Epoch 4/50] [Batch 52/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 53/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736662]\n",
      "[Epoch 4/50] [Batch 54/342] [D loss: -0.050943, acc: 0.500000, f1: 0.074074] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 55/342] [D loss: -0.050942, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 56/342] [D loss: -0.050944, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 57/342] [D loss: -0.050944, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 58/342] [D loss: -0.050944, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 59/342] [D loss: -0.050944, acc: 0.500000, f1: 0.060606] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 60/342] [D loss: -0.050944, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 61/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 62/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 63/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 64/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 65/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 66/342] [D loss: -0.050946, acc: 0.500000, f1: 0.066667] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 67/342] [D loss: -0.050946, acc: 0.500000, f1: 0.060606] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 68/342] [D loss: -0.050946, acc: 0.500000, f1: 0.066667] [G loss: 0.736663]\n",
      "[Epoch 4/50] [Batch 69/342] [D loss: -0.050946, acc: 0.500000, f1: 0.060606] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 70/342] [D loss: -0.050938, acc: 0.500000, f1: 0.066667] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 71/342] [D loss: -0.050947, acc: 0.500000, f1: 0.066667] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 72/342] [D loss: -0.050945, acc: 0.500000, f1: 0.066667] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 73/342] [D loss: -0.050947, acc: 0.500000, f1: 0.060606] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 74/342] [D loss: -0.050947, acc: 0.500000, f1: 0.074074] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 75/342] [D loss: -0.050947, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 76/342] [D loss: -0.050946, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 77/342] [D loss: -0.050947, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 78/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 79/342] [D loss: -0.050948, acc: 0.500000, f1: 0.074074] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 80/342] [D loss: -0.050947, acc: 0.500000, f1: 0.066667] [G loss: 0.736664]\n",
      "[Epoch 4/50] [Batch 81/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 82/342] [D loss: -0.050933, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 83/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 84/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 85/342] [D loss: -0.050949, acc: 0.500000, f1: 0.066667] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 86/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 87/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 88/342] [D loss: -0.050948, acc: 0.500000, f1: 0.066667] [G loss: 0.736665]\n",
      "[Epoch 4/50] [Batch 89/342] [D loss: -0.050949, acc: 0.500000, f1: 0.066667] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 90/342] [D loss: -0.050950, acc: 0.500000, f1: 0.066667] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 91/342] [D loss: -0.050949, acc: 0.500000, f1: 0.060606] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 92/342] [D loss: -0.050949, acc: 0.500000, f1: 0.060606] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 93/342] [D loss: -0.050950, acc: 0.500000, f1: 0.066667] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 94/342] [D loss: -0.050950, acc: 0.500000, f1: 0.060606] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 95/342] [D loss: -0.050942, acc: 0.500000, f1: 0.060606] [G loss: 0.736666]\n",
      "[Epoch 4/50] [Batch 96/342] [D loss: -0.050948, acc: 0.500000, f1: 0.060606] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 97/342] [D loss: -0.050950, acc: 0.500000, f1: 0.066667] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 98/342] [D loss: -0.050950, acc: 0.500000, f1: 0.060606] [G loss: 0.736667]\n",
      "[Epoch 4/50] [Batch 99/342] [D loss: -0.050951, acc: 0.500000, f1: 0.060606] [G loss: 0.736668]\n",
      "[Epoch 4/50] [Batch 100/342] [D loss: -0.050954, acc: 0.500000, f1: 0.066667] [G loss: 0.736670]\n",
      "[Epoch 4/50] [Batch 101/342] [D loss: -0.050959, acc: 0.500000, f1: 0.066667] [G loss: 0.736674]\n",
      "[Epoch 4/50] [Batch 102/342] [D loss: -0.050960, acc: 0.500000, f1: 0.066667] [G loss: 0.736677]\n",
      "[Epoch 4/50] [Batch 103/342] [D loss: -0.050964, acc: 0.500000, f1: 0.060606] [G loss: 0.736678]\n",
      "[Epoch 4/50] [Batch 104/342] [D loss: -0.050964, acc: 0.500000, f1: 0.066667] [G loss: 0.736680]\n",
      "[Epoch 4/50] [Batch 105/342] [D loss: -0.050967, acc: 0.500000, f1: 0.060606] [G loss: 0.736680]\n",
      "[Epoch 4/50] [Batch 106/342] [D loss: -0.050966, acc: 0.500000, f1: 0.066667] [G loss: 0.736681]\n",
      "[Epoch 4/50] [Batch 107/342] [D loss: -0.050967, acc: 0.500000, f1: 0.066667] [G loss: 0.736682]\n",
      "[Epoch 4/50] [Batch 108/342] [D loss: -0.050969, acc: 0.500000, f1: 0.066667] [G loss: 0.736683]\n",
      "[Epoch 4/50] [Batch 109/342] [D loss: -0.050970, acc: 0.500000, f1: 0.060606] [G loss: 0.736684]\n",
      "[Epoch 4/50] [Batch 110/342] [D loss: -0.050970, acc: 0.500000, f1: 0.066667] [G loss: 0.736685]\n",
      "[Epoch 4/50] [Batch 111/342] [D loss: -0.050971, acc: 0.500000, f1: 0.060606] [G loss: 0.736685]\n",
      "[Epoch 4/50] [Batch 112/342] [D loss: -0.050971, acc: 0.500000, f1: 0.060606] [G loss: 0.736686]\n",
      "[Epoch 4/50] [Batch 113/342] [D loss: -0.050972, acc: 0.500000, f1: 0.060606] [G loss: 0.736686]\n",
      "[Epoch 4/50] [Batch 114/342] [D loss: -0.050973, acc: 0.500000, f1: 0.066667] [G loss: 0.736687]\n",
      "[Epoch 4/50] [Batch 115/342] [D loss: -0.050972, acc: 0.500000, f1: 0.066667] [G loss: 0.736687]\n",
      "[Epoch 4/50] [Batch 116/342] [D loss: -0.050974, acc: 0.500000, f1: 0.066667] [G loss: 0.736688]\n",
      "[Epoch 4/50] [Batch 117/342] [D loss: -0.050973, acc: 0.500000, f1: 0.066667] [G loss: 0.736688]\n",
      "[Epoch 4/50] [Batch 118/342] [D loss: -0.050974, acc: 0.500000, f1: 0.066667] [G loss: 0.736689]\n",
      "[Epoch 4/50] [Batch 119/342] [D loss: -0.050977, acc: 0.500000, f1: 0.060606] [G loss: 0.736689]\n",
      "[Epoch 4/50] [Batch 120/342] [D loss: -0.050977, acc: 0.500000, f1: 0.066667] [G loss: 0.736689]\n",
      "[Epoch 4/50] [Batch 121/342] [D loss: -0.050977, acc: 0.500000, f1: 0.066667] [G loss: 0.736689]\n",
      "[Epoch 4/50] [Batch 122/342] [D loss: -0.050977, acc: 0.500000, f1: 0.066667] [G loss: 0.736690]\n",
      "[Epoch 4/50] [Batch 123/342] [D loss: -0.050978, acc: 0.500000, f1: 0.066667] [G loss: 0.736690]\n",
      "[Epoch 4/50] [Batch 124/342] [D loss: -0.050978, acc: 0.500000, f1: 0.060606] [G loss: 0.736690]\n",
      "[Epoch 4/50] [Batch 125/342] [D loss: -0.050978, acc: 0.500000, f1: 0.066667] [G loss: 0.736691]\n",
      "[Epoch 4/50] [Batch 126/342] [D loss: -0.050979, acc: 0.500000, f1: 0.066667] [G loss: 0.736691]\n",
      "[Epoch 4/50] [Batch 127/342] [D loss: -0.050979, acc: 0.500000, f1: 0.074074] [G loss: 0.736691]\n",
      "[Epoch 4/50] [Batch 128/342] [D loss: -0.050979, acc: 0.500000, f1: 0.074074] [G loss: 0.736691]\n",
      "[Epoch 4/50] [Batch 129/342] [D loss: -0.050979, acc: 0.500000, f1: 0.066667] [G loss: 0.736692]\n",
      "[Epoch 4/50] [Batch 130/342] [D loss: -0.050981, acc: 0.500000, f1: 0.066667] [G loss: 0.736692]\n",
      "[Epoch 4/50] [Batch 131/342] [D loss: -0.050980, acc: 0.500000, f1: 0.066667] [G loss: 0.736692]\n",
      "[Epoch 4/50] [Batch 132/342] [D loss: -0.050980, acc: 0.500000, f1: 0.066667] [G loss: 0.736693]\n",
      "[Epoch 4/50] [Batch 133/342] [D loss: -0.050980, acc: 0.500000, f1: 0.060606] [G loss: 0.736693]\n",
      "[Epoch 4/50] [Batch 134/342] [D loss: -0.050981, acc: 0.500000, f1: 0.066667] [G loss: 0.736694]\n",
      "[Epoch 4/50] [Batch 135/342] [D loss: -0.050981, acc: 0.500000, f1: 0.066667] [G loss: 0.736694]\n",
      "[Epoch 4/50] [Batch 136/342] [D loss: -0.050981, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 137/342] [D loss: -0.050983, acc: 0.500000, f1: 0.066667] [G loss: 0.736694]\n",
      "[Epoch 4/50] [Batch 138/342] [D loss: -0.050983, acc: 0.500000, f1: 0.060606] [G loss: 0.736695]\n",
      "[Epoch 4/50] [Batch 139/342] [D loss: -0.050983, acc: 0.500000, f1: 0.060606] [G loss: 0.736695]\n",
      "[Epoch 4/50] [Batch 140/342] [D loss: -0.050983, acc: 0.500000, f1: 0.066667] [G loss: 0.736695]\n",
      "[Epoch 4/50] [Batch 141/342] [D loss: -0.050984, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 142/342] [D loss: -0.050984, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 143/342] [D loss: -0.050984, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 144/342] [D loss: -0.050985, acc: 0.500000, f1: 0.074074] [G loss: 0.736697]\n",
      "[Epoch 4/50] [Batch 145/342] [D loss: -0.050985, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 146/342] [D loss: -0.050985, acc: 0.500000, f1: 0.066667] [G loss: 0.736696]\n",
      "[Epoch 4/50] [Batch 147/342] [D loss: -0.050985, acc: 0.500000, f1: 0.060606] [G loss: 0.736697]\n",
      "[Epoch 4/50] [Batch 148/342] [D loss: -0.050985, acc: 0.500000, f1: 0.066667] [G loss: 0.736697]\n",
      "[Epoch 4/50] [Batch 149/342] [D loss: -0.050986, acc: 0.500000, f1: 0.060606] [G loss: 0.736697]\n",
      "[Epoch 4/50] [Batch 150/342] [D loss: -0.050987, acc: 0.500000, f1: 0.066667] [G loss: 0.736699]\n",
      "[Epoch 4/50] [Batch 151/342] [D loss: -0.050986, acc: 0.500000, f1: 0.066667] [G loss: 0.736699]\n",
      "[Epoch 4/50] [Batch 152/342] [D loss: -0.050987, acc: 0.500000, f1: 0.066667] [G loss: 0.736699]\n",
      "[Epoch 4/50] [Batch 153/342] [D loss: -0.050988, acc: 0.500000, f1: 0.066667] [G loss: 0.736700]\n",
      "[Epoch 4/50] [Batch 154/342] [D loss: -0.050994, acc: 0.500000, f1: 0.066667] [G loss: 0.736704]\n",
      "[Epoch 4/50] [Batch 155/342] [D loss: -0.050996, acc: 0.500000, f1: 0.066667] [G loss: 0.736706]\n",
      "[Epoch 4/50] [Batch 156/342] [D loss: -0.050999, acc: 0.500000, f1: 0.066667] [G loss: 0.736708]\n",
      "[Epoch 4/50] [Batch 157/342] [D loss: -0.050999, acc: 0.500000, f1: 0.066667] [G loss: 0.736708]\n",
      "[Epoch 4/50] [Batch 158/342] [D loss: -0.050999, acc: 0.500000, f1: 0.060606] [G loss: 0.736710]\n",
      "[Epoch 4/50] [Batch 159/342] [D loss: -0.051002, acc: 0.500000, f1: 0.066667] [G loss: 0.736711]\n",
      "[Epoch 4/50] [Batch 160/342] [D loss: -0.051003, acc: 0.500000, f1: 0.066667] [G loss: 0.736712]\n",
      "[Epoch 4/50] [Batch 161/342] [D loss: -0.051006, acc: 0.500000, f1: 0.060606] [G loss: 0.736714]\n",
      "[Epoch 4/50] [Batch 162/342] [D loss: -0.051005, acc: 0.500000, f1: 0.066667] [G loss: 0.736714]\n",
      "[Epoch 4/50] [Batch 163/342] [D loss: -0.051005, acc: 0.500000, f1: 0.066667] [G loss: 0.736715]\n",
      "[Epoch 4/50] [Batch 164/342] [D loss: -0.051007, acc: 0.500000, f1: 0.066667] [G loss: 0.736716]\n",
      "[Epoch 4/50] [Batch 165/342] [D loss: -0.051007, acc: 0.500000, f1: 0.066667] [G loss: 0.736717]\n",
      "[Epoch 4/50] [Batch 166/342] [D loss: -0.051009, acc: 0.500000, f1: 0.066667] [G loss: 0.736717]\n",
      "[Epoch 4/50] [Batch 167/342] [D loss: -0.051009, acc: 0.500000, f1: 0.060606] [G loss: 0.736717]\n",
      "[Epoch 4/50] [Batch 168/342] [D loss: -0.051008, acc: 0.500000, f1: 0.074074] [G loss: 0.736717]\n",
      "[Epoch 4/50] [Batch 169/342] [D loss: -0.051010, acc: 0.500000, f1: 0.060606] [G loss: 0.736719]\n",
      "[Epoch 4/50] [Batch 170/342] [D loss: -0.051010, acc: 0.500000, f1: 0.060606] [G loss: 0.736719]\n",
      "[Epoch 4/50] [Batch 171/342] [D loss: -0.051011, acc: 0.500000, f1: 0.060606] [G loss: 0.736719]\n",
      "[Epoch 4/50] [Batch 172/342] [D loss: -0.051011, acc: 0.500000, f1: 0.060606] [G loss: 0.736720]\n",
      "[Epoch 4/50] [Batch 173/342] [D loss: -0.051011, acc: 0.500000, f1: 0.066667] [G loss: 0.736720]\n",
      "[Epoch 4/50] [Batch 174/342] [D loss: -0.051012, acc: 0.500000, f1: 0.060606] [G loss: 0.736720]\n",
      "[Epoch 4/50] [Batch 175/342] [D loss: -0.051012, acc: 0.500000, f1: 0.066667] [G loss: 0.736720]\n",
      "[Epoch 4/50] [Batch 176/342] [D loss: -0.051012, acc: 0.500000, f1: 0.066667] [G loss: 0.736721]\n",
      "[Epoch 4/50] [Batch 177/342] [D loss: -0.051012, acc: 0.500000, f1: 0.066667] [G loss: 0.736721]\n",
      "[Epoch 4/50] [Batch 178/342] [D loss: -0.051013, acc: 0.500000, f1: 0.066667] [G loss: 0.736721]\n",
      "[Epoch 4/50] [Batch 179/342] [D loss: -0.051014, acc: 0.500000, f1: 0.066667] [G loss: 0.736722]\n",
      "[Epoch 4/50] [Batch 180/342] [D loss: -0.051015, acc: 0.500000, f1: 0.066667] [G loss: 0.736722]\n",
      "[Epoch 4/50] [Batch 181/342] [D loss: -0.051015, acc: 0.500000, f1: 0.066667] [G loss: 0.736723]\n",
      "[Epoch 4/50] [Batch 182/342] [D loss: -0.051015, acc: 0.500000, f1: 0.066667] [G loss: 0.736724]\n",
      "[Epoch 4/50] [Batch 183/342] [D loss: -0.051016, acc: 0.500000, f1: 0.066667] [G loss: 0.736723]\n",
      "[Epoch 4/50] [Batch 184/342] [D loss: -0.051017, acc: 0.500000, f1: 0.066667] [G loss: 0.736724]\n",
      "[Epoch 4/50] [Batch 185/342] [D loss: -0.051017, acc: 0.500000, f1: 0.066667] [G loss: 0.736724]\n",
      "[Epoch 4/50] [Batch 186/342] [D loss: -0.051016, acc: 0.500000, f1: 0.066667] [G loss: 0.736724]\n",
      "[Epoch 4/50] [Batch 187/342] [D loss: -0.051018, acc: 0.500000, f1: 0.066667] [G loss: 0.736725]\n",
      "[Epoch 4/50] [Batch 188/342] [D loss: -0.051018, acc: 0.500000, f1: 0.066667] [G loss: 0.736725]\n",
      "[Epoch 4/50] [Batch 189/342] [D loss: -0.051017, acc: 0.500000, f1: 0.066667] [G loss: 0.736726]\n",
      "[Epoch 4/50] [Batch 190/342] [D loss: -0.051018, acc: 0.500000, f1: 0.066667] [G loss: 0.736725]\n",
      "[Epoch 4/50] [Batch 191/342] [D loss: -0.051018, acc: 0.500000, f1: 0.060606] [G loss: 0.736726]\n",
      "[Epoch 4/50] [Batch 192/342] [D loss: -0.051018, acc: 0.500000, f1: 0.066667] [G loss: 0.736726]\n",
      "[Epoch 4/50] [Batch 193/342] [D loss: -0.051018, acc: 0.500000, f1: 0.066667] [G loss: 0.736725]\n",
      "[Epoch 4/50] [Batch 194/342] [D loss: -0.051011, acc: 0.500000, f1: 0.060606] [G loss: 0.736726]\n",
      "[Epoch 4/50] [Batch 195/342] [D loss: -0.051019, acc: 0.500000, f1: 0.066667] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 196/342] [D loss: -0.051020, acc: 0.500000, f1: 0.060606] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 197/342] [D loss: -0.051020, acc: 0.500000, f1: 0.066667] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 198/342] [D loss: -0.051021, acc: 0.500000, f1: 0.060606] [G loss: 0.736727]\n",
      "[Epoch 4/50] [Batch 199/342] [D loss: -0.051021, acc: 0.500000, f1: 0.066667] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 200/342] [D loss: -0.051021, acc: 0.500000, f1: 0.066667] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 201/342] [D loss: -0.051020, acc: 0.500000, f1: 0.060606] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 202/342] [D loss: -0.051022, acc: 0.500000, f1: 0.060606] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 203/342] [D loss: -0.051022, acc: 0.500000, f1: 0.060606] [G loss: 0.736729]\n",
      "[Epoch 4/50] [Batch 204/342] [D loss: -0.051021, acc: 0.500000, f1: 0.066667] [G loss: 0.736728]\n",
      "[Epoch 4/50] [Batch 205/342] [D loss: -0.051022, acc: 0.500000, f1: 0.060606] [G loss: 0.736729]\n",
      "[Epoch 4/50] [Batch 206/342] [D loss: -0.051023, acc: 0.500000, f1: 0.066667] [G loss: 0.736729]\n",
      "[Epoch 4/50] [Batch 207/342] [D loss: -0.051022, acc: 0.500000, f1: 0.066667] [G loss: 0.736729]\n",
      "[Epoch 4/50] [Batch 208/342] [D loss: -0.051023, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 209/342] [D loss: -0.051022, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 210/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 211/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 212/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 213/342] [D loss: -0.051025, acc: 0.500000, f1: 0.060606] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 214/342] [D loss: -0.051023, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 215/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736730]\n",
      "[Epoch 4/50] [Batch 216/342] [D loss: -0.051024, acc: 0.500000, f1: 0.060606] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 217/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 218/342] [D loss: -0.051025, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 219/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 220/342] [D loss: -0.051024, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 221/342] [D loss: -0.051025, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 222/342] [D loss: -0.051025, acc: 0.500000, f1: 0.066667] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 223/342] [D loss: -0.051024, acc: 0.500000, f1: 0.060606] [G loss: 0.736732]\n",
      "[Epoch 4/50] [Batch 224/342] [D loss: -0.051024, acc: 0.500000, f1: 0.060606] [G loss: 0.736731]\n",
      "[Epoch 4/50] [Batch 225/342] [D loss: -0.051025, acc: 0.500000, f1: 0.066667] [G loss: 0.736733]\n",
      "[Epoch 4/50] [Batch 226/342] [D loss: -0.051025, acc: 0.500000, f1: 0.066667] [G loss: 0.736732]\n",
      "[Epoch 4/50] [Batch 227/342] [D loss: -0.051025, acc: 0.500000, f1: 0.060606] [G loss: 0.736732]\n",
      "[Epoch 4/50] [Batch 228/342] [D loss: -0.051030, acc: 0.500000, f1: 0.060606] [G loss: 0.736735]\n",
      "[Epoch 4/50] [Batch 229/342] [D loss: -0.051035, acc: 0.500000, f1: 0.066667] [G loss: 0.736740]\n",
      "[Epoch 4/50] [Batch 230/342] [D loss: -0.051038, acc: 0.500000, f1: 0.066667] [G loss: 0.736742]\n",
      "[Epoch 4/50] [Batch 231/342] [D loss: -0.051039, acc: 0.500000, f1: 0.066667] [G loss: 0.736744]\n",
      "[Epoch 4/50] [Batch 232/342] [D loss: -0.051042, acc: 0.500000, f1: 0.066667] [G loss: 0.736746]\n",
      "[Epoch 4/50] [Batch 233/342] [D loss: -0.051044, acc: 0.500000, f1: 0.060606] [G loss: 0.736747]\n",
      "[Epoch 4/50] [Batch 234/342] [D loss: -0.051045, acc: 0.500000, f1: 0.066667] [G loss: 0.736749]\n",
      "[Epoch 4/50] [Batch 235/342] [D loss: -0.051046, acc: 0.500000, f1: 0.066667] [G loss: 0.736750]\n",
      "[Epoch 4/50] [Batch 236/342] [D loss: -0.051047, acc: 0.500000, f1: 0.074074] [G loss: 0.736751]\n",
      "[Epoch 4/50] [Batch 237/342] [D loss: -0.051049, acc: 0.500000, f1: 0.060606] [G loss: 0.736752]\n",
      "[Epoch 4/50] [Batch 238/342] [D loss: -0.051049, acc: 0.500000, f1: 0.066667] [G loss: 0.736752]\n",
      "[Epoch 4/50] [Batch 239/342] [D loss: -0.051049, acc: 0.500000, f1: 0.066667] [G loss: 0.736752]\n",
      "[Epoch 4/50] [Batch 240/342] [D loss: -0.051049, acc: 0.500000, f1: 0.066667] [G loss: 0.736753]\n",
      "[Epoch 4/50] [Batch 241/342] [D loss: -0.051050, acc: 0.500000, f1: 0.066667] [G loss: 0.736753]\n",
      "[Epoch 4/50] [Batch 242/342] [D loss: -0.051050, acc: 0.500000, f1: 0.066667] [G loss: 0.736753]\n",
      "[Epoch 4/50] [Batch 243/342] [D loss: -0.051050, acc: 0.500000, f1: 0.060606] [G loss: 0.736753]\n",
      "[Epoch 4/50] [Batch 244/342] [D loss: -0.051051, acc: 0.500000, f1: 0.066667] [G loss: 0.736754]\n",
      "[Epoch 4/50] [Batch 245/342] [D loss: -0.051051, acc: 0.500000, f1: 0.066667] [G loss: 0.736754]\n",
      "[Epoch 4/50] [Batch 246/342] [D loss: -0.051052, acc: 0.500000, f1: 0.066667] [G loss: 0.736754]\n",
      "[Epoch 4/50] [Batch 247/342] [D loss: -0.051053, acc: 0.500000, f1: 0.066667] [G loss: 0.736755]\n",
      "[Epoch 4/50] [Batch 248/342] [D loss: -0.051052, acc: 0.500000, f1: 0.066667] [G loss: 0.736754]\n",
      "[Epoch 4/50] [Batch 249/342] [D loss: -0.051052, acc: 0.500000, f1: 0.074074] [G loss: 0.736754]\n",
      "[Epoch 4/50] [Batch 250/342] [D loss: -0.051053, acc: 0.500000, f1: 0.060606] [G loss: 0.736755]\n",
      "[Epoch 4/50] [Batch 251/342] [D loss: -0.051052, acc: 0.500000, f1: 0.060606] [G loss: 0.736755]\n",
      "[Epoch 4/50] [Batch 252/342] [D loss: -0.051053, acc: 0.500000, f1: 0.060606] [G loss: 0.736755]\n",
      "[Epoch 4/50] [Batch 253/342] [D loss: -0.051055, acc: 0.500000, f1: 0.066667] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 254/342] [D loss: -0.051053, acc: 0.500000, f1: 0.066667] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 255/342] [D loss: -0.051054, acc: 0.500000, f1: 0.074074] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 256/342] [D loss: -0.051054, acc: 0.500000, f1: 0.060606] [G loss: 0.736756]\n",
      "[Epoch 4/50] [Batch 257/342] [D loss: -0.051053, acc: 0.500000, f1: 0.060606] [G loss: 0.736756]\n",
      "[Epoch 4/50] [Batch 258/342] [D loss: -0.051053, acc: 0.500000, f1: 0.066667] [G loss: 0.736756]\n",
      "[Epoch 4/50] [Batch 259/342] [D loss: -0.051054, acc: 0.500000, f1: 0.060606] [G loss: 0.736756]\n",
      "[Epoch 4/50] [Batch 260/342] [D loss: -0.051055, acc: 0.500000, f1: 0.060606] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 261/342] [D loss: -0.051054, acc: 0.500000, f1: 0.060606] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 262/342] [D loss: -0.051055, acc: 0.500000, f1: 0.066667] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 263/342] [D loss: -0.051056, acc: 0.500000, f1: 0.066667] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 264/342] [D loss: -0.051055, acc: 0.500000, f1: 0.074074] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 265/342] [D loss: -0.051055, acc: 0.500000, f1: 0.060606] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 266/342] [D loss: -0.051056, acc: 0.500000, f1: 0.066667] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 267/342] [D loss: -0.051056, acc: 0.500000, f1: 0.060606] [G loss: 0.736757]\n",
      "[Epoch 4/50] [Batch 268/342] [D loss: -0.051056, acc: 0.500000, f1: 0.066667] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 269/342] [D loss: -0.051057, acc: 0.500000, f1: 0.060606] [G loss: 0.736759]\n",
      "[Epoch 4/50] [Batch 270/342] [D loss: -0.051057, acc: 0.500000, f1: 0.066667] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 271/342] [D loss: -0.051055, acc: 0.500000, f1: 0.066667] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 272/342] [D loss: -0.051056, acc: 0.500000, f1: 0.074074] [G loss: 0.736759]\n",
      "[Epoch 4/50] [Batch 273/342] [D loss: -0.051056, acc: 0.500000, f1: 0.060606] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 274/342] [D loss: -0.051057, acc: 0.500000, f1: 0.060606] [G loss: 0.736758]\n",
      "[Epoch 4/50] [Batch 275/342] [D loss: -0.051057, acc: 0.500000, f1: 0.066667] [G loss: 0.736759]\n",
      "[Epoch 4/50] [Batch 276/342] [D loss: -0.051057, acc: 0.500000, f1: 0.060606] [G loss: 0.736759]\n",
      "[Epoch 4/50] [Batch 277/342] [D loss: -0.051057, acc: 0.500000, f1: 0.066667] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 278/342] [D loss: -0.051058, acc: 0.500000, f1: 0.066667] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 279/342] [D loss: -0.051058, acc: 0.500000, f1: 0.066667] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 280/342] [D loss: -0.051054, acc: 0.500000, f1: 0.066667] [G loss: 0.736759]\n",
      "[Epoch 4/50] [Batch 281/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 282/342] [D loss: -0.051058, acc: 0.500000, f1: 0.060606] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 283/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 284/342] [D loss: -0.051058, acc: 0.500000, f1: 0.060606] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 285/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 286/342] [D loss: -0.051059, acc: 0.500000, f1: 0.074074] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 287/342] [D loss: -0.051059, acc: 0.500000, f1: 0.074074] [G loss: 0.736760]\n",
      "[Epoch 4/50] [Batch 288/342] [D loss: -0.051060, acc: 0.500000, f1: 0.060606] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 289/342] [D loss: -0.051060, acc: 0.500000, f1: 0.060606] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 290/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 291/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 292/342] [D loss: -0.051058, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 293/342] [D loss: -0.051059, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 294/342] [D loss: -0.051060, acc: 0.500000, f1: 0.066667] [G loss: 0.736762]\n",
      "[Epoch 4/50] [Batch 295/342] [D loss: -0.051061, acc: 0.500000, f1: 0.060606] [G loss: 0.736762]\n",
      "[Epoch 4/50] [Batch 296/342] [D loss: -0.051058, acc: 0.500000, f1: 0.066667] [G loss: 0.736761]\n",
      "[Epoch 4/50] [Batch 297/342] [D loss: -0.051061, acc: 0.500000, f1: 0.066667] [G loss: 0.736762]\n",
      "[Epoch 4/50] [Batch 298/342] [D loss: -0.051060, acc: 0.500000, f1: 0.060606] [G loss: 0.736762]\n",
      "[Epoch 4/50] [Batch 299/342] [D loss: -0.051060, acc: 0.500000, f1: 0.060606] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 300/342] [D loss: -0.051061, acc: 0.500000, f1: 0.074074] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 301/342] [D loss: -0.051062, acc: 0.500000, f1: 0.066667] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 302/342] [D loss: -0.051061, acc: 0.500000, f1: 0.066667] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 303/342] [D loss: -0.051061, acc: 0.500000, f1: 0.066667] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 304/342] [D loss: -0.051061, acc: 0.500000, f1: 0.060606] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 305/342] [D loss: -0.051062, acc: 0.500000, f1: 0.066667] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 306/342] [D loss: -0.051060, acc: 0.500000, f1: 0.066667] [G loss: 0.736763]\n",
      "[Epoch 4/50] [Batch 307/342] [D loss: -0.051062, acc: 0.500000, f1: 0.060606] [G loss: 0.736764]\n",
      "[Epoch 4/50] [Batch 308/342] [D loss: -0.051063, acc: 0.500000, f1: 0.060606] [G loss: 0.736765]\n",
      "[Epoch 4/50] [Batch 309/342] [D loss: -0.051067, acc: 0.500000, f1: 0.066667] [G loss: 0.736768]\n",
      "[Epoch 4/50] [Batch 310/342] [D loss: -0.051072, acc: 0.500000, f1: 0.066667] [G loss: 0.736771]\n",
      "[Epoch 4/50] [Batch 311/342] [D loss: -0.051074, acc: 0.500000, f1: 0.060606] [G loss: 0.736774]\n",
      "[Epoch 4/50] [Batch 312/342] [D loss: -0.051076, acc: 0.500000, f1: 0.066667] [G loss: 0.736775]\n",
      "[Epoch 4/50] [Batch 313/342] [D loss: -0.051080, acc: 0.500000, f1: 0.060606] [G loss: 0.736779]\n",
      "[Epoch 4/50] [Batch 314/342] [D loss: -0.051082, acc: 0.500000, f1: 0.060606] [G loss: 0.736780]\n",
      "[Epoch 4/50] [Batch 315/342] [D loss: -0.051083, acc: 0.500000, f1: 0.066667] [G loss: 0.736781]\n",
      "[Epoch 4/50] [Batch 316/342] [D loss: -0.051084, acc: 0.500000, f1: 0.066667] [G loss: 0.736782]\n",
      "[Epoch 4/50] [Batch 317/342] [D loss: -0.051085, acc: 0.500000, f1: 0.066667] [G loss: 0.736782]\n",
      "[Epoch 4/50] [Batch 318/342] [D loss: -0.051085, acc: 0.500000, f1: 0.060606] [G loss: 0.736783]\n",
      "[Epoch 4/50] [Batch 319/342] [D loss: -0.051087, acc: 0.500000, f1: 0.066667] [G loss: 0.736783]\n",
      "[Epoch 4/50] [Batch 320/342] [D loss: -0.051087, acc: 0.500000, f1: 0.066667] [G loss: 0.736784]\n",
      "[Epoch 4/50] [Batch 321/342] [D loss: -0.051089, acc: 0.500000, f1: 0.066667] [G loss: 0.736784]\n",
      "[Epoch 4/50] [Batch 322/342] [D loss: -0.051089, acc: 0.500000, f1: 0.060606] [G loss: 0.736785]\n",
      "[Epoch 4/50] [Batch 323/342] [D loss: -0.051089, acc: 0.500000, f1: 0.066667] [G loss: 0.736786]\n",
      "[Epoch 4/50] [Batch 324/342] [D loss: -0.051089, acc: 0.500000, f1: 0.060606] [G loss: 0.736786]\n",
      "[Epoch 4/50] [Batch 325/342] [D loss: -0.051090, acc: 0.500000, f1: 0.066667] [G loss: 0.736786]\n",
      "[Epoch 4/50] [Batch 326/342] [D loss: -0.051089, acc: 0.500000, f1: 0.066667] [G loss: 0.736786]\n",
      "[Epoch 4/50] [Batch 327/342] [D loss: -0.051090, acc: 0.500000, f1: 0.066667] [G loss: 0.736788]\n",
      "[Epoch 4/50] [Batch 328/342] [D loss: -0.051091, acc: 0.500000, f1: 0.060606] [G loss: 0.736788]\n",
      "[Epoch 4/50] [Batch 329/342] [D loss: -0.051091, acc: 0.500000, f1: 0.060606] [G loss: 0.736788]\n",
      "[Epoch 4/50] [Batch 330/342] [D loss: -0.051092, acc: 0.500000, f1: 0.066667] [G loss: 0.736789]\n",
      "[Epoch 4/50] [Batch 331/342] [D loss: -0.051093, acc: 0.500000, f1: 0.066667] [G loss: 0.736789]\n",
      "[Epoch 4/50] [Batch 332/342] [D loss: -0.051092, acc: 0.500000, f1: 0.060606] [G loss: 0.736788]\n",
      "[Epoch 4/50] [Batch 333/342] [D loss: -0.051092, acc: 0.500000, f1: 0.066667] [G loss: 0.736789]\n",
      "[Epoch 4/50] [Batch 334/342] [D loss: -0.051093, acc: 0.500000, f1: 0.066667] [G loss: 0.736788]\n",
      "[Epoch 4/50] [Batch 335/342] [D loss: -0.051074, acc: 0.500000, f1: 0.066667] [G loss: 0.736790]\n",
      "[Epoch 4/50] [Batch 336/342] [D loss: -0.051092, acc: 0.500000, f1: 0.066667] [G loss: 0.736790]\n",
      "[Epoch 4/50] [Batch 337/342] [D loss: -0.051093, acc: 0.500000, f1: 0.060606] [G loss: 0.736790]\n",
      "[Epoch 4/50] [Batch 338/342] [D loss: -0.051094, acc: 0.500000, f1: 0.066667] [G loss: 0.736791]\n",
      "[Epoch 4/50] [Batch 339/342] [D loss: -0.051094, acc: 0.500000, f1: 0.066667] [G loss: 0.736790]\n",
      "[Epoch 4/50] [Batch 340/342] [D loss: -0.051095, acc: 0.500000, f1: 0.066667] [G loss: 0.736791]\n",
      "[Epoch 4/50] [Batch 341/342] [D loss: -0.051095, acc: 0.500000, f1: 0.060606] [G loss: 0.736791]\n",
      "[Epoch 5/50] [Batch 0/342] [D loss: -0.051094, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 1/342] [D loss: -0.051094, acc: 0.500000, f1: 0.066667] [G loss: 0.736791]\n",
      "[Epoch 5/50] [Batch 2/342] [D loss: -0.051096, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 3/342] [D loss: -0.051096, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 4/342] [D loss: -0.051096, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 5/342] [D loss: -0.051095, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 6/342] [D loss: -0.051097, acc: 0.500000, f1: 0.066667] [G loss: 0.736793]\n",
      "[Epoch 5/50] [Batch 7/342] [D loss: -0.051097, acc: 0.500000, f1: 0.066667] [G loss: 0.736792]\n",
      "[Epoch 5/50] [Batch 8/342] [D loss: -0.051097, acc: 0.500000, f1: 0.066667] [G loss: 0.736793]\n",
      "[Epoch 5/50] [Batch 9/342] [D loss: -0.051097, acc: 0.500000, f1: 0.066667] [G loss: 0.736793]\n",
      "[Epoch 5/50] [Batch 10/342] [D loss: -0.051097, acc: 0.500000, f1: 0.066667] [G loss: 0.736793]\n",
      "[Epoch 5/50] [Batch 11/342] [D loss: -0.051097, acc: 0.500000, f1: 0.060606] [G loss: 0.736794]\n",
      "[Epoch 5/50] [Batch 12/342] [D loss: -0.051098, acc: 0.500000, f1: 0.066667] [G loss: 0.736793]\n",
      "[Epoch 5/50] [Batch 13/342] [D loss: -0.051099, acc: 0.500000, f1: 0.066667] [G loss: 0.736794]\n",
      "[Epoch 5/50] [Batch 14/342] [D loss: -0.051098, acc: 0.500000, f1: 0.066667] [G loss: 0.736794]\n",
      "[Epoch 5/50] [Batch 15/342] [D loss: -0.051098, acc: 0.500000, f1: 0.060606] [G loss: 0.736795]\n",
      "[Epoch 5/50] [Batch 16/342] [D loss: -0.051098, acc: 0.500000, f1: 0.066667] [G loss: 0.736795]\n",
      "[Epoch 5/50] [Batch 17/342] [D loss: -0.051099, acc: 0.500000, f1: 0.066667] [G loss: 0.736795]\n",
      "[Epoch 5/50] [Batch 18/342] [D loss: -0.051100, acc: 0.500000, f1: 0.066667] [G loss: 0.736796]\n",
      "[Epoch 5/50] [Batch 19/342] [D loss: -0.051100, acc: 0.500000, f1: 0.066667] [G loss: 0.736795]\n",
      "[Epoch 5/50] [Batch 20/342] [D loss: -0.051100, acc: 0.500000, f1: 0.066667] [G loss: 0.736795]\n",
      "[Epoch 5/50] [Batch 21/342] [D loss: -0.051100, acc: 0.500000, f1: 0.066667] [G loss: 0.736796]\n",
      "[Epoch 5/50] [Batch 22/342] [D loss: -0.051100, acc: 0.500000, f1: 0.066667] [G loss: 0.736796]\n",
      "[Epoch 5/50] [Batch 23/342] [D loss: -0.051101, acc: 0.500000, f1: 0.066667] [G loss: 0.736796]\n",
      "[Epoch 5/50] [Batch 24/342] [D loss: -0.051101, acc: 0.500000, f1: 0.066667] [G loss: 0.736797]\n",
      "[Epoch 5/50] [Batch 25/342] [D loss: -0.051102, acc: 0.500000, f1: 0.066667] [G loss: 0.736797]\n",
      "[Epoch 5/50] [Batch 26/342] [D loss: -0.051101, acc: 0.500000, f1: 0.066667] [G loss: 0.736797]\n",
      "[Epoch 5/50] [Batch 27/342] [D loss: -0.051102, acc: 0.500000, f1: 0.066667] [G loss: 0.736797]\n",
      "[Epoch 5/50] [Batch 28/342] [D loss: -0.051102, acc: 0.500000, f1: 0.066667] [G loss: 0.736798]\n",
      "[Epoch 5/50] [Batch 29/342] [D loss: -0.051103, acc: 0.500000, f1: 0.066667] [G loss: 0.736798]\n",
      "[Epoch 5/50] [Batch 30/342] [D loss: -0.051102, acc: 0.500000, f1: 0.066667] [G loss: 0.736798]\n",
      "[Epoch 5/50] [Batch 31/342] [D loss: -0.051102, acc: 0.500000, f1: 0.066667] [G loss: 0.736797]\n",
      "[Epoch 5/50] [Batch 32/342] [D loss: -0.051103, acc: 0.500000, f1: 0.066667] [G loss: 0.736798]\n",
      "[Epoch 5/50] [Batch 33/342] [D loss: -0.051103, acc: 0.500000, f1: 0.060606] [G loss: 0.736798]\n",
      "[Epoch 5/50] [Batch 34/342] [D loss: -0.051104, acc: 0.500000, f1: 0.060606] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 35/342] [D loss: -0.051103, acc: 0.500000, f1: 0.066667] [G loss: 0.736799]\n",
      "[Epoch 5/50] [Batch 36/342] [D loss: -0.051104, acc: 0.500000, f1: 0.066667] [G loss: 0.736799]\n",
      "[Epoch 5/50] [Batch 37/342] [D loss: -0.051105, acc: 0.500000, f1: 0.066667] [G loss: 0.736799]\n",
      "[Epoch 5/50] [Batch 38/342] [D loss: -0.051105, acc: 0.500000, f1: 0.066667] [G loss: 0.736799]\n",
      "[Epoch 5/50] [Batch 39/342] [D loss: -0.051105, acc: 0.500000, f1: 0.066667] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 40/342] [D loss: -0.051105, acc: 0.500000, f1: 0.066667] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 41/342] [D loss: -0.051106, acc: 0.500000, f1: 0.060606] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 42/342] [D loss: -0.051106, acc: 0.500000, f1: 0.066667] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 43/342] [D loss: -0.051107, acc: 0.500000, f1: 0.060606] [G loss: 0.736801]\n",
      "[Epoch 5/50] [Batch 44/342] [D loss: -0.051106, acc: 0.500000, f1: 0.060606] [G loss: 0.736800]\n",
      "[Epoch 5/50] [Batch 45/342] [D loss: -0.051106, acc: 0.500000, f1: 0.066667] [G loss: 0.736801]\n",
      "[Epoch 5/50] [Batch 46/342] [D loss: -0.051107, acc: 0.500000, f1: 0.060606] [G loss: 0.736801]\n",
      "[Epoch 5/50] [Batch 47/342] [D loss: -0.051107, acc: 0.500000, f1: 0.066667] [G loss: 0.736801]\n",
      "[Epoch 5/50] [Batch 48/342] [D loss: -0.051107, acc: 0.500000, f1: 0.066667] [G loss: 0.736801]\n",
      "[Epoch 5/50] [Batch 49/342] [D loss: -0.051107, acc: 0.500000, f1: 0.074074] [G loss: 0.736802]\n",
      "[Epoch 5/50] [Batch 50/342] [D loss: -0.051101, acc: 0.500000, f1: 0.060606] [G loss: 0.736802]\n",
      "[Epoch 5/50] [Batch 51/342] [D loss: -0.051108, acc: 0.500000, f1: 0.060606] [G loss: 0.736803]\n",
      "[Epoch 5/50] [Batch 52/342] [D loss: -0.051108, acc: 0.500000, f1: 0.060606] [G loss: 0.736802]\n",
      "[Epoch 5/50] [Batch 53/342] [D loss: -0.051107, acc: 0.500000, f1: 0.066667] [G loss: 0.736802]\n",
      "[Epoch 5/50] [Batch 54/342] [D loss: -0.051109, acc: 0.500000, f1: 0.083333] [G loss: 0.736802]\n",
      "[Epoch 5/50] [Batch 55/342] [D loss: -0.051109, acc: 0.500000, f1: 0.060606] [G loss: 0.736804]\n",
      "[Epoch 5/50] [Batch 56/342] [D loss: -0.051110, acc: 0.500000, f1: 0.066667] [G loss: 0.736804]\n",
      "[Epoch 5/50] [Batch 57/342] [D loss: -0.051110, acc: 0.500000, f1: 0.060606] [G loss: 0.736804]\n",
      "[Epoch 5/50] [Batch 58/342] [D loss: -0.051109, acc: 0.500000, f1: 0.066667] [G loss: 0.736803]\n",
      "[Epoch 5/50] [Batch 59/342] [D loss: -0.051109, acc: 0.500000, f1: 0.060606] [G loss: 0.736804]\n",
      "[Epoch 5/50] [Batch 60/342] [D loss: -0.051111, acc: 0.500000, f1: 0.066667] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 61/342] [D loss: -0.051112, acc: 0.500000, f1: 0.060606] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 62/342] [D loss: -0.051110, acc: 0.500000, f1: 0.060606] [G loss: 0.736804]\n",
      "[Epoch 5/50] [Batch 63/342] [D loss: -0.051111, acc: 0.500000, f1: 0.060606] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 64/342] [D loss: -0.051109, acc: 0.500000, f1: 0.066667] [G loss: 0.736806]\n",
      "[Epoch 5/50] [Batch 65/342] [D loss: -0.051113, acc: 0.500000, f1: 0.066667] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 66/342] [D loss: -0.051112, acc: 0.500000, f1: 0.066667] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 67/342] [D loss: -0.051112, acc: 0.500000, f1: 0.060606] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 68/342] [D loss: -0.051112, acc: 0.500000, f1: 0.066667] [G loss: 0.736805]\n",
      "[Epoch 5/50] [Batch 69/342] [D loss: -0.051114, acc: 0.500000, f1: 0.060606] [G loss: 0.736806]\n",
      "[Epoch 5/50] [Batch 70/342] [D loss: -0.051113, acc: 0.500000, f1: 0.066667] [G loss: 0.736807]\n",
      "[Epoch 5/50] [Batch 71/342] [D loss: -0.051114, acc: 0.500000, f1: 0.066667] [G loss: 0.736807]\n",
      "[Epoch 5/50] [Batch 72/342] [D loss: -0.051114, acc: 0.500000, f1: 0.066667] [G loss: 0.736808]\n",
      "[Epoch 5/50] [Batch 73/342] [D loss: -0.051113, acc: 0.500000, f1: 0.066667] [G loss: 0.736808]\n",
      "[Epoch 5/50] [Batch 74/342] [D loss: -0.051113, acc: 0.500000, f1: 0.060606] [G loss: 0.736807]\n",
      "[Epoch 5/50] [Batch 75/342] [D loss: -0.051114, acc: 0.500000, f1: 0.066667] [G loss: 0.736808]\n",
      "[Epoch 5/50] [Batch 76/342] [D loss: -0.051114, acc: 0.500000, f1: 0.060606] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 77/342] [D loss: -0.051115, acc: 0.500000, f1: 0.066667] [G loss: 0.736808]\n",
      "[Epoch 5/50] [Batch 78/342] [D loss: -0.051116, acc: 0.500000, f1: 0.066667] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 79/342] [D loss: -0.051115, acc: 0.500000, f1: 0.060606] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 80/342] [D loss: -0.051115, acc: 0.500000, f1: 0.066667] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 81/342] [D loss: -0.051115, acc: 0.500000, f1: 0.066667] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 82/342] [D loss: -0.051115, acc: 0.500000, f1: 0.066667] [G loss: 0.736808]\n",
      "[Epoch 5/50] [Batch 83/342] [D loss: -0.051116, acc: 0.500000, f1: 0.066667] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 84/342] [D loss: -0.051117, acc: 0.500000, f1: 0.060606] [G loss: 0.736810]\n",
      "[Epoch 5/50] [Batch 85/342] [D loss: -0.051117, acc: 0.500000, f1: 0.060606] [G loss: 0.736810]\n",
      "[Epoch 5/50] [Batch 86/342] [D loss: -0.051117, acc: 0.500000, f1: 0.060606] [G loss: 0.736809]\n",
      "[Epoch 5/50] [Batch 87/342] [D loss: -0.051117, acc: 0.500000, f1: 0.066667] [G loss: 0.736810]\n",
      "[Epoch 5/50] [Batch 88/342] [D loss: -0.051118, acc: 0.500000, f1: 0.066667] [G loss: 0.736810]\n",
      "[Epoch 5/50] [Batch 89/342] [D loss: -0.051119, acc: 0.500000, f1: 0.060606] [G loss: 0.736811]\n",
      "[Epoch 5/50] [Batch 90/342] [D loss: -0.051118, acc: 0.500000, f1: 0.060606] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 91/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736811]\n",
      "[Epoch 5/50] [Batch 92/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736811]\n",
      "[Epoch 5/50] [Batch 93/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 94/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736811]\n",
      "[Epoch 5/50] [Batch 95/342] [D loss: -0.051121, acc: 0.500000, f1: 0.060606] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 96/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736813]\n",
      "[Epoch 5/50] [Batch 97/342] [D loss: -0.051120, acc: 0.500000, f1: 0.066667] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 98/342] [D loss: -0.051120, acc: 0.500000, f1: 0.066667] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 99/342] [D loss: -0.051120, acc: 0.500000, f1: 0.060606] [G loss: 0.736812]\n",
      "[Epoch 5/50] [Batch 100/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736813]\n",
      "[Epoch 5/50] [Batch 101/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736813]\n",
      "[Epoch 5/50] [Batch 102/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736814]\n",
      "[Epoch 5/50] [Batch 103/342] [D loss: -0.051123, acc: 0.500000, f1: 0.066667] [G loss: 0.736814]\n",
      "[Epoch 5/50] [Batch 104/342] [D loss: -0.051121, acc: 0.500000, f1: 0.060606] [G loss: 0.736813]\n",
      "[Epoch 5/50] [Batch 105/342] [D loss: -0.051119, acc: 0.500000, f1: 0.066667] [G loss: 0.736813]\n",
      "[Epoch 5/50] [Batch 106/342] [D loss: -0.051122, acc: 0.500000, f1: 0.060606] [G loss: 0.736814]\n",
      "[Epoch 5/50] [Batch 107/342] [D loss: -0.051123, acc: 0.500000, f1: 0.066667] [G loss: 0.736814]\n",
      "[Epoch 5/50] [Batch 108/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 109/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736814]\n",
      "[Epoch 5/50] [Batch 110/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 111/342] [D loss: -0.051123, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 112/342] [D loss: -0.051122, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 113/342] [D loss: -0.051124, acc: 0.500000, f1: 0.060606] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 114/342] [D loss: -0.051123, acc: 0.500000, f1: 0.060606] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 115/342] [D loss: -0.051124, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 116/342] [D loss: -0.051123, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 117/342] [D loss: -0.051122, acc: 0.500000, f1: 0.060606] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 118/342] [D loss: -0.051123, acc: 0.500000, f1: 0.066667] [G loss: 0.736815]\n",
      "[Epoch 5/50] [Batch 119/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 120/342] [D loss: -0.051124, acc: 0.500000, f1: 0.060606] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 121/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 122/342] [D loss: -0.051124, acc: 0.500000, f1: 0.060606] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 123/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 124/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 125/342] [D loss: -0.051124, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 126/342] [D loss: -0.051118, acc: 0.500000, f1: 0.066667] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 127/342] [D loss: -0.051126, acc: 0.500000, f1: 0.060606] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 128/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 129/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 130/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 131/342] [D loss: -0.051126, acc: 0.500000, f1: 0.060606] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 132/342] [D loss: -0.051125, acc: 0.500000, f1: 0.066667] [G loss: 0.736816]\n",
      "[Epoch 5/50] [Batch 133/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736817]\n",
      "[Epoch 5/50] [Batch 134/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 135/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 136/342] [D loss: -0.051126, acc: 0.500000, f1: 0.060606] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 137/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 138/342] [D loss: -0.051127, acc: 0.500000, f1: 0.060606] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 139/342] [D loss: -0.051128, acc: 0.500000, f1: 0.060606] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 140/342] [D loss: -0.051127, acc: 0.500000, f1: 0.074074] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 141/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 142/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 143/342] [D loss: -0.051126, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 144/342] [D loss: -0.051128, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 145/342] [D loss: -0.051127, acc: 0.500000, f1: 0.060606] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 146/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 147/342] [D loss: -0.051128, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 148/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736818]\n",
      "[Epoch 5/50] [Batch 149/342] [D loss: -0.051127, acc: 0.500000, f1: 0.060606] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 150/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 151/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 152/342] [D loss: -0.051127, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 153/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 154/342] [D loss: -0.051129, acc: 0.500000, f1: 0.060606] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 155/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 156/342] [D loss: -0.051129, acc: 0.500000, f1: 0.060606] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 157/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 158/342] [D loss: -0.051128, acc: 0.500000, f1: 0.060606] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 159/342] [D loss: -0.051128, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 160/342] [D loss: -0.051128, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 161/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736819]\n",
      "[Epoch 5/50] [Batch 162/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 163/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 164/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 165/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 166/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 167/342] [D loss: -0.051130, acc: 0.500000, f1: 0.060606] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 168/342] [D loss: -0.051130, acc: 0.500000, f1: 0.074074] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 169/342] [D loss: -0.051130, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 170/342] [D loss: -0.051130, acc: 0.500000, f1: 0.060606] [G loss: 0.736820]\n",
      "[Epoch 5/50] [Batch 171/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 172/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 173/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 174/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 175/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 176/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 177/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 178/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 179/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 180/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 181/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 182/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 183/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 184/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 185/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 186/342] [D loss: -0.051126, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 187/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 188/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 189/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 190/342] [D loss: -0.051129, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 191/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 192/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 193/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 194/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 195/342] [D loss: -0.051116, acc: 0.500000, f1: 0.060606] [G loss: 0.736823]\n",
      "[Epoch 5/50] [Batch 196/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 197/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 198/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 199/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 200/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 201/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 202/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 203/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 204/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 205/342] [D loss: -0.051130, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 206/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 207/342] [D loss: -0.051129, acc: 0.500000, f1: 0.060606] [G loss: 0.736821]\n",
      "[Epoch 5/50] [Batch 208/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 209/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 210/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 211/342] [D loss: -0.051131, acc: 0.500000, f1: 0.060606] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 212/342] [D loss: -0.051131, acc: 0.500000, f1: 0.066667] [G loss: 0.736822]\n",
      "[Epoch 5/50] [Batch 213/342] [D loss: -0.051133, acc: 0.500000, f1: 0.066667] [G loss: 0.736824]\n",
      "[Epoch 5/50] [Batch 214/342] [D loss: -0.051136, acc: 0.500000, f1: 0.066667] [G loss: 0.736827]\n",
      "[Epoch 5/50] [Batch 215/342] [D loss: -0.051140, acc: 0.500000, f1: 0.066667] [G loss: 0.736830]\n",
      "[Epoch 5/50] [Batch 216/342] [D loss: -0.051143, acc: 0.500000, f1: 0.060606] [G loss: 0.736831]\n",
      "[Epoch 5/50] [Batch 217/342] [D loss: -0.051145, acc: 0.500000, f1: 0.066667] [G loss: 0.736833]\n",
      "[Epoch 5/50] [Batch 218/342] [D loss: -0.051146, acc: 0.500000, f1: 0.066667] [G loss: 0.736834]\n",
      "[Epoch 5/50] [Batch 219/342] [D loss: -0.051148, acc: 0.500000, f1: 0.066667] [G loss: 0.736836]\n",
      "[Epoch 5/50] [Batch 220/342] [D loss: -0.051150, acc: 0.500000, f1: 0.066667] [G loss: 0.736838]\n",
      "[Epoch 5/50] [Batch 221/342] [D loss: -0.051151, acc: 0.500000, f1: 0.066667] [G loss: 0.736839]\n",
      "[Epoch 5/50] [Batch 222/342] [D loss: -0.051153, acc: 0.500000, f1: 0.066667] [G loss: 0.736839]\n",
      "[Epoch 5/50] [Batch 223/342] [D loss: -0.051151, acc: 0.500000, f1: 0.066667] [G loss: 0.736840]\n",
      "[Epoch 5/50] [Batch 224/342] [D loss: -0.051152, acc: 0.500000, f1: 0.066667] [G loss: 0.736840]\n",
      "[Epoch 5/50] [Batch 225/342] [D loss: -0.051154, acc: 0.500000, f1: 0.074074] [G loss: 0.736841]\n",
      "[Epoch 5/50] [Batch 226/342] [D loss: -0.051154, acc: 0.500000, f1: 0.066667] [G loss: 0.736841]\n",
      "[Epoch 5/50] [Batch 227/342] [D loss: -0.051155, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 228/342] [D loss: -0.051154, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 229/342] [D loss: -0.051155, acc: 0.500000, f1: 0.066667] [G loss: 0.736841]\n",
      "[Epoch 5/50] [Batch 230/342] [D loss: -0.051154, acc: 0.500000, f1: 0.066667] [G loss: 0.736843]\n",
      "[Epoch 5/50] [Batch 231/342] [D loss: -0.051155, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 232/342] [D loss: -0.051154, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 233/342] [D loss: -0.051156, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 234/342] [D loss: -0.051154, acc: 0.500000, f1: 0.066667] [G loss: 0.736843]\n",
      "[Epoch 5/50] [Batch 235/342] [D loss: -0.051155, acc: 0.500000, f1: 0.060606] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 236/342] [D loss: -0.051157, acc: 0.500000, f1: 0.060606] [G loss: 0.736844]\n",
      "[Epoch 5/50] [Batch 237/342] [D loss: -0.051156, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 238/342] [D loss: -0.051155, acc: 0.500000, f1: 0.066667] [G loss: 0.736842]\n",
      "[Epoch 5/50] [Batch 239/342] [D loss: -0.051157, acc: 0.500000, f1: 0.066667] [G loss: 0.736844]\n",
      "[Epoch 5/50] [Batch 240/342] [D loss: -0.051156, acc: 0.500000, f1: 0.066667] [G loss: 0.736844]\n",
      "[Epoch 5/50] [Batch 241/342] [D loss: -0.051157, acc: 0.500000, f1: 0.066667] [G loss: 0.736843]\n",
      "[Epoch 5/50] [Batch 242/342] [D loss: -0.051151, acc: 0.500000, f1: 0.066667] [G loss: 0.736845]\n",
      "[Epoch 5/50] [Batch 243/342] [D loss: -0.051157, acc: 0.500000, f1: 0.066667] [G loss: 0.736845]\n",
      "[Epoch 5/50] [Batch 244/342] [D loss: -0.051158, acc: 0.500000, f1: 0.060606] [G loss: 0.736844]\n",
      "[Epoch 5/50] [Batch 245/342] [D loss: -0.051157, acc: 0.500000, f1: 0.066667] [G loss: 0.736844]\n",
      "[Epoch 5/50] [Batch 246/342] [D loss: -0.051158, acc: 0.500000, f1: 0.060606] [G loss: 0.736845]\n",
      "[Epoch 5/50] [Batch 247/342] [D loss: -0.051158, acc: 0.500000, f1: 0.074074] [G loss: 0.736845]\n",
      "[Epoch 5/50] [Batch 248/342] [D loss: -0.051161, acc: 0.500000, f1: 0.060606] [G loss: 0.736847]\n",
      "[Epoch 5/50] [Batch 249/342] [D loss: -0.051166, acc: 0.500000, f1: 0.066667] [G loss: 0.736851]\n",
      "[Epoch 5/50] [Batch 250/342] [D loss: -0.051169, acc: 0.500000, f1: 0.066667] [G loss: 0.736855]\n",
      "[Epoch 5/50] [Batch 251/342] [D loss: -0.051172, acc: 0.500000, f1: 0.066667] [G loss: 0.736856]\n",
      "[Epoch 5/50] [Batch 252/342] [D loss: -0.051174, acc: 0.500000, f1: 0.066667] [G loss: 0.736858]\n",
      "[Epoch 5/50] [Batch 253/342] [D loss: -0.051177, acc: 0.500000, f1: 0.060606] [G loss: 0.736860]\n",
      "[Epoch 5/50] [Batch 254/342] [D loss: -0.051178, acc: 0.500000, f1: 0.066667] [G loss: 0.736861]\n",
      "[Epoch 5/50] [Batch 255/342] [D loss: -0.051178, acc: 0.500000, f1: 0.066667] [G loss: 0.736862]\n",
      "[Epoch 5/50] [Batch 256/342] [D loss: -0.051179, acc: 0.500000, f1: 0.066667] [G loss: 0.736863]\n",
      "[Epoch 5/50] [Batch 257/342] [D loss: -0.051180, acc: 0.500000, f1: 0.066667] [G loss: 0.736863]\n",
      "[Epoch 5/50] [Batch 258/342] [D loss: -0.051181, acc: 0.500000, f1: 0.066667] [G loss: 0.736864]\n",
      "[Epoch 5/50] [Batch 259/342] [D loss: -0.051181, acc: 0.500000, f1: 0.066667] [G loss: 0.736864]\n",
      "[Epoch 5/50] [Batch 260/342] [D loss: -0.051182, acc: 0.500000, f1: 0.066667] [G loss: 0.736865]\n",
      "[Epoch 5/50] [Batch 261/342] [D loss: -0.051183, acc: 0.500000, f1: 0.066667] [G loss: 0.736865]\n",
      "[Epoch 5/50] [Batch 262/342] [D loss: -0.051182, acc: 0.500000, f1: 0.066667] [G loss: 0.736865]\n",
      "[Epoch 5/50] [Batch 263/342] [D loss: -0.051182, acc: 0.500000, f1: 0.066667] [G loss: 0.736867]\n",
      "[Epoch 5/50] [Batch 264/342] [D loss: -0.051184, acc: 0.500000, f1: 0.060606] [G loss: 0.736866]\n",
      "[Epoch 5/50] [Batch 265/342] [D loss: -0.051183, acc: 0.500000, f1: 0.066667] [G loss: 0.736866]\n",
      "[Epoch 5/50] [Batch 266/342] [D loss: -0.051183, acc: 0.500000, f1: 0.060606] [G loss: 0.736866]\n",
      "[Epoch 5/50] [Batch 267/342] [D loss: -0.051184, acc: 0.500000, f1: 0.060606] [G loss: 0.736867]\n",
      "[Epoch 5/50] [Batch 268/342] [D loss: -0.051184, acc: 0.500000, f1: 0.066667] [G loss: 0.736867]\n",
      "[Epoch 5/50] [Batch 269/342] [D loss: -0.051184, acc: 0.500000, f1: 0.066667] [G loss: 0.736868]\n",
      "[Epoch 5/50] [Batch 270/342] [D loss: -0.051184, acc: 0.500000, f1: 0.074074] [G loss: 0.736867]\n",
      "[Epoch 5/50] [Batch 271/342] [D loss: -0.051185, acc: 0.500000, f1: 0.066667] [G loss: 0.736868]\n",
      "[Epoch 5/50] [Batch 272/342] [D loss: -0.051186, acc: 0.500000, f1: 0.066667] [G loss: 0.736868]\n",
      "[Epoch 5/50] [Batch 273/342] [D loss: -0.051186, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 274/342] [D loss: -0.051184, acc: 0.500000, f1: 0.060606] [G loss: 0.736868]\n",
      "[Epoch 5/50] [Batch 275/342] [D loss: -0.051185, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 276/342] [D loss: -0.051186, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 277/342] [D loss: -0.051186, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 278/342] [D loss: -0.051187, acc: 0.500000, f1: 0.060606] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 279/342] [D loss: -0.051187, acc: 0.500000, f1: 0.066667] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 280/342] [D loss: -0.051186, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 281/342] [D loss: -0.051188, acc: 0.500000, f1: 0.060606] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 282/342] [D loss: -0.051187, acc: 0.500000, f1: 0.066667] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 283/342] [D loss: -0.051188, acc: 0.500000, f1: 0.066667] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 284/342] [D loss: -0.051188, acc: 0.500000, f1: 0.066667] [G loss: 0.736869]\n",
      "[Epoch 5/50] [Batch 285/342] [D loss: -0.051188, acc: 0.500000, f1: 0.060606] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 286/342] [D loss: -0.051188, acc: 0.500000, f1: 0.066667] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 287/342] [D loss: -0.051188, acc: 0.500000, f1: 0.060606] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 288/342] [D loss: -0.051187, acc: 0.500000, f1: 0.060606] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 289/342] [D loss: -0.051188, acc: 0.500000, f1: 0.066667] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 290/342] [D loss: -0.051188, acc: 0.500000, f1: 0.060606] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 291/342] [D loss: -0.051188, acc: 0.500000, f1: 0.060606] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 292/342] [D loss: -0.051189, acc: 0.500000, f1: 0.060606] [G loss: 0.736870]\n",
      "[Epoch 5/50] [Batch 293/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 294/342] [D loss: -0.051189, acc: 0.500000, f1: 0.060606] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 295/342] [D loss: -0.051189, acc: 0.500000, f1: 0.060606] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 296/342] [D loss: -0.051189, acc: 0.500000, f1: 0.060606] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 297/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 298/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736871]\n",
      "[Epoch 5/50] [Batch 299/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 300/342] [D loss: -0.051191, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 301/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 302/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 303/342] [D loss: -0.051191, acc: 0.500000, f1: 0.066667] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 304/342] [D loss: -0.051191, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 305/342] [D loss: -0.051191, acc: 0.500000, f1: 0.060606] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 306/342] [D loss: -0.051190, acc: 0.500000, f1: 0.066667] [G loss: 0.736872]\n",
      "[Epoch 5/50] [Batch 307/342] [D loss: -0.051191, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 308/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 309/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 310/342] [D loss: -0.051193, acc: 0.500000, f1: 0.066667] [G loss: 0.736873]\n",
      "[Epoch 5/50] [Batch 311/342] [D loss: -0.051176, acc: 0.500000, f1: 0.066667] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 312/342] [D loss: -0.051192, acc: 0.500000, f1: 0.060606] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 313/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 314/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 315/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 316/342] [D loss: -0.051192, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 317/342] [D loss: -0.051192, acc: 0.500000, f1: 0.060606] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 318/342] [D loss: -0.051190, acc: 0.500000, f1: 0.060606] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 319/342] [D loss: -0.051192, acc: 0.500000, f1: 0.060606] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 320/342] [D loss: -0.051193, acc: 0.500000, f1: 0.066667] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 321/342] [D loss: -0.051193, acc: 0.500000, f1: 0.066667] [G loss: 0.736874]\n",
      "[Epoch 5/50] [Batch 322/342] [D loss: -0.051193, acc: 0.500000, f1: 0.060606] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 323/342] [D loss: -0.051194, acc: 0.500000, f1: 0.074074] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 324/342] [D loss: -0.051193, acc: 0.500000, f1: 0.060606] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 325/342] [D loss: -0.051193, acc: 0.500000, f1: 0.066667] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 326/342] [D loss: -0.051194, acc: 0.500000, f1: 0.066667] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 327/342] [D loss: -0.051189, acc: 0.500000, f1: 0.060606] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 328/342] [D loss: -0.051193, acc: 0.500000, f1: 0.060606] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 329/342] [D loss: -0.051194, acc: 0.500000, f1: 0.066667] [G loss: 0.736875]\n",
      "[Epoch 5/50] [Batch 330/342] [D loss: -0.051195, acc: 0.500000, f1: 0.066667] [G loss: 0.736877]\n",
      "[Epoch 5/50] [Batch 331/342] [D loss: -0.051195, acc: 0.500000, f1: 0.066667] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 332/342] [D loss: -0.051194, acc: 0.500000, f1: 0.060606] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 333/342] [D loss: -0.051194, acc: 0.500000, f1: 0.060606] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 334/342] [D loss: -0.051196, acc: 0.500000, f1: 0.060606] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 335/342] [D loss: -0.051195, acc: 0.500000, f1: 0.066667] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 336/342] [D loss: -0.051196, acc: 0.500000, f1: 0.060606] [G loss: 0.736877]\n",
      "[Epoch 5/50] [Batch 337/342] [D loss: -0.051195, acc: 0.500000, f1: 0.066667] [G loss: 0.736876]\n",
      "[Epoch 5/50] [Batch 338/342] [D loss: -0.051196, acc: 0.500000, f1: 0.066667] [G loss: 0.736877]\n",
      "[Epoch 5/50] [Batch 339/342] [D loss: -0.051195, acc: 0.500000, f1: 0.060606] [G loss: 0.736877]\n",
      "[Epoch 5/50] [Batch 340/342] [D loss: -0.051197, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 5/50] [Batch 341/342] [D loss: -0.051197, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 0/342] [D loss: -0.051197, acc: 0.500000, f1: 0.060606] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 1/342] [D loss: -0.051197, acc: 0.500000, f1: 0.060606] [G loss: 0.736877]\n",
      "[Epoch 6/50] [Batch 2/342] [D loss: -0.051197, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 3/342] [D loss: -0.051199, acc: 0.500000, f1: 0.060606] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 4/342] [D loss: -0.051196, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 5/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 6/342] [D loss: -0.051196, acc: 0.500000, f1: 0.060606] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 7/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 8/342] [D loss: -0.051197, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 9/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 10/342] [D loss: -0.051198, acc: 0.500000, f1: 0.060606] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 11/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736878]\n",
      "[Epoch 6/50] [Batch 12/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 13/342] [D loss: -0.051199, acc: 0.500000, f1: 0.060606] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 14/342] [D loss: -0.051198, acc: 0.500000, f1: 0.060606] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 15/342] [D loss: -0.051198, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 16/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 17/342] [D loss: -0.051199, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 18/342] [D loss: -0.051199, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 19/342] [D loss: -0.051199, acc: 0.500000, f1: 0.066667] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 20/342] [D loss: -0.051200, acc: 0.500000, f1: 0.060606] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 21/342] [D loss: -0.051199, acc: 0.500000, f1: 0.060606] [G loss: 0.736879]\n",
      "[Epoch 6/50] [Batch 22/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 23/342] [D loss: -0.051199, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 24/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 25/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 26/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 27/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736880]\n",
      "[Epoch 6/50] [Batch 28/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 29/342] [D loss: -0.051199, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 30/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 31/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 32/342] [D loss: -0.051200, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 33/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 34/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 35/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 36/342] [D loss: -0.051201, acc: 0.500000, f1: 0.060606] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 37/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 38/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 39/342] [D loss: -0.051202, acc: 0.500000, f1: 0.066667] [G loss: 0.736881]\n",
      "[Epoch 6/50] [Batch 40/342] [D loss: -0.051202, acc: 0.500000, f1: 0.066667] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 41/342] [D loss: -0.051202, acc: 0.500000, f1: 0.074074] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 42/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 43/342] [D loss: -0.051201, acc: 0.500000, f1: 0.066667] [G loss: 0.736882]\n",
      "[Epoch 6/50] [Batch 44/342] [D loss: -0.051203, acc: 0.500000, f1: 0.060606] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 45/342] [D loss: -0.051204, acc: 0.500000, f1: 0.060606] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 46/342] [D loss: -0.051202, acc: 0.500000, f1: 0.060606] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 47/342] [D loss: -0.051203, acc: 0.500000, f1: 0.066667] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 48/342] [D loss: -0.051203, acc: 0.500000, f1: 0.060606] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 49/342] [D loss: -0.051204, acc: 0.500000, f1: 0.066667] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 50/342] [D loss: -0.051203, acc: 0.500000, f1: 0.060606] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 51/342] [D loss: -0.051203, acc: 0.500000, f1: 0.066667] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 52/342] [D loss: -0.051204, acc: 0.500000, f1: 0.066667] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 53/342] [D loss: -0.051204, acc: 0.500000, f1: 0.066667] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 54/342] [D loss: -0.051203, acc: 0.500000, f1: 0.060606] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 55/342] [D loss: -0.051204, acc: 0.500000, f1: 0.066667] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 56/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736883]\n",
      "[Epoch 6/50] [Batch 57/342] [D loss: -0.051203, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 58/342] [D loss: -0.051205, acc: 0.500000, f1: 0.060606] [G loss: 0.736884]\n",
      "[Epoch 6/50] [Batch 59/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 60/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 61/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 62/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 63/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 64/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 65/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 66/342] [D loss: -0.051207, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 67/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 68/342] [D loss: -0.051206, acc: 0.500000, f1: 0.060606] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 69/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 70/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 71/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 72/342] [D loss: -0.051206, acc: 0.500000, f1: 0.060606] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 73/342] [D loss: -0.051207, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 74/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 75/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 76/342] [D loss: -0.051208, acc: 0.500000, f1: 0.066667] [G loss: 0.736887]\n",
      "[Epoch 6/50] [Batch 77/342] [D loss: -0.051207, acc: 0.500000, f1: 0.060606] [G loss: 0.736887]\n",
      "[Epoch 6/50] [Batch 78/342] [D loss: -0.051205, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 79/342] [D loss: -0.051206, acc: 0.500000, f1: 0.060606] [G loss: 0.736885]\n",
      "[Epoch 6/50] [Batch 80/342] [D loss: -0.051207, acc: 0.500000, f1: 0.066667] [G loss: 0.736887]\n",
      "[Epoch 6/50] [Batch 81/342] [D loss: -0.051207, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 82/342] [D loss: -0.051202, acc: 0.500000, f1: 0.066667] [G loss: 0.736886]\n",
      "[Epoch 6/50] [Batch 83/342] [D loss: -0.051208, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 84/342] [D loss: -0.051209, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 85/342] [D loss: -0.051207, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 86/342] [D loss: -0.051194, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 87/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 88/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 89/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 90/342] [D loss: -0.051209, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 91/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 92/342] [D loss: -0.051208, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 93/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 94/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 95/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 96/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 97/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 98/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 99/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 100/342] [D loss: -0.051211, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 101/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 102/342] [D loss: -0.051209, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 103/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 104/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 105/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 106/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 107/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 108/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 109/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 110/342] [D loss: -0.051209, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 111/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 112/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 113/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 114/342] [D loss: -0.051211, acc: 0.500000, f1: 0.074074] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 115/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 116/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 117/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 118/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 119/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 120/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 121/342] [D loss: -0.051210, acc: 0.500000, f1: 0.060606] [G loss: 0.736888]\n",
      "[Epoch 6/50] [Batch 122/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 123/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 124/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 125/342] [D loss: -0.051209, acc: 0.500000, f1: 0.066667] [G loss: 0.736889]\n",
      "[Epoch 6/50] [Batch 126/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 127/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 128/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 129/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 130/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 131/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 132/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 133/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 134/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 135/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 136/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 137/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 138/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 139/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 140/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 141/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 142/342] [D loss: -0.051214, acc: 0.500000, f1: 0.074074] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 143/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 144/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 145/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 146/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 147/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 148/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 149/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 150/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 151/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 152/342] [D loss: -0.051198, acc: 0.500000, f1: 0.074074] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 153/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 154/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 155/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 156/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 157/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 158/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 159/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 160/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 161/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 162/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 163/342] [D loss: -0.051211, acc: 0.500000, f1: 0.074074] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 164/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 165/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 166/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 167/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 168/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 169/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 170/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 171/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 172/342] [D loss: -0.051213, acc: 0.500000, f1: 0.074074] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 173/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 174/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 175/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 176/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 177/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 178/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 179/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 180/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 181/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 182/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 183/342] [D loss: -0.051213, acc: 0.500000, f1: 0.074074] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 184/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 185/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 186/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 187/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 188/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 189/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 190/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 191/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 192/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 193/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 194/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 195/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 196/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 197/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 198/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 199/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 200/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 201/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 202/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 203/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 204/342] [D loss: -0.051213, acc: 0.500000, f1: 0.074074] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 205/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 206/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 207/342] [D loss: -0.051210, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 208/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 209/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 210/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 211/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 212/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 213/342] [D loss: -0.051216, acc: 0.500000, f1: 0.066667] [G loss: 0.736894]\n",
      "[Epoch 6/50] [Batch 214/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736894]\n",
      "[Epoch 6/50] [Batch 215/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 216/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 217/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 218/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 219/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 220/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 221/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 222/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 223/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 224/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 225/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 226/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 227/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 228/342] [D loss: -0.051214, acc: 0.500000, f1: 0.074074] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 229/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 230/342] [D loss: -0.051215, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 231/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 232/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 233/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 234/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 235/342] [D loss: -0.051213, acc: 0.500000, f1: 0.074074] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 236/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 237/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 238/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 239/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 240/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 241/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 242/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 243/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 244/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 245/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 246/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 247/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 248/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 249/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 250/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 251/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 252/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 253/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 254/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 255/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 256/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 257/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 258/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 259/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 260/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 261/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 262/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 263/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 264/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 265/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 266/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 267/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 268/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 269/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 270/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 271/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 272/342] [D loss: -0.051213, acc: 0.500000, f1: 0.083333] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 273/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 274/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 275/342] [D loss: -0.051209, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 276/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 277/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 278/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 279/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 280/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 281/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 282/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 283/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 284/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 285/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 286/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 287/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 288/342] [D loss: -0.051215, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 289/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 290/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 291/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 292/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 293/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 294/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 295/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 296/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 297/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 298/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 299/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736890]\n",
      "[Epoch 6/50] [Batch 300/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 301/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 302/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 303/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 304/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 305/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 306/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 307/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 308/342] [D loss: -0.051211, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 309/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 310/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 311/342] [D loss: -0.051212, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 312/342] [D loss: -0.051212, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 313/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 314/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 315/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 316/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 317/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 318/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 319/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 320/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 321/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 322/342] [D loss: -0.051206, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 323/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736893]\n",
      "[Epoch 6/50] [Batch 324/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 325/342] [D loss: -0.051208, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 326/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 327/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 328/342] [D loss: -0.051213, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 329/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 330/342] [D loss: -0.051214, acc: 0.500000, f1: 0.066667] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 331/342] [D loss: -0.051214, acc: 0.500000, f1: 0.060606] [G loss: 0.736892]\n",
      "[Epoch 6/50] [Batch 332/342] [D loss: -0.051213, acc: 0.500000, f1: 0.066667] [G loss: 0.736891]\n",
      "[Epoch 6/50] [Batch 333/342] [D loss: -0.051216, acc: 0.500000, f1: 0.066667] [G loss: 0.736894]\n",
      "[Epoch 6/50] [Batch 334/342] [D loss: -0.051221, acc: 0.500000, f1: 0.066667] [G loss: 0.736897]\n",
      "[Epoch 6/50] [Batch 335/342] [D loss: -0.051225, acc: 0.500000, f1: 0.066667] [G loss: 0.736902]\n",
      "[Epoch 6/50] [Batch 336/342] [D loss: -0.051227, acc: 0.500000, f1: 0.060606] [G loss: 0.736904]\n",
      "[Epoch 6/50] [Batch 337/342] [D loss: -0.051230, acc: 0.500000, f1: 0.060606] [G loss: 0.736906]\n",
      "[Epoch 6/50] [Batch 338/342] [D loss: -0.051231, acc: 0.500000, f1: 0.066667] [G loss: 0.736906]\n",
      "[Epoch 6/50] [Batch 339/342] [D loss: -0.051232, acc: 0.500000, f1: 0.066667] [G loss: 0.736908]\n",
      "[Epoch 6/50] [Batch 340/342] [D loss: -0.051232, acc: 0.500000, f1: 0.066667] [G loss: 0.736908]\n",
      "[Epoch 6/50] [Batch 341/342] [D loss: -0.051233, acc: 0.500000, f1: 0.060606] [G loss: 0.736909]\n",
      "[Epoch 7/50] [Batch 0/342] [D loss: -0.051234, acc: 0.500000, f1: 0.066667] [G loss: 0.736910]\n",
      "[Epoch 7/50] [Batch 1/342] [D loss: -0.051234, acc: 0.500000, f1: 0.060606] [G loss: 0.736910]\n",
      "[Epoch 7/50] [Batch 2/342] [D loss: -0.051235, acc: 0.500000, f1: 0.066667] [G loss: 0.736909]\n",
      "[Epoch 7/50] [Batch 3/342] [D loss: -0.051236, acc: 0.500000, f1: 0.060606] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 4/342] [D loss: -0.051236, acc: 0.500000, f1: 0.066667] [G loss: 0.736911]\n",
      "[Epoch 7/50] [Batch 5/342] [D loss: -0.051235, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 6/342] [D loss: -0.051237, acc: 0.500000, f1: 0.066667] [G loss: 0.736911]\n",
      "[Epoch 7/50] [Batch 7/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736911]\n",
      "[Epoch 7/50] [Batch 8/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 9/342] [D loss: -0.051237, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 10/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 11/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 12/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 13/342] [D loss: -0.051237, acc: 0.500000, f1: 0.066667] [G loss: 0.736912]\n",
      "[Epoch 7/50] [Batch 14/342] [D loss: -0.051238, acc: 0.500000, f1: 0.060606] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 15/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 16/342] [D loss: -0.051240, acc: 0.500000, f1: 0.066667] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 17/342] [D loss: -0.051238, acc: 0.500000, f1: 0.074074] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 18/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 19/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 20/342] [D loss: -0.051238, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 21/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 22/342] [D loss: -0.051240, acc: 0.500000, f1: 0.066667] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 23/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 24/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 25/342] [D loss: -0.051239, acc: 0.500000, f1: 0.066667] [G loss: 0.736913]\n",
      "[Epoch 7/50] [Batch 26/342] [D loss: -0.051240, acc: 0.500000, f1: 0.066667] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 27/342] [D loss: -0.051242, acc: 0.500000, f1: 0.066667] [G loss: 0.736916]\n",
      "[Epoch 7/50] [Batch 28/342] [D loss: -0.051240, acc: 0.500000, f1: 0.060606] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 29/342] [D loss: -0.051239, acc: 0.500000, f1: 0.060606] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 30/342] [D loss: -0.051240, acc: 0.500000, f1: 0.066667] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 31/342] [D loss: -0.051241, acc: 0.500000, f1: 0.066667] [G loss: 0.736916]\n",
      "[Epoch 7/50] [Batch 32/342] [D loss: -0.051241, acc: 0.500000, f1: 0.060606] [G loss: 0.736914]\n",
      "[Epoch 7/50] [Batch 33/342] [D loss: -0.051241, acc: 0.500000, f1: 0.066667] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 34/342] [D loss: -0.051241, acc: 0.500000, f1: 0.060606] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 35/342] [D loss: -0.051242, acc: 0.500000, f1: 0.066667] [G loss: 0.736916]\n",
      "[Epoch 7/50] [Batch 36/342] [D loss: -0.051241, acc: 0.500000, f1: 0.060606] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 37/342] [D loss: -0.051241, acc: 0.500000, f1: 0.066667] [G loss: 0.736915]\n",
      "[Epoch 7/50] [Batch 38/342] [D loss: -0.051243, acc: 0.500000, f1: 0.060606] [G loss: 0.736917]\n",
      "[Epoch 7/50] [Batch 39/342] [D loss: -0.051244, acc: 0.500000, f1: 0.066667] [G loss: 0.736918]\n",
      "[Epoch 7/50] [Batch 40/342] [D loss: -0.051251, acc: 0.500000, f1: 0.066667] [G loss: 0.736924]\n",
      "[Epoch 7/50] [Batch 41/342] [D loss: -0.051255, acc: 0.500000, f1: 0.060606] [G loss: 0.736926]\n",
      "[Epoch 7/50] [Batch 42/342] [D loss: -0.051257, acc: 0.500000, f1: 0.066667] [G loss: 0.736929]\n",
      "[Epoch 7/50] [Batch 43/342] [D loss: -0.051258, acc: 0.500000, f1: 0.060606] [G loss: 0.736929]\n",
      "[Epoch 7/50] [Batch 44/342] [D loss: -0.051259, acc: 0.500000, f1: 0.060606] [G loss: 0.736931]\n",
      "[Epoch 7/50] [Batch 45/342] [D loss: -0.051261, acc: 0.500000, f1: 0.074074] [G loss: 0.736933]\n",
      "[Epoch 7/50] [Batch 46/342] [D loss: -0.051261, acc: 0.500000, f1: 0.060606] [G loss: 0.736934]\n",
      "[Epoch 7/50] [Batch 47/342] [D loss: -0.051262, acc: 0.500000, f1: 0.060606] [G loss: 0.736933]\n",
      "[Epoch 7/50] [Batch 48/342] [D loss: -0.051264, acc: 0.500000, f1: 0.060606] [G loss: 0.736934]\n",
      "[Epoch 7/50] [Batch 49/342] [D loss: -0.051265, acc: 0.500000, f1: 0.066667] [G loss: 0.736936]\n",
      "[Epoch 7/50] [Batch 50/342] [D loss: -0.051264, acc: 0.500000, f1: 0.066667] [G loss: 0.736936]\n",
      "[Epoch 7/50] [Batch 51/342] [D loss: -0.051264, acc: 0.500000, f1: 0.060606] [G loss: 0.736935]\n",
      "[Epoch 7/50] [Batch 52/342] [D loss: -0.051264, acc: 0.500000, f1: 0.060606] [G loss: 0.736935]\n",
      "[Epoch 7/50] [Batch 53/342] [D loss: -0.051266, acc: 0.500000, f1: 0.066667] [G loss: 0.736937]\n",
      "[Epoch 7/50] [Batch 54/342] [D loss: -0.051265, acc: 0.500000, f1: 0.060606] [G loss: 0.736936]\n",
      "[Epoch 7/50] [Batch 55/342] [D loss: -0.051266, acc: 0.500000, f1: 0.066667] [G loss: 0.736936]\n",
      "[Epoch 7/50] [Batch 56/342] [D loss: -0.051266, acc: 0.500000, f1: 0.066667] [G loss: 0.736938]\n",
      "[Epoch 7/50] [Batch 57/342] [D loss: -0.051267, acc: 0.500000, f1: 0.066667] [G loss: 0.736938]\n",
      "[Epoch 7/50] [Batch 58/342] [D loss: -0.051267, acc: 0.500000, f1: 0.066667] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 59/342] [D loss: -0.051267, acc: 0.500000, f1: 0.066667] [G loss: 0.736938]\n",
      "[Epoch 7/50] [Batch 60/342] [D loss: -0.051267, acc: 0.500000, f1: 0.066667] [G loss: 0.736938]\n",
      "[Epoch 7/50] [Batch 61/342] [D loss: -0.051268, acc: 0.500000, f1: 0.060606] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 62/342] [D loss: -0.051266, acc: 0.500000, f1: 0.066667] [G loss: 0.736938]\n",
      "[Epoch 7/50] [Batch 63/342] [D loss: -0.051267, acc: 0.500000, f1: 0.066667] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 64/342] [D loss: -0.051270, acc: 0.500000, f1: 0.066667] [G loss: 0.736940]\n",
      "[Epoch 7/50] [Batch 65/342] [D loss: -0.051269, acc: 0.500000, f1: 0.066667] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 66/342] [D loss: -0.051270, acc: 0.500000, f1: 0.066667] [G loss: 0.736942]\n",
      "[Epoch 7/50] [Batch 67/342] [D loss: -0.051270, acc: 0.500000, f1: 0.060606] [G loss: 0.736940]\n",
      "[Epoch 7/50] [Batch 68/342] [D loss: -0.051268, acc: 0.500000, f1: 0.066667] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 69/342] [D loss: -0.051270, acc: 0.500000, f1: 0.066667] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 70/342] [D loss: -0.051271, acc: 0.500000, f1: 0.060606] [G loss: 0.736942]\n",
      "[Epoch 7/50] [Batch 71/342] [D loss: -0.051270, acc: 0.500000, f1: 0.066667] [G loss: 0.736939]\n",
      "[Epoch 7/50] [Batch 72/342] [D loss: -0.051270, acc: 0.500000, f1: 0.066667] [G loss: 0.736940]\n",
      "[Epoch 7/50] [Batch 73/342] [D loss: -0.051271, acc: 0.500000, f1: 0.060606] [G loss: 0.736940]\n",
      "[Epoch 7/50] [Batch 74/342] [D loss: -0.051271, acc: 0.500000, f1: 0.060606] [G loss: 0.736940]\n",
      "[Epoch 7/50] [Batch 75/342] [D loss: -0.051257, acc: 0.500000, f1: 0.066667] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 76/342] [D loss: -0.051271, acc: 0.500000, f1: 0.066667] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 77/342] [D loss: -0.051271, acc: 0.500000, f1: 0.066667] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 78/342] [D loss: -0.051271, acc: 0.500000, f1: 0.060606] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 79/342] [D loss: -0.051273, acc: 0.500000, f1: 0.060606] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 80/342] [D loss: -0.051272, acc: 0.500000, f1: 0.066667] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 81/342] [D loss: -0.051271, acc: 0.500000, f1: 0.066667] [G loss: 0.736942]\n",
      "[Epoch 7/50] [Batch 82/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 83/342] [D loss: -0.051271, acc: 0.500000, f1: 0.060606] [G loss: 0.736941]\n",
      "[Epoch 7/50] [Batch 84/342] [D loss: -0.051273, acc: 0.500000, f1: 0.066667] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 85/342] [D loss: -0.051273, acc: 0.500000, f1: 0.066667] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 86/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 87/342] [D loss: -0.051273, acc: 0.500000, f1: 0.066667] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 88/342] [D loss: -0.051273, acc: 0.500000, f1: 0.074074] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 89/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 90/342] [D loss: -0.051273, acc: 0.500000, f1: 0.060606] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 91/342] [D loss: -0.051273, acc: 0.500000, f1: 0.066667] [G loss: 0.736943]\n",
      "[Epoch 7/50] [Batch 92/342] [D loss: -0.051274, acc: 0.500000, f1: 0.060606] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 93/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 94/342] [D loss: -0.051275, acc: 0.500000, f1: 0.074074] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 95/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 96/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 97/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 98/342] [D loss: -0.051274, acc: 0.500000, f1: 0.060606] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 99/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 100/342] [D loss: -0.051276, acc: 0.500000, f1: 0.066667] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 101/342] [D loss: -0.051274, acc: 0.500000, f1: 0.060606] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 102/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 103/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 104/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 105/342] [D loss: -0.051275, acc: 0.500000, f1: 0.060606] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 106/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 107/342] [D loss: -0.051275, acc: 0.500000, f1: 0.066667] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 108/342] [D loss: -0.051277, acc: 0.500000, f1: 0.066667] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 109/342] [D loss: -0.051276, acc: 0.500000, f1: 0.060606] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 110/342] [D loss: -0.051274, acc: 0.500000, f1: 0.066667] [G loss: 0.736944]\n",
      "[Epoch 7/50] [Batch 111/342] [D loss: -0.051276, acc: 0.500000, f1: 0.066667] [G loss: 0.736947]\n",
      "[Epoch 7/50] [Batch 112/342] [D loss: -0.051277, acc: 0.500000, f1: 0.060606] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 113/342] [D loss: -0.051275, acc: 0.500000, f1: 0.060606] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 114/342] [D loss: -0.051277, acc: 0.500000, f1: 0.066667] [G loss: 0.736947]\n",
      "[Epoch 7/50] [Batch 115/342] [D loss: -0.051277, acc: 0.500000, f1: 0.066667] [G loss: 0.736947]\n",
      "[Epoch 7/50] [Batch 116/342] [D loss: -0.051276, acc: 0.500000, f1: 0.066667] [G loss: 0.736946]\n",
      "[Epoch 7/50] [Batch 117/342] [D loss: -0.051277, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 118/342] [D loss: -0.051276, acc: 0.500000, f1: 0.074074] [G loss: 0.736945]\n",
      "[Epoch 7/50] [Batch 119/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 120/342] [D loss: -0.051278, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 121/342] [D loss: -0.051278, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 122/342] [D loss: -0.051278, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 123/342] [D loss: -0.051277, acc: 0.500000, f1: 0.066667] [G loss: 0.736947]\n",
      "[Epoch 7/50] [Batch 124/342] [D loss: -0.051278, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 125/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736947]\n",
      "[Epoch 7/50] [Batch 126/342] [D loss: -0.051279, acc: 0.500000, f1: 0.060606] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 127/342] [D loss: -0.051279, acc: 0.500000, f1: 0.074074] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 128/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 129/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 130/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 131/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 132/342] [D loss: -0.051278, acc: 0.500000, f1: 0.066667] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 133/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 134/342] [D loss: -0.051279, acc: 0.500000, f1: 0.060606] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 135/342] [D loss: -0.051279, acc: 0.500000, f1: 0.060606] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 136/342] [D loss: -0.051279, acc: 0.500000, f1: 0.066667] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 137/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736948]\n",
      "[Epoch 7/50] [Batch 138/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 139/342] [D loss: -0.051280, acc: 0.500000, f1: 0.060606] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 140/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 141/342] [D loss: -0.051281, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 142/342] [D loss: -0.051281, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 143/342] [D loss: -0.051280, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 144/342] [D loss: -0.051281, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 145/342] [D loss: -0.051281, acc: 0.500000, f1: 0.060606] [G loss: 0.736951]\n",
      "[Epoch 7/50] [Batch 146/342] [D loss: -0.051282, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 147/342] [D loss: -0.051281, acc: 0.500000, f1: 0.060606] [G loss: 0.736949]\n",
      "[Epoch 7/50] [Batch 148/342] [D loss: -0.051282, acc: 0.500000, f1: 0.060606] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 149/342] [D loss: -0.051283, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 150/342] [D loss: -0.051283, acc: 0.500000, f1: 0.066667] [G loss: 0.736951]\n",
      "[Epoch 7/50] [Batch 151/342] [D loss: -0.051282, acc: 0.500000, f1: 0.060606] [G loss: 0.736951]\n",
      "[Epoch 7/50] [Batch 152/342] [D loss: -0.051281, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 153/342] [D loss: -0.051281, acc: 0.500000, f1: 0.066667] [G loss: 0.736951]\n",
      "[Epoch 7/50] [Batch 154/342] [D loss: -0.051282, acc: 0.500000, f1: 0.066667] [G loss: 0.736950]\n",
      "[Epoch 7/50] [Batch 155/342] [D loss: -0.051283, acc: 0.500000, f1: 0.066667] [G loss: 0.736951]\n",
      "[Epoch 7/50] [Batch 156/342] [D loss: -0.051283, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 157/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 158/342] [D loss: -0.051283, acc: 0.500000, f1: 0.060606] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 159/342] [D loss: -0.051283, acc: 0.500000, f1: 0.060606] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 160/342] [D loss: -0.051283, acc: 0.500000, f1: 0.060606] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 161/342] [D loss: -0.051285, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 162/342] [D loss: -0.051284, acc: 0.500000, f1: 0.060606] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 163/342] [D loss: -0.051285, acc: 0.500000, f1: 0.066667] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 164/342] [D loss: -0.051285, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 165/342] [D loss: -0.051283, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 166/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 167/342] [D loss: -0.051283, acc: 0.500000, f1: 0.060606] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 168/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736952]\n",
      "[Epoch 7/50] [Batch 169/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 170/342] [D loss: -0.051286, acc: 0.500000, f1: 0.066667] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 171/342] [D loss: -0.051286, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 172/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 173/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 174/342] [D loss: -0.051284, acc: 0.500000, f1: 0.060606] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 175/342] [D loss: -0.051284, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 176/342] [D loss: -0.051285, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 177/342] [D loss: -0.051286, acc: 0.500000, f1: 0.060606] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 178/342] [D loss: -0.051286, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 179/342] [D loss: -0.051286, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 180/342] [D loss: -0.051286, acc: 0.500000, f1: 0.060606] [G loss: 0.736953]\n",
      "[Epoch 7/50] [Batch 181/342] [D loss: -0.051287, acc: 0.500000, f1: 0.060606] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 182/342] [D loss: -0.051287, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 183/342] [D loss: -0.051289, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 184/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736954]\n",
      "[Epoch 7/50] [Batch 185/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 186/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 187/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 188/342] [D loss: -0.051287, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 189/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 190/342] [D loss: -0.051288, acc: 0.500000, f1: 0.060606] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 191/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 192/342] [D loss: -0.051289, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 193/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 194/342] [D loss: -0.051289, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 195/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 196/342] [D loss: -0.051286, acc: 0.500000, f1: 0.066667] [G loss: 0.736955]\n",
      "[Epoch 7/50] [Batch 197/342] [D loss: -0.051289, acc: 0.500000, f1: 0.060606] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 198/342] [D loss: -0.051288, acc: 0.500000, f1: 0.060606] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 199/342] [D loss: -0.051288, acc: 0.500000, f1: 0.066667] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 200/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 201/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 202/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 203/342] [D loss: -0.051290, acc: 0.500000, f1: 0.060606] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 204/342] [D loss: -0.051289, acc: 0.500000, f1: 0.066667] [G loss: 0.736956]\n",
      "[Epoch 7/50] [Batch 205/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736957]\n",
      "[Epoch 7/50] [Batch 206/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 207/342] [D loss: -0.051290, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 208/342] [D loss: -0.051291, acc: 0.500000, f1: 0.060606] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 209/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 210/342] [D loss: -0.051291, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 211/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 212/342] [D loss: -0.051282, acc: 0.500000, f1: 0.060606] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 213/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 214/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 215/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 216/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 217/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 218/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 219/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 220/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 221/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 222/342] [D loss: -0.051291, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 223/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 224/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 225/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 226/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736958]\n",
      "[Epoch 7/50] [Batch 227/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 228/342] [D loss: -0.051293, acc: 0.500000, f1: 0.060606] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 229/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 230/342] [D loss: -0.051293, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 231/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 232/342] [D loss: -0.051293, acc: 0.500000, f1: 0.060606] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 233/342] [D loss: -0.051291, acc: 0.500000, f1: 0.066667] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 234/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 235/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 236/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 237/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 238/342] [D loss: -0.051292, acc: 0.500000, f1: 0.060606] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 239/342] [D loss: -0.051293, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 240/342] [D loss: -0.051294, acc: 0.500000, f1: 0.066667] [G loss: 0.736961]\n",
      "[Epoch 7/50] [Batch 241/342] [D loss: -0.051287, acc: 0.500000, f1: 0.066667] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 242/342] [D loss: -0.051292, acc: 0.500000, f1: 0.066667] [G loss: 0.736959]\n",
      "[Epoch 7/50] [Batch 243/342] [D loss: -0.051294, acc: 0.500000, f1: 0.066667] [G loss: 0.736961]\n",
      "[Epoch 7/50] [Batch 244/342] [D loss: -0.051293, acc: 0.500000, f1: 0.066667] [G loss: 0.736962]\n",
      "[Epoch 7/50] [Batch 245/342] [D loss: -0.051293, acc: 0.500000, f1: 0.060606] [G loss: 0.736960]\n",
      "[Epoch 7/50] [Batch 246/342] [D loss: -0.051294, acc: 0.500000, f1: 0.066667] [G loss: 0.736961]\n",
      "[Epoch 7/50] [Batch 247/342] [D loss: -0.051296, acc: 0.500000, f1: 0.060606] [G loss: 0.736963]\n",
      "[Epoch 7/50] [Batch 248/342] [D loss: -0.051302, acc: 0.500000, f1: 0.060606] [G loss: 0.736968]\n",
      "[Epoch 7/50] [Batch 249/342] [D loss: -0.051305, acc: 0.500000, f1: 0.060606] [G loss: 0.736971]\n",
      "[Epoch 7/50] [Batch 250/342] [D loss: -0.051308, acc: 0.500000, f1: 0.066667] [G loss: 0.736973]\n",
      "[Epoch 7/50] [Batch 251/342] [D loss: -0.051310, acc: 0.500000, f1: 0.060606] [G loss: 0.736974]\n",
      "[Epoch 7/50] [Batch 252/342] [D loss: -0.051313, acc: 0.500000, f1: 0.060606] [G loss: 0.736977]\n",
      "[Epoch 7/50] [Batch 253/342] [D loss: -0.051313, acc: 0.500000, f1: 0.066667] [G loss: 0.736977]\n",
      "[Epoch 7/50] [Batch 254/342] [D loss: -0.051314, acc: 0.500000, f1: 0.066667] [G loss: 0.736978]\n",
      "[Epoch 7/50] [Batch 255/342] [D loss: -0.051314, acc: 0.500000, f1: 0.066667] [G loss: 0.736979]\n",
      "[Epoch 7/50] [Batch 256/342] [D loss: -0.051315, acc: 0.500000, f1: 0.066667] [G loss: 0.736979]\n",
      "[Epoch 7/50] [Batch 257/342] [D loss: -0.051315, acc: 0.500000, f1: 0.066667] [G loss: 0.736980]\n",
      "[Epoch 7/50] [Batch 258/342] [D loss: -0.051316, acc: 0.500000, f1: 0.060606] [G loss: 0.736980]\n",
      "[Epoch 7/50] [Batch 259/342] [D loss: -0.051317, acc: 0.500000, f1: 0.074074] [G loss: 0.736981]\n",
      "[Epoch 7/50] [Batch 260/342] [D loss: -0.051319, acc: 0.500000, f1: 0.066667] [G loss: 0.736982]\n",
      "[Epoch 7/50] [Batch 261/342] [D loss: -0.051319, acc: 0.500000, f1: 0.066667] [G loss: 0.736981]\n",
      "[Epoch 7/50] [Batch 262/342] [D loss: -0.051318, acc: 0.500000, f1: 0.060606] [G loss: 0.736981]\n",
      "[Epoch 7/50] [Batch 263/342] [D loss: -0.051320, acc: 0.500000, f1: 0.060606] [G loss: 0.736982]\n",
      "[Epoch 7/50] [Batch 264/342] [D loss: -0.051320, acc: 0.500000, f1: 0.066667] [G loss: 0.736984]\n",
      "[Epoch 7/50] [Batch 265/342] [D loss: -0.051320, acc: 0.500000, f1: 0.066667] [G loss: 0.736983]\n",
      "[Epoch 7/50] [Batch 266/342] [D loss: -0.051321, acc: 0.500000, f1: 0.060606] [G loss: 0.736984]\n",
      "[Epoch 7/50] [Batch 267/342] [D loss: -0.051319, acc: 0.500000, f1: 0.066667] [G loss: 0.736982]\n",
      "[Epoch 7/50] [Batch 268/342] [D loss: -0.051320, acc: 0.500000, f1: 0.066667] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 269/342] [D loss: -0.051319, acc: 0.500000, f1: 0.060606] [G loss: 0.736982]\n",
      "[Epoch 7/50] [Batch 270/342] [D loss: -0.051320, acc: 0.500000, f1: 0.066667] [G loss: 0.736983]\n",
      "[Epoch 7/50] [Batch 271/342] [D loss: -0.051321, acc: 0.500000, f1: 0.066667] [G loss: 0.736983]\n",
      "[Epoch 7/50] [Batch 272/342] [D loss: -0.051321, acc: 0.500000, f1: 0.060606] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 273/342] [D loss: -0.051321, acc: 0.500000, f1: 0.066667] [G loss: 0.736984]\n",
      "[Epoch 7/50] [Batch 274/342] [D loss: -0.051321, acc: 0.500000, f1: 0.060606] [G loss: 0.736983]\n",
      "[Epoch 7/50] [Batch 275/342] [D loss: -0.051322, acc: 0.500000, f1: 0.066667] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 276/342] [D loss: -0.051322, acc: 0.500000, f1: 0.066667] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 277/342] [D loss: -0.051322, acc: 0.500000, f1: 0.066667] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 278/342] [D loss: -0.051323, acc: 0.500000, f1: 0.066667] [G loss: 0.736985]\n",
      "[Epoch 7/50] [Batch 279/342] [D loss: -0.051309, acc: 0.500000, f1: 0.066667] [G loss: 0.736988]\n",
      "[Epoch 7/50] [Batch 280/342] [D loss: -0.051330, acc: 0.500000, f1: 0.066667] [G loss: 0.736992]\n",
      "[Epoch 7/50] [Batch 281/342] [D loss: -0.051334, acc: 0.500000, f1: 0.060606] [G loss: 0.736995]\n",
      "[Epoch 7/50] [Batch 282/342] [D loss: -0.051337, acc: 0.500000, f1: 0.066667] [G loss: 0.736997]\n",
      "[Epoch 7/50] [Batch 283/342] [D loss: -0.051339, acc: 0.500000, f1: 0.060606] [G loss: 0.736999]\n",
      "[Epoch 7/50] [Batch 284/342] [D loss: -0.051340, acc: 0.500000, f1: 0.066667] [G loss: 0.737000]\n",
      "[Epoch 7/50] [Batch 285/342] [D loss: -0.051342, acc: 0.500000, f1: 0.060606] [G loss: 0.737002]\n",
      "[Epoch 7/50] [Batch 286/342] [D loss: -0.051343, acc: 0.500000, f1: 0.066667] [G loss: 0.737002]\n",
      "[Epoch 7/50] [Batch 287/342] [D loss: -0.051344, acc: 0.500000, f1: 0.060606] [G loss: 0.737003]\n",
      "[Epoch 7/50] [Batch 288/342] [D loss: -0.051343, acc: 0.500000, f1: 0.066667] [G loss: 0.737003]\n",
      "[Epoch 7/50] [Batch 289/342] [D loss: -0.051344, acc: 0.500000, f1: 0.066667] [G loss: 0.737003]\n",
      "[Epoch 7/50] [Batch 290/342] [D loss: -0.051345, acc: 0.500000, f1: 0.066667] [G loss: 0.737004]\n",
      "[Epoch 7/50] [Batch 291/342] [D loss: -0.051346, acc: 0.500000, f1: 0.066667] [G loss: 0.737004]\n",
      "[Epoch 7/50] [Batch 292/342] [D loss: -0.051348, acc: 0.500000, f1: 0.060606] [G loss: 0.737006]\n",
      "[Epoch 7/50] [Batch 293/342] [D loss: -0.051346, acc: 0.500000, f1: 0.066667] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 294/342] [D loss: -0.051347, acc: 0.500000, f1: 0.060606] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 295/342] [D loss: -0.051348, acc: 0.500000, f1: 0.060606] [G loss: 0.737006]\n",
      "[Epoch 7/50] [Batch 296/342] [D loss: -0.051347, acc: 0.500000, f1: 0.060606] [G loss: 0.737006]\n",
      "[Epoch 7/50] [Batch 297/342] [D loss: -0.051347, acc: 0.500000, f1: 0.060606] [G loss: 0.737006]\n",
      "[Epoch 7/50] [Batch 298/342] [D loss: -0.051347, acc: 0.500000, f1: 0.066667] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 299/342] [D loss: -0.051349, acc: 0.500000, f1: 0.066667] [G loss: 0.737008]\n",
      "[Epoch 7/50] [Batch 300/342] [D loss: -0.051348, acc: 0.500000, f1: 0.066667] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 301/342] [D loss: -0.051348, acc: 0.500000, f1: 0.066667] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 302/342] [D loss: -0.051348, acc: 0.500000, f1: 0.060606] [G loss: 0.737007]\n",
      "[Epoch 7/50] [Batch 303/342] [D loss: -0.051350, acc: 0.500000, f1: 0.066667] [G loss: 0.737008]\n",
      "[Epoch 7/50] [Batch 304/342] [D loss: -0.051351, acc: 0.500000, f1: 0.066667] [G loss: 0.737009]\n",
      "[Epoch 7/50] [Batch 305/342] [D loss: -0.051349, acc: 0.500000, f1: 0.066667] [G loss: 0.737008]\n",
      "[Epoch 7/50] [Batch 306/342] [D loss: -0.051351, acc: 0.500000, f1: 0.066667] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 307/342] [D loss: -0.051350, acc: 0.500000, f1: 0.066667] [G loss: 0.737009]\n",
      "[Epoch 7/50] [Batch 308/342] [D loss: -0.051348, acc: 0.500000, f1: 0.074074] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 309/342] [D loss: -0.051350, acc: 0.500000, f1: 0.066667] [G loss: 0.737008]\n",
      "[Epoch 7/50] [Batch 310/342] [D loss: -0.051352, acc: 0.500000, f1: 0.066667] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 311/342] [D loss: -0.051352, acc: 0.500000, f1: 0.066667] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 312/342] [D loss: -0.051353, acc: 0.500000, f1: 0.060606] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 313/342] [D loss: -0.051352, acc: 0.500000, f1: 0.066667] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 314/342] [D loss: -0.051351, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 315/342] [D loss: -0.051352, acc: 0.500000, f1: 0.066667] [G loss: 0.737010]\n",
      "[Epoch 7/50] [Batch 316/342] [D loss: -0.051351, acc: 0.500000, f1: 0.060606] [G loss: 0.737009]\n",
      "[Epoch 7/50] [Batch 317/342] [D loss: -0.051353, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 318/342] [D loss: -0.051352, acc: 0.500000, f1: 0.060606] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 319/342] [D loss: -0.051353, acc: 0.500000, f1: 0.060606] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 320/342] [D loss: -0.051354, acc: 0.500000, f1: 0.060606] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 321/342] [D loss: -0.051354, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 322/342] [D loss: -0.051348, acc: 0.500000, f1: 0.060606] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 323/342] [D loss: -0.051355, acc: 0.500000, f1: 0.060606] [G loss: 0.737012]\n",
      "[Epoch 7/50] [Batch 324/342] [D loss: -0.051354, acc: 0.500000, f1: 0.060606] [G loss: 0.737012]\n",
      "[Epoch 7/50] [Batch 325/342] [D loss: -0.051354, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 326/342] [D loss: -0.051348, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 327/342] [D loss: -0.051353, acc: 0.500000, f1: 0.066667] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 328/342] [D loss: -0.051355, acc: 0.500000, f1: 0.060606] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 329/342] [D loss: -0.051354, acc: 0.500000, f1: 0.066667] [G loss: 0.737012]\n",
      "[Epoch 7/50] [Batch 330/342] [D loss: -0.051354, acc: 0.500000, f1: 0.060606] [G loss: 0.737011]\n",
      "[Epoch 7/50] [Batch 331/342] [D loss: -0.051354, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 332/342] [D loss: -0.051355, acc: 0.500000, f1: 0.066667] [G loss: 0.737012]\n",
      "[Epoch 7/50] [Batch 333/342] [D loss: -0.051354, acc: 0.500000, f1: 0.060606] [G loss: 0.737012]\n",
      "[Epoch 7/50] [Batch 334/342] [D loss: -0.051355, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 335/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 7/50] [Batch 336/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 7/50] [Batch 337/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 338/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 7/50] [Batch 339/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 340/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 7/50] [Batch 341/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 8/50] [Batch 0/342] [D loss: -0.051356, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 8/50] [Batch 1/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 8/50] [Batch 2/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737014]\n",
      "[Epoch 8/50] [Batch 3/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 4/342] [D loss: -0.051340, acc: 0.500000, f1: 0.066667] [G loss: 0.737013]\n",
      "[Epoch 8/50] [Batch 5/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 6/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 7/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 8/342] [D loss: -0.051357, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 9/342] [D loss: -0.051358, acc: 0.500000, f1: 0.060606] [G loss: 0.737014]\n",
      "[Epoch 8/50] [Batch 10/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 11/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 12/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 13/342] [D loss: -0.051357, acc: 0.500000, f1: 0.060606] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 14/342] [D loss: -0.051358, acc: 0.500000, f1: 0.074074] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 15/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 16/342] [D loss: -0.051352, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 17/342] [D loss: -0.051360, acc: 0.500000, f1: 0.060606] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 18/342] [D loss: -0.051360, acc: 0.500000, f1: 0.066667] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 19/342] [D loss: -0.051358, acc: 0.500000, f1: 0.066667] [G loss: 0.737018]\n",
      "[Epoch 8/50] [Batch 20/342] [D loss: -0.051359, acc: 0.500000, f1: 0.066667] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 21/342] [D loss: -0.051359, acc: 0.500000, f1: 0.066667] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 22/342] [D loss: -0.051358, acc: 0.500000, f1: 0.060606] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 23/342] [D loss: -0.051360, acc: 0.500000, f1: 0.066667] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 24/342] [D loss: -0.051359, acc: 0.500000, f1: 0.066667] [G loss: 0.737015]\n",
      "[Epoch 8/50] [Batch 25/342] [D loss: -0.051359, acc: 0.500000, f1: 0.060606] [G loss: 0.737016]\n",
      "[Epoch 8/50] [Batch 26/342] [D loss: -0.051360, acc: 0.500000, f1: 0.066667] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 27/342] [D loss: -0.051361, acc: 0.500000, f1: 0.060606] [G loss: 0.737018]\n",
      "[Epoch 8/50] [Batch 28/342] [D loss: -0.051360, acc: 0.500000, f1: 0.060606] [G loss: 0.737017]\n",
      "[Epoch 8/50] [Batch 29/342] [D loss: -0.051362, acc: 0.500000, f1: 0.066667] [G loss: 0.737018]\n",
      "[Epoch 8/50] [Batch 30/342] [D loss: -0.051360, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 31/342] [D loss: -0.051362, acc: 0.500000, f1: 0.060606] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 32/342] [D loss: -0.051362, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 33/342] [D loss: -0.051362, acc: 0.500000, f1: 0.060606] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 34/342] [D loss: -0.051362, acc: 0.500000, f1: 0.074074] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 35/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 36/342] [D loss: -0.051361, acc: 0.500000, f1: 0.060606] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 37/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 38/342] [D loss: -0.051364, acc: 0.500000, f1: 0.060606] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 39/342] [D loss: -0.051362, acc: 0.500000, f1: 0.066667] [G loss: 0.737018]\n",
      "[Epoch 8/50] [Batch 40/342] [D loss: -0.051362, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 41/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 42/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 43/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 44/342] [D loss: -0.051364, acc: 0.500000, f1: 0.060606] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 45/342] [D loss: -0.051362, acc: 0.500000, f1: 0.060606] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 46/342] [D loss: -0.051362, acc: 0.500000, f1: 0.060606] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 47/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737019]\n",
      "[Epoch 8/50] [Batch 48/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 49/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 50/342] [D loss: -0.051364, acc: 0.500000, f1: 0.074074] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 51/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 52/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 53/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 54/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737020]\n",
      "[Epoch 8/50] [Batch 55/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 56/342] [D loss: -0.051365, acc: 0.500000, f1: 0.060606] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 57/342] [D loss: -0.051363, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 58/342] [D loss: -0.051367, acc: 0.500000, f1: 0.060606] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 59/342] [D loss: -0.051366, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 60/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 61/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 62/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 63/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 64/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 65/342] [D loss: -0.051366, acc: 0.500000, f1: 0.066667] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 66/342] [D loss: -0.051366, acc: 0.500000, f1: 0.060606] [G loss: 0.737021]\n",
      "[Epoch 8/50] [Batch 67/342] [D loss: -0.051367, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 68/342] [D loss: -0.051367, acc: 0.500000, f1: 0.066667] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 69/342] [D loss: -0.051367, acc: 0.500000, f1: 0.066667] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 70/342] [D loss: -0.051367, acc: 0.500000, f1: 0.060606] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 71/342] [D loss: -0.051366, acc: 0.500000, f1: 0.060606] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 72/342] [D loss: -0.051366, acc: 0.500000, f1: 0.060606] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 73/342] [D loss: -0.051366, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 74/342] [D loss: -0.051366, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 75/342] [D loss: -0.051367, acc: 0.500000, f1: 0.066667] [G loss: 0.737022]\n",
      "[Epoch 8/50] [Batch 76/342] [D loss: -0.051369, acc: 0.500000, f1: 0.060606] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 77/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 78/342] [D loss: -0.051368, acc: 0.500000, f1: 0.066667] [G loss: 0.737023]\n",
      "[Epoch 8/50] [Batch 79/342] [D loss: -0.051369, acc: 0.500000, f1: 0.066667] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 80/342] [D loss: -0.051369, acc: 0.500000, f1: 0.060606] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 81/342] [D loss: -0.051368, acc: 0.500000, f1: 0.066667] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 82/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 83/342] [D loss: -0.051369, acc: 0.500000, f1: 0.060606] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 84/342] [D loss: -0.051369, acc: 0.500000, f1: 0.066667] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 85/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 86/342] [D loss: -0.051370, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 87/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 88/342] [D loss: -0.051368, acc: 0.500000, f1: 0.066667] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 89/342] [D loss: -0.051370, acc: 0.500000, f1: 0.066667] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 90/342] [D loss: -0.051370, acc: 0.500000, f1: 0.060606] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 91/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737024]\n",
      "[Epoch 8/50] [Batch 92/342] [D loss: -0.051368, acc: 0.500000, f1: 0.066667] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 93/342] [D loss: -0.051369, acc: 0.500000, f1: 0.066667] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 94/342] [D loss: -0.051370, acc: 0.500000, f1: 0.060606] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 95/342] [D loss: -0.051369, acc: 0.500000, f1: 0.066667] [G loss: 0.737025]\n",
      "[Epoch 8/50] [Batch 96/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737027]\n",
      "[Epoch 8/50] [Batch 97/342] [D loss: -0.051370, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 98/342] [D loss: -0.051370, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 99/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 100/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737027]\n",
      "[Epoch 8/50] [Batch 101/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 102/342] [D loss: -0.051371, acc: 0.500000, f1: 0.074074] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 103/342] [D loss: -0.051371, acc: 0.500000, f1: 0.074074] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 104/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737026]\n",
      "[Epoch 8/50] [Batch 105/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737027]\n",
      "[Epoch 8/50] [Batch 106/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 107/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 108/342] [D loss: -0.051373, acc: 0.500000, f1: 0.074074] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 109/342] [D loss: -0.051373, acc: 0.500000, f1: 0.066667] [G loss: 0.737027]\n",
      "[Epoch 8/50] [Batch 110/342] [D loss: -0.051373, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 111/342] [D loss: -0.051373, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 112/342] [D loss: -0.051373, acc: 0.500000, f1: 0.066667] [G loss: 0.737027]\n",
      "[Epoch 8/50] [Batch 113/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 114/342] [D loss: -0.051373, acc: 0.500000, f1: 0.060606] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 115/342] [D loss: -0.051374, acc: 0.500000, f1: 0.060606] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 116/342] [D loss: -0.051374, acc: 0.500000, f1: 0.060606] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 117/342] [D loss: -0.051373, acc: 0.500000, f1: 0.066667] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 118/342] [D loss: -0.051373, acc: 0.500000, f1: 0.060606] [G loss: 0.737028]\n",
      "[Epoch 8/50] [Batch 119/342] [D loss: -0.051373, acc: 0.500000, f1: 0.060606] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 120/342] [D loss: -0.051375, acc: 0.500000, f1: 0.060606] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 121/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 122/342] [D loss: -0.051375, acc: 0.500000, f1: 0.074074] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 123/342] [D loss: -0.051374, acc: 0.500000, f1: 0.060606] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 124/342] [D loss: -0.051374, acc: 0.500000, f1: 0.060606] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 125/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 126/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 127/342] [D loss: -0.051375, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 128/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 129/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 130/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 131/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 132/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 133/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 134/342] [D loss: -0.051375, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 135/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 136/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737029]\n",
      "[Epoch 8/50] [Batch 137/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 138/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 139/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 140/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 141/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 142/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 143/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 144/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 145/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 146/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 147/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 148/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 8/50] [Batch 149/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 150/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 151/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 152/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 153/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 154/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 155/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 156/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 157/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 158/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 159/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 160/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 161/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 162/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 163/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 164/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 165/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 166/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 167/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 168/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 169/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 170/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 171/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 172/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 173/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 174/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 175/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 176/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 177/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 178/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 179/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 180/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 181/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 182/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 183/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 184/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 185/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 186/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 187/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 188/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 189/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 190/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 191/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 192/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 193/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 194/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 195/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 196/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 197/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 198/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 199/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 200/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 201/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 202/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 203/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 204/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 205/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 206/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 207/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 208/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 209/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 210/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 211/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 212/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 213/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 214/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 215/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 216/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 217/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 218/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 219/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 220/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 221/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 222/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 223/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 224/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 225/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 226/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 227/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 228/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 229/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 230/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 231/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 232/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 233/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 234/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 235/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 236/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 237/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 238/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 239/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 240/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 241/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 242/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 243/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 244/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 245/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 246/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 247/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 248/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 249/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 250/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 251/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 252/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 253/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 254/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 255/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 256/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 257/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 258/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 259/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 260/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 261/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 262/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 263/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 264/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 265/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 266/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 267/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 268/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 269/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 270/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 271/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 272/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 273/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 274/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 275/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 276/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 277/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 278/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 279/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 280/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 281/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 282/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 283/342] [D loss: -0.051370, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 284/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 285/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 286/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 287/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 288/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 289/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 290/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 291/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 292/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 293/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 294/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 295/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 296/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 297/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 298/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 299/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 300/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 301/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 302/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 303/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 304/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 305/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 306/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 307/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 308/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 309/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 310/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 311/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 312/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 313/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 314/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 315/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 316/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 317/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 318/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 319/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 320/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 321/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 322/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 323/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 324/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 325/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 326/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 327/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 328/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 329/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 330/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 331/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 332/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 333/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 334/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 335/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 8/50] [Batch 336/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 337/342] [D loss: -0.051362, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 338/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 8/50] [Batch 339/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 340/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 8/50] [Batch 341/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 0/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 9/50] [Batch 1/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 2/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 3/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 4/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 5/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 6/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 7/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 8/342] [D loss: -0.051380, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 9/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 10/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 11/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 12/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 13/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 14/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 15/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 16/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 17/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 18/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 19/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 9/50] [Batch 20/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 21/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 22/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 23/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 24/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 25/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 26/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 27/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 28/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 29/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 30/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 31/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 32/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 33/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 34/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 35/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 36/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 37/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 38/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 39/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 40/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 41/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 42/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 43/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 44/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 45/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 46/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 47/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 48/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 49/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 50/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 51/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 52/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 53/342] [D loss: -0.051376, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 54/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 55/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 56/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 57/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 58/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 59/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 60/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 61/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 62/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 63/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 64/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 65/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 66/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 67/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 68/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 69/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 70/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 71/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 72/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 9/50] [Batch 73/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 74/342] [D loss: -0.051376, acc: 0.500000, f1: 0.074074] [G loss: 0.737030]\n",
      "[Epoch 9/50] [Batch 75/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 76/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 77/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 78/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 79/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 80/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 81/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 82/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 83/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 9/50] [Batch 84/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 85/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 86/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 87/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 88/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 89/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 90/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 91/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 92/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 93/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 94/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 95/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 96/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 97/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 98/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 99/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 100/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 101/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 102/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 103/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 104/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 105/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 106/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 107/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 108/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 109/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 110/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 111/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 112/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 113/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 114/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 115/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 116/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 117/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 118/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 119/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 120/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 121/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 122/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 123/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 124/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 125/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 126/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 127/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 128/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 129/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 130/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 131/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 132/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 133/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 134/342] [D loss: -0.051376, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 135/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 136/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 137/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 138/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 139/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 140/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 141/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 142/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 143/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 144/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 145/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 146/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 147/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 148/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 149/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 150/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 151/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 152/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 153/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 154/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 155/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 156/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 157/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 158/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 159/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 160/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 161/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 162/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 163/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 164/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 165/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 166/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 167/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 168/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 169/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 170/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 171/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 172/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 173/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 174/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 175/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 176/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 177/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 178/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 179/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 180/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 181/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 182/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 183/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 184/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 185/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 186/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 187/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 188/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 189/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 190/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 191/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 192/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 193/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 194/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 195/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 196/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 197/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 198/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 199/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 200/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 201/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 202/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 203/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 204/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 205/342] [D loss: -0.051375, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 206/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 207/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 208/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 209/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 210/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 211/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 212/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 213/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 214/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 215/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 216/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 217/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 218/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 219/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 220/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 221/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 222/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 223/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 224/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 225/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 226/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 227/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 228/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 229/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 230/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 231/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 232/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 233/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 234/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 235/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 236/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 237/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 238/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 239/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 240/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 241/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 242/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 243/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 244/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 245/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 246/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 247/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 248/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 249/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 250/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 251/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 252/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 253/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 9/50] [Batch 254/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 255/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 256/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 9/50] [Batch 257/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 258/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 259/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 260/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 261/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 262/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 263/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 264/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 265/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 266/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 267/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 268/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 269/342] [D loss: -0.051365, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 270/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 271/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 272/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 273/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 274/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 275/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 276/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 277/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 278/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 279/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 280/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 281/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 282/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737035]\n",
      "[Epoch 9/50] [Batch 283/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 284/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 285/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 286/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 287/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 288/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 289/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 290/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 291/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 292/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 293/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 294/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 295/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 296/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 297/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 298/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 299/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 300/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 301/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 302/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 303/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 304/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 305/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 306/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 9/50] [Batch 307/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 308/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 309/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 310/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 311/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 312/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 313/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 314/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 315/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 316/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 317/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 318/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 319/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 320/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 321/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 322/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 323/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 324/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 325/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 326/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 327/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 328/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 329/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 330/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 331/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 332/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 333/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 334/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 335/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 336/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 337/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 338/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 9/50] [Batch 339/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 9/50] [Batch 340/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 9/50] [Batch 341/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 0/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 1/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 2/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 3/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 4/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 5/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 6/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 7/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 8/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 9/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 10/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 11/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 12/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 13/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 10/50] [Batch 14/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 15/342] [D loss: -0.051376, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 16/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 17/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 18/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 19/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 20/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 21/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 22/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 23/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 24/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 25/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 26/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 27/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 28/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 29/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 30/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 31/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 32/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 33/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 34/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 35/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 36/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 37/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 38/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 39/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 40/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 41/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 42/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 43/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 44/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 45/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 46/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 47/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 48/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 49/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 50/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 51/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 52/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 53/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 54/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 55/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 56/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 57/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 58/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 59/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 60/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 61/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 62/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 63/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 64/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 65/342] [D loss: -0.051376, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 66/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 67/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 68/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 69/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 70/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 71/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 72/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 73/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 74/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 75/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 76/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 77/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 78/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 79/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 80/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 81/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 82/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 83/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 84/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 85/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 86/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 87/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 88/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 89/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 90/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 91/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 92/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 93/342] [D loss: -0.051373, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 94/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 95/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 96/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 97/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 98/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 99/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 100/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 101/342] [D loss: -0.051365, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 102/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 103/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 104/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 105/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 106/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 107/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 108/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 109/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 110/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 111/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 112/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 113/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 114/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 115/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 116/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 117/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 118/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 119/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 120/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 121/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 122/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 123/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 124/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 125/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 126/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 127/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 128/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 129/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 130/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 10/50] [Batch 131/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 132/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 133/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 134/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 135/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 136/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 137/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 138/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 139/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 140/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 141/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 142/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 143/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 144/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 145/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 146/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 147/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 148/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 149/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 150/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 151/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 152/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 153/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 154/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 155/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 156/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 157/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 158/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 159/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 160/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 161/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 162/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 163/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 164/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 165/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 166/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 167/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 168/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 169/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 170/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 171/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 172/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 173/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 174/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 175/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 176/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 177/342] [D loss: -0.051380, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 178/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 179/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 180/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 181/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 182/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 183/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 184/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 185/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 186/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 187/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 188/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 189/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 190/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 191/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 192/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 193/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 194/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 195/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 196/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 197/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 198/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 199/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 200/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 201/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 202/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 203/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 10/50] [Batch 204/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 205/342] [D loss: -0.051381, acc: 0.500000, f1: 0.074074] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 206/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 207/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 208/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 209/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 210/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 211/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 212/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 213/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 214/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 215/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 216/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 217/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 218/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 219/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 220/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 221/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 222/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 223/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 224/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 225/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 226/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 227/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 228/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 229/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 230/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 231/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 232/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 233/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 234/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 235/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 236/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 237/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 238/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 239/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 240/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 241/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 242/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 243/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 244/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 245/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 246/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 247/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 248/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 249/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 250/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 251/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 252/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 253/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 254/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737035]\n",
      "[Epoch 10/50] [Batch 255/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 256/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 257/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 258/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 259/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 260/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 261/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 262/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 263/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 264/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 265/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 266/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 267/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 268/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 269/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 270/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 271/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 272/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 273/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 274/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 275/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 276/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 277/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 278/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 279/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 280/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 281/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 282/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 283/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 284/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 285/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 286/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 287/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 288/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 289/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 290/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 291/342] [D loss: -0.051364, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 292/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 293/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 294/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 295/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 296/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 297/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 298/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 299/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 300/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 301/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 302/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 10/50] [Batch 303/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 304/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 305/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 306/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 307/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 308/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 309/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 310/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 311/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 312/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 313/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 314/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 315/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 316/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 317/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 318/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 319/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 320/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 321/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 322/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 323/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 324/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 325/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 326/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 327/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 328/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737035]\n",
      "[Epoch 10/50] [Batch 329/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 330/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 331/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 332/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 333/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 334/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 335/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 336/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 337/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 10/50] [Batch 338/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 10/50] [Batch 339/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 340/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 10/50] [Batch 341/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 0/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 1/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 2/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 3/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 4/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 5/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 6/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 7/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 8/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 9/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 10/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 11/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 12/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 13/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 14/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 15/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 16/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 17/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 18/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 19/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 20/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 21/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 22/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 23/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 24/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 25/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 26/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 27/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 28/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 29/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 30/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 31/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 32/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 33/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 34/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 35/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 36/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 37/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 38/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 39/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 40/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 41/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 42/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 43/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 44/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 45/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 46/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 47/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 48/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 49/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 50/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 51/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 52/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 53/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 54/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 55/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 56/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 57/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 58/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 59/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 60/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 61/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 62/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 63/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 64/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 65/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 66/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 67/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 68/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 69/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737030]\n",
      "[Epoch 11/50] [Batch 70/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 71/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 72/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 73/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 74/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 75/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 76/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 77/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 78/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 79/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 80/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 81/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 82/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 83/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 84/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 85/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 86/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 87/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 88/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 89/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 90/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 91/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 92/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 93/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 94/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 95/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 96/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 97/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 98/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 99/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 100/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 101/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 102/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 103/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 104/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 105/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 106/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 107/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 108/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 109/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 110/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 111/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 112/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 113/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 114/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 115/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 116/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 117/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 118/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 119/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 120/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 121/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 122/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 123/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 124/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 125/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 126/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 127/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 128/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 129/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 130/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 131/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 132/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 133/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 134/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 135/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 136/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 137/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 138/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 139/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 140/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 141/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 142/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 143/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 144/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 145/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 146/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 147/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 148/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 149/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 11/50] [Batch 150/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 151/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 152/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 153/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 154/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 155/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 156/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 157/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 158/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 159/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 160/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 161/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 162/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 163/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 164/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 165/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 166/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 167/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 168/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 169/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 170/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 171/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 172/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 173/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 174/342] [D loss: -0.051368, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 175/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 176/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 177/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 178/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 179/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 180/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 181/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 182/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 183/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 184/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 185/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 186/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 187/342] [D loss: -0.051373, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 188/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 189/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 190/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 191/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 192/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 193/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 194/342] [D loss: -0.051371, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 195/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 196/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 197/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 198/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 199/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 200/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 201/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 202/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 203/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 204/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 205/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 206/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 207/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 208/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 209/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 210/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 211/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 212/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 213/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 214/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 215/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 216/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 217/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 218/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 219/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 220/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 221/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 222/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 223/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 224/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 225/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 226/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 227/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 228/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 229/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 230/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 231/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 232/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 233/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 234/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 235/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 236/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 237/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 238/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 239/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 240/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 241/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 242/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 243/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 244/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 11/50] [Batch 245/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 246/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 247/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 248/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 249/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 250/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 251/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 252/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 253/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 254/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 255/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 256/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 257/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 258/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 259/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 260/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 261/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 262/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 263/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 264/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 265/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 266/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 267/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 268/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 269/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 270/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 271/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 272/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 273/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 274/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 275/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 276/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 277/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 278/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 279/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 280/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 281/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 282/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 283/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 284/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 285/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 286/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 287/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 288/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 289/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 290/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 291/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 292/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 293/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 294/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 295/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 296/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 297/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 298/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 299/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 300/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 301/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 302/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 303/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 304/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 305/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 306/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 307/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 308/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 309/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 310/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 311/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 312/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 313/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 314/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 315/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 316/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 317/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 318/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 319/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 320/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 321/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 322/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 323/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 324/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 325/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 326/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 327/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 328/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 329/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 330/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 331/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 332/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 333/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 334/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 335/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 336/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 11/50] [Batch 337/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 11/50] [Batch 338/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 339/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 11/50] [Batch 340/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 11/50] [Batch 341/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 0/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 1/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 2/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 3/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 4/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 5/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 6/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 12/50] [Batch 7/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 8/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 9/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 10/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 11/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 12/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 13/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 14/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 15/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 16/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 17/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 18/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 19/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 20/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 21/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 22/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 23/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 24/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 25/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 26/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 27/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 28/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 29/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 30/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 31/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 32/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 33/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 34/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 35/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 36/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 37/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 38/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 39/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 40/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 41/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 42/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 43/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 44/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 45/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 46/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 47/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 48/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 49/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 50/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 51/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 52/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 53/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 54/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 55/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 56/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 57/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 12/50] [Batch 58/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 59/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 60/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 61/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 62/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 63/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 64/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 65/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 66/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 67/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 68/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 69/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 70/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 71/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 72/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 73/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 74/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 75/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 76/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 77/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 78/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 79/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 80/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 81/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 82/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 83/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 84/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 85/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 86/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 87/342] [D loss: -0.051374, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 88/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 89/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 90/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 91/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 92/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 93/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 94/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 95/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 96/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 97/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 98/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 99/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 100/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 101/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 102/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 103/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 104/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 105/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 106/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 107/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 108/342] [D loss: -0.051376, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 109/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 110/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 111/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 112/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 113/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 114/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 115/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 116/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 117/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 118/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 119/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 120/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 121/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 122/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 123/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 124/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 125/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 126/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 127/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 128/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 129/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 130/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 131/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 132/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 133/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 134/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 135/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 136/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 137/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 138/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 139/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 140/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 141/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 142/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 143/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 144/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 145/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 146/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 147/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 148/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 149/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 150/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 151/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 152/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 153/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 154/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 155/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 156/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 157/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 158/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 159/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 160/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 161/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 162/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 163/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 164/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 165/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 166/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 167/342] [D loss: -0.051375, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 168/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 169/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 170/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 171/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 172/342] [D loss: -0.051378, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 173/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 174/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 175/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 176/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 177/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 178/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 179/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 180/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 181/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 182/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 183/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 184/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 185/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 186/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 187/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 188/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 189/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 190/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 191/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 192/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 193/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 194/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 195/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 196/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 197/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 198/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 199/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 200/342] [D loss: -0.051380, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 201/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 202/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 203/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 204/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 205/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 206/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 207/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 208/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 209/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 210/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 211/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 212/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 213/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 214/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 215/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 216/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 217/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 218/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 219/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 220/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 221/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 222/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 223/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 224/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 225/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 226/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 227/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 228/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 229/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 230/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 231/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 232/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 233/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 234/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 235/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 236/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 237/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 238/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 239/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 240/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 241/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 242/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 243/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 244/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 245/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737030]\n",
      "[Epoch 12/50] [Batch 246/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 247/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737034]\n",
      "[Epoch 12/50] [Batch 248/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 249/342] [D loss: -0.051380, acc: 0.500000, f1: 0.066667] [G loss: 0.737034]\n",
      "[Epoch 12/50] [Batch 250/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 251/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 252/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 253/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 254/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 255/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 256/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 257/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 258/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 259/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 260/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 261/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 262/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 263/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 264/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 265/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 266/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 267/342] [D loss: -0.051364, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 268/342] [D loss: -0.051372, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 269/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 270/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 271/342] [D loss: -0.051377, acc: 0.500000, f1: 0.074074] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 272/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 273/342] [D loss: -0.051376, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 274/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 275/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 276/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 277/342] [D loss: -0.051379, acc: 0.500000, f1: 0.060606] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 278/342] [D loss: -0.051377, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 279/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 280/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 281/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 282/342] [D loss: -0.051379, acc: 0.500000, f1: 0.074074] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 283/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 284/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 285/342] [D loss: -0.051379, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 286/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 287/342] [D loss: -0.051378, acc: 0.500000, f1: 0.060606] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 288/342] [D loss: -0.051377, acc: 0.500000, f1: 0.060606] [G loss: 0.737031]\n",
      "[Epoch 12/50] [Batch 289/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737033]\n",
      "[Epoch 12/50] [Batch 290/342] [D loss: -0.051378, acc: 0.500000, f1: 0.066667] [G loss: 0.737032]\n",
      "[Epoch 12/50] [Batch 291/342] [D loss: -0.051384, acc: 0.500000, f1: 0.066667] [G loss: 0.737036]\n",
      "[Epoch 12/50] [Batch 292/342] [D loss: -0.051388, acc: 0.500000, f1: 0.066667] [G loss: 0.737041]\n",
      "[Epoch 12/50] [Batch 293/342] [D loss: -0.051390, acc: 0.500000, f1: 0.066667] [G loss: 0.737042]\n",
      "[Epoch 12/50] [Batch 294/342] [D loss: -0.051393, acc: 0.500000, f1: 0.066667] [G loss: 0.737045]\n",
      "[Epoch 12/50] [Batch 295/342] [D loss: -0.051394, acc: 0.500000, f1: 0.066667] [G loss: 0.737045]\n",
      "[Epoch 12/50] [Batch 296/342] [D loss: -0.051396, acc: 0.500000, f1: 0.060606] [G loss: 0.737047]\n",
      "[Epoch 12/50] [Batch 297/342] [D loss: -0.051398, acc: 0.500000, f1: 0.066667] [G loss: 0.737049]\n",
      "[Epoch 12/50] [Batch 298/342] [D loss: -0.051398, acc: 0.500000, f1: 0.060606] [G loss: 0.737049]\n",
      "[Epoch 12/50] [Batch 299/342] [D loss: -0.051399, acc: 0.500000, f1: 0.066667] [G loss: 0.737050]\n",
      "[Epoch 12/50] [Batch 300/342] [D loss: -0.051400, acc: 0.500000, f1: 0.066667] [G loss: 0.737050]\n",
      "[Epoch 12/50] [Batch 301/342] [D loss: -0.051393, acc: 0.500000, f1: 0.060606] [G loss: 0.737051]\n",
      "[Epoch 12/50] [Batch 302/342] [D loss: -0.051400, acc: 0.500000, f1: 0.066667] [G loss: 0.737051]\n",
      "[Epoch 12/50] [Batch 303/342] [D loss: -0.051401, acc: 0.500000, f1: 0.060606] [G loss: 0.737051]\n",
      "[Epoch 12/50] [Batch 304/342] [D loss: -0.051401, acc: 0.500000, f1: 0.060606] [G loss: 0.737052]\n",
      "[Epoch 12/50] [Batch 305/342] [D loss: -0.051401, acc: 0.500000, f1: 0.066667] [G loss: 0.737052]\n",
      "[Epoch 12/50] [Batch 306/342] [D loss: -0.051401, acc: 0.500000, f1: 0.066667] [G loss: 0.737052]\n",
      "[Epoch 12/50] [Batch 307/342] [D loss: -0.051401, acc: 0.500000, f1: 0.066667] [G loss: 0.737052]\n",
      "[Epoch 12/50] [Batch 308/342] [D loss: -0.051402, acc: 0.500000, f1: 0.066667] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 309/342] [D loss: -0.051401, acc: 0.500000, f1: 0.060606] [G loss: 0.737052]\n",
      "[Epoch 12/50] [Batch 310/342] [D loss: -0.051403, acc: 0.500000, f1: 0.066667] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 311/342] [D loss: -0.051402, acc: 0.500000, f1: 0.066667] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 312/342] [D loss: -0.051403, acc: 0.500000, f1: 0.066667] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 313/342] [D loss: -0.051403, acc: 0.500000, f1: 0.060606] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 314/342] [D loss: -0.051403, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 315/342] [D loss: -0.051403, acc: 0.500000, f1: 0.066667] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 316/342] [D loss: -0.051404, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 317/342] [D loss: -0.051404, acc: 0.500000, f1: 0.060606] [G loss: 0.737053]\n",
      "[Epoch 12/50] [Batch 318/342] [D loss: -0.051403, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 319/342] [D loss: -0.051404, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 320/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737055]\n",
      "[Epoch 12/50] [Batch 321/342] [D loss: -0.051404, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 322/342] [D loss: -0.051406, acc: 0.500000, f1: 0.066667] [G loss: 0.737055]\n",
      "[Epoch 12/50] [Batch 323/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737055]\n",
      "[Epoch 12/50] [Batch 324/342] [D loss: -0.051404, acc: 0.500000, f1: 0.066667] [G loss: 0.737056]\n",
      "[Epoch 12/50] [Batch 325/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 326/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737055]\n",
      "[Epoch 12/50] [Batch 327/342] [D loss: -0.051404, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 328/342] [D loss: -0.051404, acc: 0.500000, f1: 0.060606] [G loss: 0.737056]\n",
      "[Epoch 12/50] [Batch 329/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737054]\n",
      "[Epoch 12/50] [Batch 330/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737056]\n",
      "[Epoch 12/50] [Batch 331/342] [D loss: -0.051405, acc: 0.500000, f1: 0.066667] [G loss: 0.737055]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30913/60083553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mf1score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mopt_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = 0.0\n",
    "f1score = 0.0\n",
    "clip_value = 0.01\n",
    "\n",
    "tb = SummaryWriter(log_dir='lightning_logs')\n",
    "for epoch in range(n_epoch):\n",
    "    for i, (imgs, labels) in enumerate(tr_dataloader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(torch.FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False).cuda()\n",
    "        fake = Variable(torch.FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False).cuda()\n",
    "        fake_aux_gt = Variable(torch.LongTensor(batch_size).fill_(num_classes), requires_grad=False).cuda()\n",
    "        \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "\n",
    "        z = torch.randn(batch_size, z_dim).cuda()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = G(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, _ = D(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        # print(imgs.device)\n",
    "        real_pred, real_aux = D(imgs)\n",
    "        # print(real_pred.device, valid.device, real_aux.device, labels.device)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        # fake_pred, fake_aux = D(gen_imgs)\n",
    "        fake_pred, fake_aux = D(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, fake_aux_gt)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        # d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss = -torch.mean(d_real_loss) + torch.mean(d_fake_loss)\n",
    "        \n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), fake_aux_gt.data.cpu().numpy()], axis=0)\n",
    "        # d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "        y_pred = np.argmax(pred, axis=1)\n",
    "        accuracy = accuracy_score(gt, y_pred)\n",
    "        precision = precision_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        f1score = f1_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        recall = recall_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        d_loss.backward()\n",
    "\n",
    "        opt_D.step()\n",
    "        for p in D.parameters():\n",
    "           p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "        tb.add_scalar('f1_score', f1score, (epoch+1)*i)\n",
    "        tb.add_scalar('accuracy', accuracy, (epoch+1)*i)\n",
    "        \n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %f, f1: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epoch, i, len(tr_dataloader), d_loss.item(), accuracy, f1score, g_loss.item())\n",
    "        )\n",
    "\n",
    "        # batches_done = epoch * len(tr_dataloader) + i\n",
    "        # if batches_done % sample_interval == 0:\n",
    "        #     save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.eval()\n",
    "f1score = 0.0\n",
    "accuracy = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, labels) in enumerate(te_dataloader):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        pred_true, pred_labels = D(imgs)\n",
    "        pred = pred_labels.data.cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        real = labels.data.cpu().numpy()\n",
    "        accuracy += accuracy_score(real, pred)\n",
    "        # precision = precision_score(gt, y_pred, average='macro', zero_division=1)\n",
    "        f1score += f1_score(real, pred, average='macro', zero_division=1)\n",
    "        # recall = recall_score(gt, y_pred, average='macro', zero_division=1)\n",
    "length = len(te_dataloader)\n",
    "print(accuracy/length, f1score/length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:5]\n",
    "real[:5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b82254768225213474ab4669cea3d52fe6b864ad6c9d79489ae1089fd4498"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
